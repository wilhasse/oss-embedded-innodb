==================================================================
COMPONENT: LOGGING AND RECOVERY
==================================================================
The log system implements write-ahead logging (WAL) for durability
and crash recovery. This is essential for the 'D' in ACID.

Key concepts:
- Redo log structure and format
- Log sequence numbers (LSN)
- Checkpointing mechanism
- Recovery process (analysis, redo, undo phases)
- Log buffer and flushing

Files included:
/*****************************************************************************

Copyright (c) 1995, 2010, Innobase Oy. All Rights Reserved.
Copyright (c) 2009, Google Inc.

Portions of this file contain modifications contributed and copyrighted by
Google, Inc. Those modifications are gratefully acknowledged and are described
briefly in the InnoDB documentation. The contributions by Google are
incorporated with their permission, and subject to the conditions contained in
the file COPYING.Google.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file include/log0log.h
Database log

Created 12/9/1995 Heikki Tuuri
*******************************************************/

#ifndef log0log_h
#define log0log_h

#include "univ.i"
#include "ut0byte.h"
#include "ut0lst.h"
#ifndef UNIV_HOTBACKUP
#include "sync0sync.h"
#include "sync0rw.h"
#endif /* !UNIV_HOTBACKUP */
#include "srv0srv.h"
#include "api0api.h"

/** Redo log buffer */
typedef struct log_struct	log_t;
/** Redo log group */
typedef struct log_group_struct	log_group_t;

#ifdef UNIV_DEBUG
/** Flag: write to log file? */
extern	ibool	log_do_write;
/** Flag: enable debug output when writing to the log? */
extern	ibool	log_debug_writes;
#else /* UNIV_DEBUG */
/** Write to log */
# define log_do_write TRUE
#endif /* UNIV_DEBUG */

/** Wait modes for log_write_up_to @{ */
#define LOG_NO_WAIT		91
#define LOG_WAIT_ONE_GROUP	92
#define	LOG_WAIT_ALL_GROUPS	93
/* @} */
/** Maximum number of log groups in log_group_struct::checkpoint_buf */
#define LOG_MAX_N_GROUPS	32

#ifndef UNIV_HOTBACKUP
/****************************************************************//**
Sets the global variable log_fsp_current_free_limit. Also makes a checkpoint,
so that we know that the limit has been written to a log checkpoint field
on disk. */
UNIV_INTERN
void
log_fsp_current_free_limit_set_and_checkpoint(
/*==========================================*/
	ulint	limit);	/*!< in: limit to set */
#endif /* !UNIV_HOTBACKUP */
/*******************************************************************//**
Calculates where in log files we find a specified lsn.
@return	log file number */
UNIV_INTERN
ulint
log_calc_where_lsn_is(
/*==================*/
	ib_int64_t*	log_file_offset,	/*!< out: offset in that file
						(including the header) */
	ib_uint64_t	first_header_lsn,	/*!< in: first log file start
						lsn */
	ib_uint64_t	lsn,			/*!< in: lsn whose position to
						determine */
	ulint		n_log_files,		/*!< in: total number of log
						files */
	ib_int64_t	log_file_size);		/*!< in: log file size
						(including the header) */
#ifndef UNIV_HOTBACKUP
/*************************************************************************//**
Acquire the log mutex. */
UNIV_INLINE
void
log_acquire(void);
/*=============*/

/************************************************************//**
Writes to the log the string given. The log must be released with
log_release.
@return	end lsn of the log record, zero if did not succeed */
UNIV_INLINE
ib_uint64_t
log_reserve_and_write_fast(
/*=======================*/
	const void*	str,	/*!< in: string */
	ulint		len,	/*!< in: string length */
	ib_uint64_t*	start_lsn);/*!< out: start lsn of the log record */
/***********************************************************************//**
Releases the log mutex. */
UNIV_INLINE
void
log_release(void);
/*=============*/
/***********************************************************************//**
Checks if there is need for a log buffer flush or a new checkpoint, and does
this if yes. Any database operation should call this when it has modified
more than about 4 pages. NOTE that this function may only be called when the
OS thread owns no synchronization objects except the dictionary mutex. */
UNIV_INLINE
void
log_free_check(void);
/*================*/
/************************************************************//**
Opens the log for log_write_low. The log must be closed with log_close and
released with log_release.
@return	start lsn of the log record */
UNIV_INTERN
ib_uint64_t
log_reserve_and_open(
/*=================*/
	ulint	len);	/*!< in: length of data to be catenated */
/************************************************************//**
Writes to the log the string given. It is assumed that the caller holds the
log mutex. */
UNIV_INTERN
void
log_write_low(
/*==========*/
	byte*	str,		/*!< in: string */
	ulint	str_len);	/*!< in: string length */
/************************************************************//**
Closes the log.
@return	lsn */
UNIV_INTERN
ib_uint64_t
log_close(
/*======*/
	ib_recovery_t	recovery);	/*!< in: recovery flag */
/************************************************************//**
Gets the current lsn.
@return	current lsn */
UNIV_INLINE
ib_uint64_t
log_get_lsn(void);
/*=============*/
/****************************************************************
Gets the log group capacity. It is OK to read the value without
holding log_sys->mutex because it is constant.
@return	log group capacity */
UNIV_INLINE
ulint
log_get_capacity(void);
/*==================*/
/******************************************************//**
Initializes the log. */
UNIV_INTERN
void
innobase_log_init(void);
/*====================*/
/******************************************************************//**
Inits a log group to the log system. */
UNIV_INTERN
void
log_group_init(
/*===========*/
	ulint	id,			/*!< in: group id */
	ulint	n_files,		/*!< in: number of log files */
	ulint	file_size,		/*!< in: log file size in bytes */
	ulint	space_id,		/*!< in: space id of the file space
					which contains the log files of this
					group */
	ulint	archive_space_id);	/*!< in: space id of the file space
					which contains some archived log
					files for this group; currently, only
					for the first log group this is
					used */
/******************************************************//**
Completes an i/o to a log file. */
UNIV_INTERN
void
log_io_complete(
/*============*/
	log_group_t*	group);	/*!< in: log group */
/******************************************************//**
This function is called, e.g., when a transaction wants to commit. It checks
that the log has been written to the log file up to the last log entry written
by the transaction. If there is a flush running, it waits and checks if the
flush flushed enough. If not, starts a new flush. */
UNIV_INTERN
void
log_write_up_to(
/*============*/
	ib_uint64_t	lsn,	/*!< in: log sequence number up to which
				the log should be written,
				IB_UINT64_T_MAX if not specified */
	ulint		wait,	/*!< in: LOG_NO_WAIT, LOG_WAIT_ONE_GROUP,
				or LOG_WAIT_ALL_GROUPS */
	ibool		flush_to_disk);
				/*!< in: TRUE if we want the written log
				also to be flushed to disk */
/****************************************************************//**
Does a syncronous flush of the log buffer to disk. */
UNIV_INTERN
void
log_buffer_flush_to_disk(void);
/*==========================*/
/****************************************************************//**
This functions writes the log buffer to the log file and if 'flush'
is set it forces a flush of the log file as well. This is meant to be
called from background master thread only as it does not wait for
the write (+ possible flush) to finish. */
UNIV_INTERN
void
log_buffer_sync_in_background(
/*==========================*/
	ibool	flush);	/*<! in: flush the logs to disk */
/****************************************************************//**
Advances the smallest lsn for which there are unflushed dirty blocks in the
buffer pool and also may make a new checkpoint. NOTE: this function may only
be called if the calling thread owns no synchronization objects!
@return FALSE if there was a flush batch of the same type running,
which means that we could not start this flush batch */
UNIV_INTERN
ibool
log_preflush_pool_modified_pages(
/*=============================*/
	ib_uint64_t	new_oldest,	/*!< in: try to advance
					oldest_modified_lsn at least
					to this lsn */
	ibool		sync);		/*!< in: TRUE if synchronous
					operation is desired */
/******************************************************//**
Makes a checkpoint. Note that this function does not flush dirty
blocks from the buffer pool: it only checks what is lsn of the oldest
modification in the pool, and writes information about the lsn in
log files. Use log_make_checkpoint_at to flush also the pool.
@return	TRUE if success, FALSE if a checkpoint write was already running */
UNIV_INTERN
ibool
log_checkpoint(
/*===========*/
	ibool	sync,		/*!< in: TRUE if synchronous operation is
				desired */
	ibool	write_always);	/*!< in: the function normally checks if the
				the new checkpoint would have a greater
				lsn than the previous one: if not, then no
				physical write is done; by setting this
				parameter TRUE, a physical write will always be
				made to log files */
/****************************************************************//**
Makes a checkpoint at a given lsn or later. */
UNIV_INTERN
void
log_make_checkpoint_at(
/*===================*/
	ib_uint64_t	lsn,		/*!< in: make a checkpoint at this or a
					later lsn, if IB_UINT64_T_MAX, makes
					a checkpoint at the latest lsn */
	ibool		write_always);	/*!< in: the function normally checks if
					the new checkpoint would have a
					greater lsn than the previous one: if
					not, then no physical write is done;
					by setting this parameter TRUE, a
					physical write will always be made to
					log files */
/****************************************************************//**
Makes a checkpoint at the latest lsn and writes it to first page of each
data file in the database, so that we know that the file spaces contain
all modifications up to that lsn. This can only be called at database
shutdown. This function also writes all log in log files to the log archive. */
UNIV_INTERN
void
logs_empty_and_mark_files_at_shutdown(
/*==================================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	ib_shutdown_t	shutdown);	/*!< in: shutdown flag */
/******************************************************//**
Reads a checkpoint info from a log group header to log_sys->checkpoint_buf. */
UNIV_INTERN
void
log_group_read_checkpoint_info(
/*===========================*/
	log_group_t*	group,	/*!< in: log group */
	ulint		field);	/*!< in: LOG_CHECKPOINT_1 or LOG_CHECKPOINT_2 */
/*******************************************************************//**
Gets info from a checkpoint about a log group. */
UNIV_INTERN
void
log_checkpoint_get_nth_group_info(
/*==============================*/
	const byte*	buf,	/*!< in: buffer containing checkpoint info */
	ulint		n,	/*!< in: nth slot */
	ulint*		file_no,/*!< out: archived file number */
	ulint*		offset);/*!< out: archived file offset */
/******************************************************//**
Writes checkpoint info to groups. */
UNIV_INTERN
void
log_groups_write_checkpoint_info(void);
/*==================================*/
/********************************************************************//**
Starts an archiving operation.
@return	TRUE if succeed, FALSE if an archiving operation was already running */
UNIV_INTERN
ibool
log_archive_do(
/*===========*/
	ibool	sync,	/*!< in: TRUE if synchronous operation is desired */
	ulint*	n_bytes);/*!< out: archive log buffer size, 0 if nothing to
			archive */
/****************************************************************//**
Writes the log contents to the archive up to the lsn when this function was
called, and stops the archiving. When archiving is started again, the archived
log file numbers start from a number one higher, so that the archiving will
not write again to the archived log files which exist when this function
returns.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_stop(void);
/*==================*/
/****************************************************************//**
Starts again archiving which has been stopped.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_start(void);
/*===================*/
/****************************************************************//**
>>>>>>> .merge-right.r5456
Stop archiving the log so that a gap may occur in the archived log files.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_noarchivelog(void);
/*==========================*/
/****************************************************************//**
Start archiving the log so that a gap may occur in the archived log files.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_archivelog(void);
/*========================*/
/******************************************************//**
Generates an archived log file name. */
UNIV_INTERN
void
log_archived_file_name_gen(
/*=======================*/
	char*	buf,	/*!< in: buffer where to write */
	ulint	id,	/*!< in: group id */
	ulint	file_no);/*!< in: file number */
#else /* !UNIV_HOTBACKUP */
/******************************************************//**
Writes info to a buffer of a log group when log files are created in
backup restoration. */
UNIV_INTERN
void
log_reset_first_header_and_checkpoint(
/*==================================*/
	byte*		hdr_buf,/*!< in: buffer which will be written to the
				start of the first log file */
	ib_uint64_t	start);	/*!< in: lsn of the start of the first log file;
				we pretend that there is a checkpoint at
				start + LOG_BLOCK_HDR_SIZE */
#endif /* !UNIV_HOTBACKUP */
/********************************************************************//**
Checks that there is enough free space in the log to start a new query step.
Flushes the log buffer or makes a new checkpoint if necessary. NOTE: this
function may only be called if the calling thread owns no synchronization
objects! */
UNIV_INTERN
void
log_check_margins(void);
/*===================*/
#ifndef UNIV_HOTBACKUP
/******************************************************//**
Reads a specified log segment to a buffer. */
UNIV_INTERN
void
log_group_read_log_seg(
/*===================*/
	ulint		type,		/*!< in: LOG_ARCHIVE or LOG_RECOVER */
	byte*		buf,		/*!< in: buffer where to read */
	log_group_t*	group,		/*!< in: log group */
	ib_uint64_t	start_lsn,	/*!< in: read area start */
	ib_uint64_t	end_lsn);	/*!< in: read area end */
/******************************************************//**
Writes a buffer to a log file group. */
UNIV_INTERN
void
log_group_write_buf(
/*================*/
	log_group_t*	group,		/*!< in: log group */
	byte*		buf,		/*!< in: buffer */
	ulint		len,		/*!< in: buffer len; must be divisible
					by OS_FILE_LOG_BLOCK_SIZE */
	ib_uint64_t	start_lsn,	/*!< in: start lsn of the buffer; must
					be divisible by
					OS_FILE_LOG_BLOCK_SIZE */
	ulint		new_data_offset);/*!< in: start offset of new data in
					buf: this parameter is used to decide
					if we have to write a new log file
					header */
/********************************************************//**
Sets the field values in group to correspond to a given lsn. For this function
to work, the values must already be correctly initialized to correspond to
some lsn, for instance, a checkpoint lsn. */
UNIV_INTERN
void
log_group_set_fields(
/*=================*/
	log_group_t*	group,	/*!< in/out: group */
	ib_uint64_t	lsn);	/*!< in: lsn for which the values should be
				set */
/******************************************************//**
Calculates the data capacity of a log group, when the log file headers are not
included.
@return	capacity in bytes */
UNIV_INTERN
ulint
log_group_get_capacity(
/*===================*/
	const log_group_t*	group);	/*!< in: log group */
#endif /* !UNIV_HOTBACKUP */
/************************************************************//**
Gets a log block flush bit.
@return	TRUE if this block was the first to be written in a log flush */
UNIV_INLINE
ibool
log_block_get_flush_bit(
/*====================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Gets a log block number stored in the header.
@return	log block number stored in the block header */
UNIV_INLINE
ulint
log_block_get_hdr_no(
/*=================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Gets a log block data length.
@return	log block data length measured as a byte offset from the block start */
UNIV_INLINE
ulint
log_block_get_data_len(
/*===================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Sets the log block data length. */
UNIV_INLINE
void
log_block_set_data_len(
/*===================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	len);		/*!< in: data length */
/************************************************************//**
Calculates the checksum for a log block.
@return	checksum */
UNIV_INLINE
ulint
log_block_calc_checksum(
/*====================*/
	const byte*	block);	/*!< in: log block */
/************************************************************//**
Gets a log block checksum field value.
@return	checksum */
UNIV_INLINE
ulint
log_block_get_checksum(
/*===================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Sets a log block checksum field value. */
UNIV_INLINE
void
log_block_set_checksum(
/*===================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	checksum);	/*!< in: checksum */
/************************************************************//**
Gets a log block first mtr log record group offset.
@return first mtr log record group byte offset from the block start, 0
if none */
UNIV_INLINE
ulint
log_block_get_first_rec_group(
/*==========================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Sets the log block first mtr log record group offset. */
UNIV_INLINE
void
log_block_set_first_rec_group(
/*==========================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	offset);	/*!< in: offset, 0 if none */
/************************************************************//**
Gets a log block checkpoint number field (4 lowest bytes).
@return	checkpoint no (4 lowest bytes) */
UNIV_INLINE
ulint
log_block_get_checkpoint_no(
/*========================*/
	const byte*	log_block);	/*!< in: log block */
/************************************************************//**
Initializes a log block in the log buffer. */
UNIV_INLINE
void
log_block_init(
/*===========*/
	byte*		log_block,	/*!< in: pointer to the log buffer */
	ib_uint64_t	lsn);		/*!< in: lsn within the log block */
/************************************************************//**
Initializes a log block in the log buffer in the old, < 3.23.52 format, where
there was no checksum yet. */
UNIV_INLINE
void
log_block_init_in_old_format(
/*=========================*/
	byte*		log_block,	/*!< in: pointer to the log buffer */
	ib_uint64_t	lsn);		/*!< in: lsn within the log block */
/************************************************************//**
Converts a lsn to a log block number.
@return	log block number, it is > 0 and <= 1G */
UNIV_INLINE
ulint
log_block_convert_lsn_to_no(
/*========================*/
	ib_uint64_t	lsn);	/*!< in: lsn of a byte within the block */
/******************************************************//**
Prints info of the log. */
UNIV_INTERN
void
log_print(
/*======*/
	ib_stream_t	ib_stream);	/*!< in: stream where to print */
/******************************************************//**
Peeks the current lsn.
@return	TRUE if success, FALSE if could not get the log system mutex */
UNIV_INTERN
ibool
log_peek_lsn(
/*=========*/
	ib_uint64_t*	lsn);	/*!< out: if returns TRUE, current lsn is here */
/**********************************************************************//**
Refreshes the statistics used to print per-second averages. */
UNIV_INTERN
void
log_refresh_stats(void);
/*===================*/
/**********************************************************
Shutdown log system but doesn't release all the memory. */
UNIV_INTERN
void
log_shutdown(void);
/*==============*/
/********************************************************************
Reset the variables. */
UNIV_INTERN
void
log_var_init(void);
/*==============*/
/**********************************************************
Free the log system data structures. */
UNIV_INTERN
void
log_mem_free(void);
/*===============*/

extern log_t*	log_sys;

/* Values used as flags */
#define LOG_FLUSH	7652559
#define LOG_CHECKPOINT	78656949
#ifdef UNIV_LOG_ARCHIVE
# define LOG_ARCHIVE	11122331
#endif /* UNIV_LOG_ARCHIVE */
#define LOG_RECOVER	98887331

/* The counting of lsn's starts from this value: this must be non-zero */
#define LOG_START_LSN		((ib_uint64_t) (16 * OS_FILE_LOG_BLOCK_SIZE))

#define LOG_BUFFER_SIZE		(srv_log_buffer_size * UNIV_PAGE_SIZE)
#define LOG_ARCHIVE_BUF_SIZE	(srv_log_buffer_size * UNIV_PAGE_SIZE / 4)

/* Offsets of a log block header */
#define	LOG_BLOCK_HDR_NO	0	/* block number which must be > 0 and
					is allowed to wrap around at 2G; the
					highest bit is set to 1 if this is the
					first log block in a log flush write
					segment */
#define LOG_BLOCK_FLUSH_BIT_MASK 0x80000000UL
					/* mask used to get the highest bit in
					the preceding field */
#define	LOG_BLOCK_HDR_DATA_LEN	4	/* number of bytes of log written to
					this block */
#define	LOG_BLOCK_FIRST_REC_GROUP 6	/* offset of the first start of an
					mtr log record group in this log block,
					0 if none; if the value is the same
					as LOG_BLOCK_HDR_DATA_LEN, it means
					that the first rec group has not yet
					been catenated to this log block, but
					if it will, it will start at this
					offset; an archive recovery can
					start parsing the log records starting
					from this offset in this log block,
					if value not 0 */
#define LOG_BLOCK_CHECKPOINT_NO	8	/* 4 lower bytes of the value of
					log_sys->next_checkpoint_no when the
					log block was last written to: if the
					block has not yet been written full,
					this value is only updated before a
					log buffer flush */
#define LOG_BLOCK_HDR_SIZE	12	/* size of the log block header in
					bytes */

/* Offsets of a log block trailer from the end of the block */
#define	LOG_BLOCK_CHECKSUM	4	/* 4 byte checksum of the log block
					contents; in InnoDB versions
					< 3.23.52 this did not contain the
					checksum but the same value as
					.._HDR_NO */
#define	LOG_BLOCK_TRL_SIZE	4	/* trailer size in bytes */

/* Offsets for a checkpoint field */
#define LOG_CHECKPOINT_NO		0
#define LOG_CHECKPOINT_LSN		8
#define LOG_CHECKPOINT_OFFSET		16
#define LOG_CHECKPOINT_LOG_BUF_SIZE	20
#define	LOG_CHECKPOINT_ARCHIVED_LSN	24
#define	LOG_CHECKPOINT_GROUP_ARRAY	32

/* For each value smaller than LOG_MAX_N_GROUPS the following 8 bytes: */

#define LOG_CHECKPOINT_ARCHIVED_FILE_NO	0
#define LOG_CHECKPOINT_ARCHIVED_OFFSET	4

#define	LOG_CHECKPOINT_ARRAY_END	(LOG_CHECKPOINT_GROUP_ARRAY\
							+ LOG_MAX_N_GROUPS * 8)
#define LOG_CHECKPOINT_CHECKSUM_1	LOG_CHECKPOINT_ARRAY_END
#define LOG_CHECKPOINT_CHECKSUM_2	(4 + LOG_CHECKPOINT_ARRAY_END)
#define LOG_CHECKPOINT_FSP_FREE_LIMIT	(8 + LOG_CHECKPOINT_ARRAY_END)
					/* current fsp free limit in
					tablespace 0, in units of one
					megabyte; this information is only used
					by ibbackup to decide if it can
					truncate unused ends of
					non-auto-extending data files in space
					0 */
#define LOG_CHECKPOINT_FSP_MAGIC_N	(12 + LOG_CHECKPOINT_ARRAY_END)
					/* this magic number tells if the
					checkpoint contains the above field:
					the field was added to
					InnoDB-3.23.50 */
#define LOG_CHECKPOINT_SIZE		(16 + LOG_CHECKPOINT_ARRAY_END)

#define LOG_CHECKPOINT_FSP_MAGIC_N_VAL	1441231243

/* Offsets of a log file header */
#define LOG_GROUP_ID		0	/* log group number */
#define LOG_FILE_START_LSN	4	/* lsn of the start of data in this
					log file */
#define LOG_FILE_NO		12	/* 4-byte archived log file number;
					this field is only defined in an
					archived log file */
#define LOG_FILE_WAS_CREATED_BY_HOT_BACKUP 16
					/* a 32-byte field which contains
					the string 'ibbackup' and the
					creation time if the log file was
					created by ibbackup --restore;
					when the application is started for
					the first time on the restored
					database, it can print helpful
					info for the user */
#define	LOG_FILE_ARCH_COMPLETED	OS_FILE_LOG_BLOCK_SIZE
					/* this 4-byte field is TRUE when
					the writing of an archived log file
					has been completed; this field is
					only defined in an archived log file */
#define LOG_FILE_END_LSN	(OS_FILE_LOG_BLOCK_SIZE + 4)
					/* lsn where the archived log file
					at least extends: actually the
					archived log file may extend to a
					later lsn, as long as it is within the
					same log block as this lsn; this field
					is defined only when an archived log
					file has been completely written */
#define LOG_CHECKPOINT_1	OS_FILE_LOG_BLOCK_SIZE
					/* first checkpoint field in the log
					header; we write alternately to the
					checkpoint fields when we make new
					checkpoints; this field is only defined
					in the first log file of a log group */
#define LOG_CHECKPOINT_2	(3 * OS_FILE_LOG_BLOCK_SIZE)
					/* second checkpoint field in the log
					header */
#define LOG_FILE_HDR_SIZE	(4 * OS_FILE_LOG_BLOCK_SIZE)

#define LOG_GROUP_OK		301
#define LOG_GROUP_CORRUPTED	302

/** Log group consists of a number of log files, each of the same size; a log
group is implemented as a space in the sense of the module fil0fil. */
struct log_group_struct{
	/* The following fields are protected by log_sys->mutex */
	ulint		id;		/*!< log group id */
	ulint		n_files;	/*!< number of files in the group */
	ulint		file_size;	/*!< individual log file size in bytes,
					including the log file header */
	ulint		space_id;	/*!< file space which implements the log
					group */
	ulint		state;		/*!< LOG_GROUP_OK or
					LOG_GROUP_CORRUPTED */
	ib_uint64_t	lsn;		/*!< lsn used to fix coordinates within
					the log group */
	ulint		lsn_offset;	/*!< the offset of the above lsn */
	ulint		n_pending_writes;/*!< number of currently pending flush
					writes for this log group */
	byte**		file_header_bufs_ptr;/*!< unaligned buffers */
	byte**		file_header_bufs;/*!< buffers for each file header
					 in the group */
#ifdef UNIV_LOG_ARCHIVE
	/*-----------------------------*/
#ifdef UNIV_LOG_ARCHIVE
	byte**		archive_file_header_bufs_ptr;/*!< unaligned buffers */
	byte**		archive_file_header_bufs;/*!< buffers for each file
					header in the group */
#endif
	ulint		archive_space_id;/*!< file space which implements
					the log group archive */
	ulint		archived_file_no;/*!< file number corresponding to
					log_sys->archived_lsn */
	ulint		archived_offset;/*!< file offset corresponding to
					log_sys->archived_lsn, 0 if we have
					not yet written to the archive file
					number archived_file_no */
	ulint		next_archived_file_no;/*!< during an archive write,
					until the write is completed, we
					store the next value for
					archived_file_no here: the write
					completion function then sets the new
					value to ..._file_no */
	ulint		next_archived_offset; /*!< like the preceding field */
#endif /* UNIV_LOG_ARCHIVE */
	/*-----------------------------*/
	ib_uint64_t	scanned_lsn;	/*!< used only in recovery: recovery scan
					succeeded up to this lsn in this log
					group */
	byte*		checkpoint_buf_ptr;/*!< unaligned checkpoint header */
	byte*		checkpoint_buf;	/*!< checkpoint header is written from
					this buffer to the group */
	UT_LIST_NODE_T(log_group_t)
			log_groups;	/*!< list of log groups */
};

/** Redo log buffer */
struct log_struct{
	byte		pad[64];	/*!< padding to prevent other memory
					update hotspots from residing on the
					same memory cache line */
	ib_uint64_t	lsn;		/*!< log sequence number */
	ulint		buf_free;	/*!< first free offset within the log
					buffer */
#ifndef UNIV_HOTBACKUP
	mutex_t		mutex;		/*!< mutex protecting the log */
#endif /* !UNIV_HOTBACKUP */
	byte*		buf_ptr;	/* unaligned log buffer */
	byte*		buf;		/*!< log buffer */
	ulint		buf_size;	/*!< log buffer size in bytes */
	ulint		max_buf_free;	/*!< recommended maximum value of
					buf_free, after which the buffer is
					flushed */
#ifdef UNIV_DEBUG
	ulint		old_buf_free;	/*!< value of buf free when log was
					last time opened; only in the debug
					version */
	ib_uint64_t	old_lsn;	/*!< value of lsn when log was
					last time opened; only in the
					debug version */
#endif
	ibool		check_flush_or_checkpoint;
					/*!< this is set to TRUE when there may
					be need to flush the log buffer, or
					preflush buffer pool pages, or make
					a checkpoint; this MUST be TRUE when
					lsn - last_checkpoint_lsn >
					max_checkpoint_age; this flag is
					peeked at by log_free_check(), which
					does not reserve the log mutex */
	UT_LIST_BASE_NODE_T(log_group_t)
			log_groups;	/*!< log groups */

#ifndef UNIV_HOTBACKUP
	/** The fields involved in the log buffer flush @{ */

	ulint		buf_next_to_write;/*!< first offset in the log buffer
					where the byte content may not exist
					written to file, e.g., the start
					offset of a log record catenated
					later; this is advanced when a flush
					operation is completed to all the log
					groups */
	ib_uint64_t	written_to_some_lsn;
					/*!< first log sequence number not yet
					written to any log group; for this to
					be advanced, it is enough that the
					write i/o has been completed for any
					one log group */
	ib_uint64_t	written_to_all_lsn;
					/*!< first log sequence number not yet
					written to some log group; for this to
					be advanced, it is enough that the
					write i/o has been completed for all
					log groups.
					Note that since InnoDB currently
					has only one log group therefore
					this value is redundant. Also it
					is possible that this value
					falls behind the
					flushed_to_disk_lsn transiently.
					It is appropriate to use either
					flushed_to_disk_lsn or
					write_lsn which are always
					up-to-date and accurate. */
	ib_uint64_t	write_lsn;	/*!< end lsn for the current running
					write */
	ulint		write_end_offset;/*!< the data in buffer has
					been written up to this offset
					when the current write ends:
					this field will then be copied
					to buf_next_to_write */
	ib_uint64_t	current_flush_lsn;/*!< end lsn for the current running
					write + flush operation */
	ib_uint64_t	flushed_to_disk_lsn;
					/*!< how far we have written the log
					AND flushed to disk */
	ulint		n_pending_writes;/*!< number of currently
					pending flushes or writes */
	/* NOTE on the 'flush' in names of the fields below: starting from
	4.0.14, we separate the write of the log file and the actual fsync()
	or other method to flush it to disk. The names below shhould really
	be 'flush_or_write'! */
	os_event_t	no_flush_event;	/*!< this event is in the reset state
					when a flush or a write is running;
					a thread should wait for this without
					owning the log mutex, but NOTE that
					to set or reset this event, the
					thread MUST own the log mutex! */
	ibool		one_flushed;	/*!< during a flush, this is
					first FALSE and becomes TRUE
					when one log group has been
					written or flushed */
	os_event_t	one_flushed_event;/*!< this event is reset when the
					flush or write has not yet completed
					for any log group; e.g., this means
					that a transaction has been committed
					when this is set; a thread should wait
					for this without owning the log mutex,
					but NOTE that to set or reset this
					event, the thread MUST own the log
					mutex! */
	ulint		n_log_ios;	/*!< number of log i/os initiated thus
					far */
	ulint		n_log_ios_old;	/*!< number of log i/o's at the
					previous printout */
	time_t		last_printout_time;/*!< when log_print was last time
					called */
	/* @} */

	/** Fields involved in checkpoints @{ */
	ulint		log_group_capacity; /*!< capacity of the log group; if
					the checkpoint age exceeds this, it is
					a serious error because it is possible
					we will then overwrite log and spoil
					crash recovery */
	ulint		max_modified_age_async;
					/*!< when this recommended
					value for lsn -
					buf_pool_get_oldest_modification()
					is exceeded, we start an
					asynchronous preflush of pool pages */
	ulint		max_modified_age_sync;
					/*!< when this recommended
					value for lsn -
					buf_pool_get_oldest_modification()
					is exceeded, we start a
					synchronous preflush of pool pages */
	ulint		adm_checkpoint_interval;
					/*!< administrator-specified checkpoint
					interval in terms of log growth in
					bytes; the interval actually used by
					the database can be smaller */
	ulint		max_checkpoint_age_async;
					/*!< when this checkpoint age
					is exceeded we start an
					asynchronous writing of a new
					checkpoint */
	ulint		max_checkpoint_age;
					/*!< this is the maximum allowed value
					for lsn - last_checkpoint_lsn when a
					new query step is started */
	ib_uint64_t	next_checkpoint_no;
					/*!< next checkpoint number */
	ib_uint64_t	last_checkpoint_lsn;
					/*!< latest checkpoint lsn */
	ib_uint64_t	next_checkpoint_lsn;
					/*!< next checkpoint lsn */
	ulint		n_pending_checkpoint_writes;
					/*!< number of currently pending
					checkpoint writes */
	rw_lock_t	checkpoint_lock;/*!< this latch is x-locked when a
					checkpoint write is running; a thread
					should wait for this without owning
					the log mutex */
#endif /* !UNIV_HOTBACKUP */
	byte*		checkpoint_buf_ptr;/* unaligned checkpoint header */
	byte*		checkpoint_buf;	/*!< checkpoint header is read to this
					buffer */
	/* @} */
#ifdef UNIV_LOG_ARCHIVE
	/** Fields involved in archiving @{ */
	ulint		archiving_state;/*!< LOG_ARCH_ON, LOG_ARCH_STOPPING
					LOG_ARCH_STOPPED, LOG_ARCH_OFF */
	ib_uint64_t	archived_lsn;	/*!< archiving has advanced to this
					lsn */
	ulint		max_archived_lsn_age_async;
					/*!< recommended maximum age of
					archived_lsn, before we start
					asynchronous copying to the archive */
	ulint		max_archived_lsn_age;
					/*!< maximum allowed age for
					archived_lsn */
	ib_uint64_t	next_archived_lsn;/*!< during an archive write,
					until the write is completed, we
					store the next value for
					archived_lsn here: the write
					completion function then sets the new
					value to archived_lsn */
	ulint		archiving_phase;/*!< LOG_ARCHIVE_READ or
					LOG_ARCHIVE_WRITE */
	ulint		n_pending_archive_ios;
					/*!< number of currently pending reads
					or writes in archiving */
	rw_lock_t	archive_lock;	/*!< this latch is x-locked when an
					archive write is running; a thread
					should wait for this without owning
					the log mutex */
	ulint		archive_buf_size;/*!< size of archive_buf */
	byte*		archive_buf;	/*!< log segment is written to the
					archive from this buffer */
	os_event_t	archiving_on;	/*!< if archiving has been stopped,
					a thread can wait for this event to
					become signaled */
	/* @} */
#endif /* UNIV_LOG_ARCHIVE */
};

#ifdef UNIV_LOG_ARCHIVE
/** Archiving state @{ */
#define LOG_ARCH_ON		71
#define LOG_ARCH_STOPPING	72
#define LOG_ARCH_STOPPING2	73
#define LOG_ARCH_STOPPED	74
#define LOG_ARCH_OFF		75
/* @} */
#endif /* UNIV_LOG_ARCHIVE */

#ifndef UNIV_NONINL
#include "log0log.ic"
#endif

#endif
/*****************************************************************************

Copyright (c) 1997, 2010, Innobase Oy. All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file include/log0recv.h
Recovery

Created 9/20/1997 Heikki Tuuri
*******************************************************/

#ifndef log0recv_h
#define log0recv_h

#include "univ.i"
#include "ut0byte.h"
#include "buf0types.h"
#include "hash0hash.h"
#include "log0log.h"
#include "srv0srv.h"
#include "api0api.h"

#ifdef UNIV_HOTBACKUP
extern ibool	recv_replay_file_ops;

/*******************************************************************//**
Reads the checkpoint info needed in hot backup.
@return	TRUE if success */
UNIV_INTERN
ibool
recv_read_cp_info_for_backup(
/*=========================*/
	const byte*	hdr,	/*!< in: buffer containing the log group
				header */
	ib_uint64_t*	lsn,	/*!< out: checkpoint lsn */
	ulint*		offset,	/*!< out: checkpoint offset in the log group */
	ulint*		fsp_limit,/*!< out: fsp limit of space 0,
				1000000000 if the database is running
				with < version 3.23.50 of InnoDB */
	ib_uint64_t*	cp_no,	/*!< out: checkpoint number */
	ib_uint64_t*	first_header_lsn);
				/*!< out: lsn of of the start of the
				first log file */
/*******************************************************************//**
Scans the log segment and n_bytes_scanned is set to the length of valid
log scanned. */
UNIV_INTERN
void
recv_scan_log_seg_for_backup(
/*=========================*/
	byte*		buf,		/*!< in: buffer containing log data */
	ulint		buf_len,	/*!< in: data length in that buffer */
	ib_uint64_t*	scanned_lsn,	/*!< in/out: lsn of buffer start,
					we return scanned lsn */
	ulint*		scanned_checkpoint_no,
					/*!< in/out: 4 lowest bytes of the
					highest scanned checkpoint number so
					far */
	ulint*		n_bytes_scanned);/*!< out: how much we were able to
					scan, smaller than buf_len if log
					data ended here */
#endif /* UNIV_HOTBACKUP */
/*******************************************************************//**
Returns TRUE if recovery is currently running.
@return	recv_recovery_on */
UNIV_INLINE
ibool
recv_recovery_is_on(void);
/*=====================*/
#ifdef UNIV_LOG_ARCHIVE
/*******************************************************************//**
Returns TRUE if recovery from backup is currently running.
@return	recv_recovery_from_backup_on */
UNIV_INLINE
ibool
recv_recovery_from_backup_is_on(void);
/*=================================*/
#endif /* UNIV_LOG_ARCHIVE */
/************************************************************************//**
Applies the hashed log records to the page, if the page lsn is less than the
lsn of a log record. This can be called when a buffer page has just been
read in, or also for a page already in the buffer pool. */
UNIV_INTERN
void
recv_recover_page_func(
/*===================*/
#ifndef UNIV_HOTBACKUP
	ibool		just_read_in,
				/*!< in: TRUE if the i/o handler calls
				this for a freshly read page */
#endif /* !UNIV_HOTBACKUP */
	buf_block_t*	block);	/*!< in/out: buffer block */
#ifndef UNIV_HOTBACKUP
/** Wrapper for recv_recover_page_func().
Applies the hashed log records to the page, if the page lsn is less than the
lsn of a log record. This can be called when a buffer page has just been
read in, or also for a page already in the buffer pool.
@param jri	in: TRUE if just read in (the i/o handler calls this for
a freshly read page)
@param block	in/out: the buffer block
*/
# define recv_recover_page(jri, block)	recv_recover_page_func(jri, block)
#else /* !UNIV_HOTBACKUP */
/** Wrapper for recv_recover_page_func().
Applies the hashed log records to the page, if the page lsn is less than the
lsn of a log record. This can be called when a buffer page has just been
read in, or also for a page already in the buffer pool.
@param jri	in: TRUE if just read in (the i/o handler calls this for
a freshly read page)
@param block	in/out: the buffer block
*/
# define recv_recover_page(jri, block)	recv_recover_page_func(block)
#endif /* !UNIV_HOTBACKUP */
/********************************************************//**
Recovers from a checkpoint. When this function returns, the database is able
to start processing of new user transactions, but the function
recv_recovery_from_checkpoint_finish should be called later to complete
the recovery and free the resources used in it.
@return	error code or DB_SUCCESS */
UNIV_INTERN
ulint
recv_recovery_from_checkpoint_start_func(
/*=====================================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
#ifdef UNIV_LOG_ARCHIVE
	ulint		type,		/*!< in: LOG_CHECKPOINT or
					LOG_ARCHIVE */
	ib_uint64_t	limit_lsn,	/*!< in: recover up to this lsn
					if possible */
#endif /* UNIV_LOG_ARCHIVE */
	ib_uint64_t	min_flushed_lsn,/*!< in: min flushed lsn from
					data files */
	ib_uint64_t	max_flushed_lsn);/*!< in: max flushed lsn from
					 data files */
#ifdef UNIV_LOG_ARCHIVE
/** Wrapper for recv_recovery_from_checkpoint_start_func().
Recovers from a checkpoint. When this function returns, the database is able
to start processing of new user transactions, but the function
recv_recovery_from_checkpoint_finish should be called later to complete
the recovery and free the resources used in it.
@param type	in: LOG_CHECKPOINT or LOG_ARCHIVE
@param lim	in: recover up to this log sequence number if possible
@param min	in: minimum flushed log sequence number from data files
@param max	in: maximum flushed log sequence number from data files
@return	error code or DB_SUCCESS */
# define recv_recovery_from_checkpoint_start(recv,type,lim,min,max)	\
	recv_recovery_from_checkpoint_start_func(recv,type,lim,min,max)
#else /* UNIV_LOG_ARCHIVE */
/** Wrapper for recv_recovery_from_checkpoint_start_func().
Recovers from a checkpoint. When this function returns, the database is able
to start processing of new user transactions, but the function
recv_recovery_from_checkpoint_finish should be called later to complete
the recovery and free the resources used in it.
@param type	ignored: LOG_CHECKPOINT or LOG_ARCHIVE
@param lim	ignored: recover up to this log sequence number if possible
@param min	in: minimum flushed log sequence number from data files
@param max	in: maximum flushed log sequence number from data files
@return	error code or DB_SUCCESS */
# define recv_recovery_from_checkpoint_start(recv,type,lim,min,max)	\
	recv_recovery_from_checkpoint_start_func(recv,min,max)
#endif /* UNIV_LOG_ARCHIVE */
/********************************************************//**
Completes recovery from a checkpoint. */
UNIV_INTERN
void
recv_recovery_from_checkpoint_finish(
/*=================================*/
	ib_recovery_t	recovery);	/*!< in: recovery flag */
/********************************************************//**
Initiates the rollback of active transactions. */
UNIV_INTERN
void
recv_recovery_rollback_active(void);
/*===============================*/
/*******************************************************//**
Scans log from a buffer and stores new log data to the parsing buffer.
Parses and hashes the log records if new data found.  Unless
UNIV_HOTBACKUP is defined, this function will apply log records
automatically when the hash table becomes full.
@return TRUE if limit_lsn has been reached, or not able to scan any
more in this log group */
UNIV_INTERN
ibool
recv_scan_log_recs(
/*===============*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	ulint		available_memory,/*!< in: we let the hash table of recs
					to grow to this size, at the maximum */
	ibool		store_to_hash,	/*!< in: TRUE if the records should be
					stored to the hash table; this is set
					to FALSE if just debug checking is
					needed */
	const byte*	buf,		/*!< in: buffer containing a log
					segment or garbage */
	ulint		len,		/*!< in: buffer length */
	ib_uint64_t	start_lsn,	/*!< in: buffer start lsn */
	ib_uint64_t*	contiguous_lsn,	/*!< in/out: it is known that all log
					groups contain contiguous log data up
					to this lsn */
	ib_uint64_t*	group_scanned_lsn);/*!< out: scanning succeeded up to
					this lsn */
/******************************************************//**
Resets the logs. The contents of log files will be lost! */
UNIV_INTERN
void
recv_reset_logs(
/*============*/
	ib_uint64_t	lsn,		/*!< in: reset to this lsn
					rounded up to be divisible by
					OS_FILE_LOG_BLOCK_SIZE, after
					which we add
					LOG_BLOCK_HDR_SIZE */
#ifdef UNIV_LOG_ARCHIVE
	ulint		arch_log_no,	/*!< in: next archived log file number */
#endif /* UNIV_LOG_ARCHIVE */
	ibool		new_logs_created);/*!< in: TRUE if resetting logs
					is done at the log creation;
					FALSE if it is done after
					archive recovery */
#ifdef UNIV_HOTBACKUP
/******************************************************//**
Creates new log files after a backup has been restored. */
UNIV_INTERN
void
recv_reset_log_files_for_backup(
/*============================*/
	const char*	log_dir,	/*!< in: log file directory path */
	ulint		n_log_files,	/*!< in: number of log files */
	ulint		log_file_size,	/*!< in: log file size */
	ib_uint64_t	lsn);		/*!< in: new start lsn, must be
					divisible by OS_FILE_LOG_BLOCK_SIZE */
#endif /* UNIV_HOTBACKUP */
/********************************************************//**
Creates the recovery system. */
UNIV_INTERN
void
recv_sys_create(void);
/*=================*/
/**********************************************************//**
Release recovery system mutexes. */
UNIV_INTERN
void
recv_sys_close(void);
/*================*/
/********************************************************//**
Frees the recovery system memory. */
UNIV_INTERN
void
recv_sys_mem_free(void);
/*====================*/
/**********************************************************//**
Release recovery system mutexes. */
UNIV_INTERN
void
recv_sys_close(void);
/*===============*/
/**********************************************************//**
Inits the recovery system for a recovery operation. */
UNIV_INTERN
void
recv_sys_init(
/*==========*/
	ulint	available_memory);	/*!< in: available memory in bytes */
#ifndef UNIV_HOTBACKUP
/**********************************************************//**
Reset the state of the recovery system variables. */
UNIV_INTERN
void
recv_sys_var_init(void);
/*===================*/
#endif /* !UNIV_HOTBACKUP */
/*******************************************************************//**
Empties the hash table of stored log records, applying them to appropriate
pages. */
UNIV_INTERN
void
recv_apply_hashed_log_recs(
/*=======================*/
	ibool	allow_ibuf);	/*!< in: if TRUE, also ibuf operations are
				allowed during the application; if FALSE,
				no ibuf operations are allowed, and after
				the application all file pages are flushed to
				disk and invalidated in buffer pool: this
				alternative means that no new log records
				can be generated during the application */
#ifdef UNIV_HOTBACKUP
/*******************************************************************//**
Applies log records in the hash table to a backup. */
UNIV_INTERN
void
recv_apply_log_recs_for_backup(void);
/*================================*/
#endif
#ifdef UNIV_LOG_ARCHIVE
/********************************************************//**
Recovers from archived log files, and also from log files, if they exist.
@return	error code or DB_SUCCESS */
UNIV_INTERN
ulint
recv_recovery_from_archive_start(
/*=============================*/
	ib_uint64_t	min_flushed_lsn,/*!< in: min flushed lsn field from the
					data files */
	ib_uint64_t	limit_lsn,	/*!< in: recover up to this lsn if
					possible */
	ulint		first_log_no);	/*!< in: number of the first archived
					log file to use in the recovery; the
					file will be searched from
					INNOBASE_LOG_ARCH_DIR specified in
					server config file */
/********************************************************//**
Completes recovery from archive. */
UNIV_INTERN
void
recv_recovery_from_archive_finish(void);
/*===================================*/
#endif /* UNIV_LOG_ARCHIVE */

/** Block of log record data */
typedef struct recv_data_struct	recv_data_t;
/** Block of log record data */
struct recv_data_struct{
	recv_data_t*	next;	/*!< pointer to the next block or NULL */
				/*!< the log record data is stored physically
				immediately after this struct, max amount
				RECV_DATA_BLOCK_SIZE bytes of it */
};

/** Stored log record struct */
typedef struct recv_struct	recv_t;
/** Stored log record struct */
struct recv_struct{
	byte		type;	/*!< log record type */
	ulint		len;	/*!< log record body length in bytes */
	recv_data_t*	data;	/*!< chain of blocks containing the log record
				body */
	ib_uint64_t	start_lsn;/*!< start lsn of the log segment written by
				the mtr which generated this log record: NOTE
				that this is not necessarily the start lsn of
				this log record */
	ib_uint64_t	end_lsn;/*!< end lsn of the log segment written by
				the mtr which generated this log record: NOTE
				that this is not necessarily the end lsn of
				this log record */
	UT_LIST_NODE_T(recv_t)
			rec_list;/*!< list of log records for this page */
};

/** States of recv_addr_struct */
enum recv_addr_state {
	/** not yet processed */
	RECV_NOT_PROCESSED,
	/** page is being read */
	RECV_BEING_READ,
	/** log records are being applied on the page */
	RECV_BEING_PROCESSED,
	/** log records have been applied on the page, or they have
	been discarded because the tablespace does not exist */
	RECV_PROCESSED
};

/** Hashed page file address struct */
typedef struct recv_addr_struct	recv_addr_t;
/** Hashed page file address struct */
struct recv_addr_struct{
	enum recv_addr_state state;
				/*!< recovery state of the page */
	ulint		space;	/*!< space id */
	ulint		page_no;/*!< page number */
	UT_LIST_BASE_NODE_T(recv_t)
			rec_list;/*!< list of log records for this page */
	hash_node_t	addr_hash;/*!< hash node in the hash bucket chain */
};

/** Recovery system data structure */
typedef struct recv_sys_struct	recv_sys_t;
/** Recovery system data structure */
struct recv_sys_struct{
#ifndef UNIV_HOTBACKUP
	mutex_t		mutex;	/*!< mutex protecting the fields apply_log_recs,
				n_addrs, and the state field in each recv_addr
				struct */
#endif /* !UNIV_HOTBACKUP */
	ibool		apply_log_recs;
				/*!< this is TRUE when log rec application to
				pages is allowed; this flag tells the
				i/o-handler if it should do log record
				application */
	ibool		apply_batch_on;
				/*!< this is TRUE when a log rec application
				batch is running */
	ib_uint64_t	lsn;	/*!< log sequence number */
	ulint		last_log_buf_size;
				/*!< size of the log buffer when the database
				last time wrote to the log */
	byte*		last_block;
				/*!< possible incomplete last recovered log
				block */
	byte*		last_block_buf_start;
				/*!< the nonaligned start address of the
				preceding buffer */
	byte*		buf;	/*!< buffer for parsing log records */
	ulint		len;	/*!< amount of data in buf */
	ib_uint64_t	parse_start_lsn;
				/*!< this is the lsn from which we were able to
				start parsing log records and adding them to
				the hash table; zero if a suitable
				start point not found yet */
	ib_uint64_t	scanned_lsn;
				/*!< the log data has been scanned up to this
				lsn */
	ulint		scanned_checkpoint_no;
				/*!< the log data has been scanned up to this
				checkpoint number (lowest 4 bytes) */
	ulint		recovered_offset;
				/*!< start offset of non-parsed log records in
				buf */
	ib_uint64_t	recovered_lsn;
				/*!< the log records have been parsed up to
				this lsn */
	ib_uint64_t	limit_lsn;/*!< recovery should be made at most
				up to this lsn */
	ibool		found_corrupt_log;
				/*!< this is set to TRUE if we during log
				scan find a corrupt log block, or a corrupt
				log record, or there is a log parsing
				buffer overflow */
#ifdef UNIV_LOG_ARCHIVE
	log_group_t*	archive_group;
				/*!< in archive recovery: the log group whose
				archive is read */
#endif /* !UNIV_LOG_ARCHIVE */
	mem_heap_t*	heap;	/*!< memory heap of log records and file
				addresses*/
	hash_table_t*	addr_hash;/*!< hash table of file addresses of pages */
	ulint		n_addrs;/*!< number of not processed hashed file
				addresses in the hash table */
};

/** The recovery system */
extern recv_sys_t*	recv_sys;

/** TRUE when applying redo log records during crash recovery; FALSE
otherwise.  Note that this is FALSE while a background thread is
rolling back incomplete transactions. */
extern ibool		recv_recovery_on;
/** If the following is TRUE, the buffer pool file pages must be invalidated
after recovery and no ibuf operations are allowed; this becomes TRUE if
the log record hash table becomes too full, and log records must be merged
to file pages already before the recovery is finished: in this case no
ibuf operations are allowed, as they could modify the pages read in the
buffer pool before the pages have been recovered to the up-to-date state.

TRUE means that recovery is running and no operations on the log files
are allowed yet: the variable name is misleading. */
extern ibool		recv_no_ibuf_operations;
/** TRUE when recv_init_crash_recovery() has been called. */
extern ibool		recv_needed_recovery;
#ifdef UNIV_DEBUG
/** TRUE if writing to the redo log (mtr_commit) is forbidden.
Protected by log_sys->mutex. */
extern ibool		recv_no_log_write;
#endif /* UNIV_DEBUG */

/** TRUE if buf_page_is_corrupted() should check if the log sequence
number (FIL_PAGE_LSN) is in the future.  Initially FALSE, and set by
recv_recovery_from_checkpoint_start_func(). */
extern ibool		recv_lsn_checks_on;
extern ib_cb_t		recv_pre_rollback_hook;
#ifdef UNIV_HOTBACKUP
/** TRUE when the redo log is being backed up */
extern ibool		recv_is_making_a_backup;
#endif /* UNIV_HOTBACKUP */
/** Maximum page number encountered in the redo log */
extern ulint		recv_max_parsed_page_no;

/** Size of the parsing buffer; it must accommodate RECV_SCAN_SIZE many
times! */
#define RECV_PARSING_BUF_SIZE	(2 * 1024 * 1024)

/** Size of block reads when the log groups are scanned forward to do a
roll-forward */
#define RECV_SCAN_SIZE		(4 * UNIV_PAGE_SIZE)

/** This many frames must be left free in the buffer pool when we scan
the log and store the scanned log records in the buffer pool: we will
use these free frames to read in pages when we start applying the
log records to the database. */
extern ulint	recv_n_pool_free_frames;

#ifndef UNIV_NONINL
#include "log0recv.ic"
#endif

#endif
/*****************************************************************************

Copyright (c) 1995, 2010, Innobase Oy. All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file include/log0log.ic
Database log

Created 12/9/1995 Heikki Tuuri
*******************************************************/

#include "os0file.h"
#include "mach0data.h"
#include "mtr0mtr.h"
#include "srv0srv.h"

/*************************************************************************//**
Acquire the log mutex. */
UNIV_INLINE
void
log_acquire(void)
/*=============*/
{
	ut_ad(!mutex_own(&log_sys->mutex));
	mutex_enter(&log_sys->mutex);
}

/*************************************************************************//**
Releases the log mutex. */
UNIV_INLINE
void
log_release(void)
/*=============*/
{
	ut_ad(mutex_own(&log_sys->mutex));
	mutex_exit(&log_sys->mutex);
}

#ifdef UNIV_LOG_DEBUG
/******************************************************//**
Checks by parsing that the catenated log segment for a single mtr is
consistent. */
UNIV_INTERN
ibool
log_check_log_recs(
/*===============*/
	const byte*	buf,		/*!< in: pointer to the start of
					the log segment in the
					log_sys->buf log buffer */
	ulint		len,		/*!< in: segment length in bytes */
	ib_uint64_t	buf_start_lsn);	/*!< in: buffer start lsn */
#endif /* UNIV_LOG_DEBUG */

/************************************************************//**
Gets a log block flush bit.
@return	TRUE if this block was the first to be written in a log flush */
UNIV_INLINE
ibool
log_block_get_flush_bit(
/*====================*/
	const byte*	log_block)	/*!< in: log block */
{
	if (LOG_BLOCK_FLUSH_BIT_MASK
	    & mach_read_from_4(log_block + LOG_BLOCK_HDR_NO)) {

		return(TRUE);
	}

	return(FALSE);
}

/************************************************************//**
Sets the log block flush bit. */
UNIV_INLINE
void
log_block_set_flush_bit(
/*====================*/
	byte*	log_block,	/*!< in/out: log block */
	ibool	val)		/*!< in: value to set */
{
	ulint	field;

	field = mach_read_from_4(log_block + LOG_BLOCK_HDR_NO);

	if (val) {
		field = field | LOG_BLOCK_FLUSH_BIT_MASK;
	} else {
		field = field & ~LOG_BLOCK_FLUSH_BIT_MASK;
	}

	mach_write_to_4(log_block + LOG_BLOCK_HDR_NO, field);
}

/************************************************************//**
Gets a log block number stored in the header.
@return	log block number stored in the block header */
UNIV_INLINE
ulint
log_block_get_hdr_no(
/*=================*/
	const byte*	log_block)	/*!< in: log block */
{
	return(~LOG_BLOCK_FLUSH_BIT_MASK
	       & mach_read_from_4(log_block + LOG_BLOCK_HDR_NO));
}

/************************************************************//**
Sets the log block number stored in the header; NOTE that this must be set
before the flush bit! */
UNIV_INLINE
void
log_block_set_hdr_no(
/*=================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	n)		/*!< in: log block number: must be > 0 and
				< LOG_BLOCK_FLUSH_BIT_MASK */
{
	ut_ad(n > 0);
	ut_ad(n < LOG_BLOCK_FLUSH_BIT_MASK);

	mach_write_to_4(log_block + LOG_BLOCK_HDR_NO, n);
}

/************************************************************//**
Gets a log block data length.
@return	log block data length measured as a byte offset from the block start */
UNIV_INLINE
ulint
log_block_get_data_len(
/*===================*/
	const byte*	log_block)	/*!< in: log block */
{
	return(mach_read_from_2(log_block + LOG_BLOCK_HDR_DATA_LEN));
}

/************************************************************//**
Sets the log block data length. */
UNIV_INLINE
void
log_block_set_data_len(
/*===================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	len)		/*!< in: data length */
{
	mach_write_to_2(log_block + LOG_BLOCK_HDR_DATA_LEN, len);
}

/************************************************************//**
Gets a log block first mtr log record group offset.
@return first mtr log record group byte offset from the block start, 0
if none */
UNIV_INLINE
ulint
log_block_get_first_rec_group(
/*==========================*/
	const byte*	log_block)	/*!< in: log block */
{
	return(mach_read_from_2(log_block + LOG_BLOCK_FIRST_REC_GROUP));
}

/************************************************************//**
Sets the log block first mtr log record group offset. */
UNIV_INLINE
void
log_block_set_first_rec_group(
/*==========================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	offset)		/*!< in: offset, 0 if none */
{
	mach_write_to_2(log_block + LOG_BLOCK_FIRST_REC_GROUP, offset);
}

/************************************************************//**
Gets a log block checkpoint number field (4 lowest bytes).
@return	checkpoint no (4 lowest bytes) */
UNIV_INLINE
ulint
log_block_get_checkpoint_no(
/*========================*/
	const byte*	log_block)	/*!< in: log block */
{
	return(mach_read_from_4(log_block + LOG_BLOCK_CHECKPOINT_NO));
}

/************************************************************//**
Sets a log block checkpoint number field (4 lowest bytes). */
UNIV_INLINE
void
log_block_set_checkpoint_no(
/*========================*/
	byte*		log_block,	/*!< in/out: log block */
	ib_uint64_t	no)		/*!< in: checkpoint no */
{
	mach_write_to_4(log_block + LOG_BLOCK_CHECKPOINT_NO, (ulint) no);
}

/************************************************************//**
Converts a lsn to a log block number.
@return	log block number, it is > 0 and <= 1G */
UNIV_INLINE
ulint
log_block_convert_lsn_to_no(
/*========================*/
	ib_uint64_t	lsn)	/*!< in: lsn of a byte within the block */
{
	return(((ulint) (lsn / OS_FILE_LOG_BLOCK_SIZE) & 0x3FFFFFFFUL) + 1);
}

/************************************************************//**
Calculates the checksum for a log block.
@return	checksum */
UNIV_INLINE
ulint
log_block_calc_checksum(
/*====================*/
	const byte*	block)	/*!< in: log block */
{
	ulint	sum;
	ulint	sh;
	ulint	i;

	sum = 1;
	sh = 0;

	for (i = 0; i < OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE; i++) {
		ulint	b = (ulint) block[i];
		sum &= 0x7FFFFFFFUL;
		sum += b;
		sum += b << sh;
		sh++;
		if (sh > 24) {
			sh = 0;
		}
	}

	return(sum);
}

/************************************************************//**
Gets a log block checksum field value.
@return	checksum */
UNIV_INLINE
ulint
log_block_get_checksum(
/*===================*/
	const byte*	log_block)	/*!< in: log block */
{
	return(mach_read_from_4(log_block + OS_FILE_LOG_BLOCK_SIZE
				- LOG_BLOCK_CHECKSUM));
}

/************************************************************//**
Sets a log block checksum field value. */
UNIV_INLINE
void
log_block_set_checksum(
/*===================*/
	byte*	log_block,	/*!< in/out: log block */
	ulint	checksum)	/*!< in: checksum */
{
	mach_write_to_4(log_block + OS_FILE_LOG_BLOCK_SIZE
			- LOG_BLOCK_CHECKSUM,
			checksum);
}

/************************************************************//**
Initializes a log block in the log buffer. */
UNIV_INLINE
void
log_block_init(
/*===========*/
	byte*		log_block,	/*!< in: pointer to the log buffer */
	ib_uint64_t	lsn)		/*!< in: lsn within the log block */
{
	ulint	no;

	ut_ad(mutex_own(&(log_sys->mutex)));

	no = log_block_convert_lsn_to_no(lsn);

	log_block_set_hdr_no(log_block, no);

	log_block_set_data_len(log_block, LOG_BLOCK_HDR_SIZE);
	log_block_set_first_rec_group(log_block, 0);
}

/************************************************************//**
Initializes a log block in the log buffer in the old format, where there
was no checksum yet. */
UNIV_INLINE
void
log_block_init_in_old_format(
/*=========================*/
	byte*		log_block,	/*!< in: pointer to the log buffer */
	ib_uint64_t	lsn)		/*!< in: lsn within the log block */
{
	ulint	no;

	ut_ad(mutex_own(&(log_sys->mutex)));

	no = log_block_convert_lsn_to_no(lsn);

	log_block_set_hdr_no(log_block, no);
	mach_write_to_4(log_block + OS_FILE_LOG_BLOCK_SIZE
			- LOG_BLOCK_CHECKSUM, no);
	log_block_set_data_len(log_block, LOG_BLOCK_HDR_SIZE);
	log_block_set_first_rec_group(log_block, 0);
}

#ifndef UNIV_HOTBACKUP
/************************************************************//**
Writes to the log the string given. The log must be released with
log_release().
@return	end lsn of the log record, zero if did not succeed */
UNIV_INLINE
ib_uint64_t
log_reserve_and_write_fast(
/*=======================*/
	const void*	str,	/*!< in: string */
	ulint		len,	/*!< in: string length */
	ib_uint64_t*	start_lsn)/*!< out: start lsn of the log record */
{
	ulint		data_len;
#ifdef UNIV_LOG_LSN_DEBUG
	/* length of the LSN pseudo-record */
	ulint		lsn_len;
#endif /* UNIV_LOG_LSN_DEBUG */

#ifdef UNIV_LOG_LSN_DEBUG
	lsn_len = 1
		+ mach_get_compressed_size(log_sys->lsn >> 32)
		+ mach_get_compressed_size(log_sys->lsn & 0xFFFFFFFFUL);
#endif /* UNIV_LOG_LSN_DEBUG */

	data_len = len
#ifdef UNIV_LOG_LSN_DEBUG
		+ lsn_len
#endif /* UNIV_LOG_LSN_DEBUG */
		+ log_sys->buf_free % OS_FILE_LOG_BLOCK_SIZE;

	if (data_len >= OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE) {

		/* The string does not fit within the current log block
		or the log block would become full */

		return(0);
	}

	*start_lsn = log_sys->lsn;

#ifdef UNIV_LOG_LSN_DEBUG
	{
		/* Write the LSN pseudo-record. */
		byte* b = &log_sys->buf[log_sys->buf_free];
		*b++ = MLOG_LSN | (MLOG_SINGLE_REC_FLAG & *(const byte*) str);
		/* Write the LSN in two parts,
		as a pseudo page number and space id. */
		b += mach_write_compressed(b, log_sys->lsn >> 32);
		b += mach_write_compressed(b, log_sys->lsn & 0xFFFFFFFFUL);
		ut_a(b - lsn_len == &log_sys->buf[log_sys->buf_free]);

		memcpy(b, str, len);
		len += lsn_len;
	}
#else /* UNIV_LOG_LSN_DEBUG */
	memcpy(log_sys->buf + log_sys->buf_free, str, len);
#endif /* UNIV_LOG_LSN_DEBUG */

	log_block_set_data_len((byte*) ut_align_down(log_sys->buf
						     + log_sys->buf_free,
						     OS_FILE_LOG_BLOCK_SIZE),
			       data_len);
#ifdef UNIV_LOG_DEBUG
	log_sys->old_buf_free = log_sys->buf_free;
	log_sys->old_lsn = log_sys->lsn;
#endif
	log_sys->buf_free += len;

	ut_ad(log_sys->buf_free <= log_sys->buf_size);

	log_sys->lsn += len;

#ifdef UNIV_LOG_DEBUG
	log_check_log_recs(log_sys->buf + log_sys->old_buf_free,
			   log_sys->buf_free - log_sys->old_buf_free,
			   log_sys->old_lsn);
#endif

	return(log_sys->lsn);
}

/************************************************************//**
Gets the current lsn.
@return	current lsn */
UNIV_INLINE
ib_uint64_t
log_get_lsn(void)
/*=============*/
{
	ib_uint64_t	lsn;

	log_acquire();

	lsn = log_sys->lsn;

	log_release();

	return(lsn);
}

/****************************************************************
Gets the log group capacity. It is OK to read the value without
holding log_sys->mutex because it is constant.
@return	log group capacity */
UNIV_INLINE
ulint
log_get_capacity(void)
/*==================*/
{
	return(log_sys->log_group_capacity);
}

/***********************************************************************//**
Checks if there is need for a log buffer flush or a new checkpoint, and does
this if yes. Any database operation should call this when it has modified
more than about 4 pages. NOTE that this function may only be called when the
OS thread owns no synchronization objects except the dictionary mutex. */
UNIV_INLINE
void
log_free_check(void)
/*================*/
{
	/* ut_ad(sync_thread_levels_empty()); */

	if (log_sys->check_flush_or_checkpoint) {

		log_check_margins();
	}
}
#endif /* !UNIV_HOTBACKUP */
/*****************************************************************************

Copyright (c) 1997, 2009, Innobase Oy. All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file include/log0recv.ic
Recovery

Created 9/20/1997 Heikki Tuuri
*******************************************************/

#include "univ.i"

/*******************************************************************//**
Returns TRUE if recovery is currently running.
@return	recv_recovery_on */
UNIV_INLINE
ibool
recv_recovery_is_on(void)
/*=====================*/
{
	return(UNIV_UNLIKELY(recv_recovery_on));
}

#ifdef UNIV_LOG_ARCHIVE
/** TRUE when applying redo log records from an archived log file */
extern ibool	recv_recovery_from_backup_on;

/*******************************************************************//**
Returns TRUE if recovery from backup is currently running.
@return	recv_recovery_from_backup_on */
UNIV_INLINE
ibool
recv_recovery_from_backup_is_on(void)
/*=================================*/
{
	return(recv_recovery_from_backup_on);
}
#endif /* UNIV_LOG_ARCHIVE */


=== IMPLEMENTATION ===

/*****************************************************************************

Copyright (c) 1995, 2010, Innobase Oy. All Rights Reserved.
Copyright (c) 2009, Google Inc.

Portions of this file contain modifications contributed and copyrighted by
Google, Inc. Those modifications are gratefully acknowledged and are described
briefly in the InnoDB documentation. The contributions by Google are
incorporated with their permission, and subject to the conditions contained in
the file COPYING.Google.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file log/log0log.c
Database log

Created 12/9/1995 Heikki Tuuri
*******************************************************/

#include "log0log.h"

#ifdef UNIV_NONINL
#include "log0log.ic"
#endif

#ifndef UNIV_HOTBACKUP
#include "mem0mem.h"
#include "buf0buf.h"
#include "buf0flu.h"
#include "srv0srv.h"
#include "log0recv.h"
#include "fil0fil.h"
#include "dict0boot.h"
#include "srv0srv.h"
#include "srv0start.h"
#include "trx0sys.h"
#include "trx0trx.h"

/*
General philosophy of InnoDB redo-logs:

1) Every change to a contents of a data page must be done
through mtr, which in mtr_commit() writes log records
to the InnoDB redo log.

2) Normally these changes are performed using a mlog_write_ulint()
or similar function.

3) In some page level operations only a code number of a
c-function and its parameters are written to the log to
reduce the size of the log.

  3a) You should not add parameters to these kind of functions
  (e.g. trx_undo_header_create(), trx_undo_insert_header_reuse())

  3b) You should not add such functionality which either change
  working when compared with the old or are dependent on data
  outside of the page. These kind of functions should implement
  self-contained page transformation and it should be unchanged
  if you don't have very essential reasons to change log
  semantics or format.

*/

/* Current free limit of space 0; protected by the log sys mutex; 0 means
uninitialized */
UNIV_INTERN ulint	log_fsp_current_free_limit		= 0;

/* Global log system variable */
UNIV_INTERN log_t*	log_sys	= NULL;

#ifdef UNIV_DEBUG
UNIV_INTERN ibool	log_do_write = TRUE;
#endif /* UNIV_DEBUG */

/* These control how often we print warnings if the last checkpoint is too
old */
UNIV_INTERN ibool	log_has_printed_chkp_warning = FALSE;
UNIV_INTERN time_t	log_last_warning_time;

#ifdef UNIV_LOG_ARCHIVE
/* Pointer to this variable is used as the i/o-message when we do i/o to an
archive */
UNIV_INTERN byte	log_archive_io;
#endif /* UNIV_LOG_ARCHIVE */

/* A margin for free space in the log buffer before a log entry is catenated */
#define LOG_BUF_WRITE_MARGIN	(4 * OS_FILE_LOG_BLOCK_SIZE)

/* Margins for free space in the log buffer after a log entry is catenated */
#define LOG_BUF_FLUSH_RATIO	2
#define LOG_BUF_FLUSH_MARGIN	(LOG_BUF_WRITE_MARGIN + 4 * UNIV_PAGE_SIZE)

/* Margin for the free space in the smallest log group, before a new query
step which modifies the database, is started */

#define LOG_CHECKPOINT_FREE_PER_THREAD	(4 * UNIV_PAGE_SIZE)
#define LOG_CHECKPOINT_EXTRA_FREE	(8 * UNIV_PAGE_SIZE)

/* This parameter controls asynchronous making of a new checkpoint; the value
should be bigger than LOG_POOL_PREFLUSH_RATIO_SYNC */

#define LOG_POOL_CHECKPOINT_RATIO_ASYNC	32

/* This parameter controls synchronous preflushing of modified buffer pages */
#define LOG_POOL_PREFLUSH_RATIO_SYNC	16

/* The same ratio for asynchronous preflushing; this value should be less than
the previous */
#define LOG_POOL_PREFLUSH_RATIO_ASYNC	8

/* Extra margin, in addition to one log file, used in archiving */
#define LOG_ARCHIVE_EXTRA_MARGIN	(4 * UNIV_PAGE_SIZE)

/* This parameter controls asynchronous writing to the archive */
#define LOG_ARCHIVE_RATIO_ASYNC		16

/* Codes used in unlocking flush latches */
#define LOG_UNLOCK_NONE_FLUSHED_LOCK	1
#define LOG_UNLOCK_FLUSH_LOCK		2

/* States of an archiving operation */
#define	LOG_ARCHIVE_READ	1
#define	LOG_ARCHIVE_WRITE	2

/******************************************************//**
Completes a checkpoint write i/o to a log file. */
UNIV_STATIC
void
log_io_complete_checkpoint(void);
/*============================*/
#ifdef UNIV_LOG_ARCHIVE
/******************************************************//**
Completes an archiving i/o. */
UNIV_STATIC
void
log_io_complete_archive(void);
/*=========================*/
#endif /* UNIV_LOG_ARCHIVE */

/****************************************************************//**
Reset the variables. */
UNIV_INTERN
void
log_var_init(void)
/*==============*/
{
	log_fsp_current_free_limit = 0;
	log_sys	= NULL;

#ifdef UNIV_DEBUG
	log_do_write = TRUE;
	log_debug_writes = FALSE;
#endif /* UNIV_DEBUG */

	log_has_printed_chkp_warning = FALSE;
	log_last_warning_time = 0;

#ifdef UNIV_LOG_ARCHIVE
	log_archive_io = 0;
#endif /* UNIV_LOG_ARCHIVE */
}

/********************************************************************
Sets the global variable log_fsp_current_free_limit. Also makes a checkpoint,
so that we know that the limit has been written to a log checkpoint field
on disk. */
UNIV_INTERN
void
log_fsp_current_free_limit_set_and_checkpoint(
/*==========================================*/
	ulint	limit)	/*!< in: limit to set */
{
	ibool	success;

	log_acquire();

	log_fsp_current_free_limit = limit;

	log_release();

	/* Try to make a synchronous checkpoint */

	success = FALSE;

	while (!success) {
		success = log_checkpoint(TRUE, TRUE);
	}
}

/****************************************************************//**
Returns the oldest modified block lsn in the pool, or log_sys->lsn if none
exists.
@return	LSN of oldest modification */
UNIV_STATIC
ib_uint64_t
log_buf_pool_get_oldest_modification(void)
/*======================================*/
{
	ib_uint64_t	lsn;

	ut_ad(mutex_own(&(log_sys->mutex)));

	lsn = buf_pool_get_oldest_modification();

	if (!lsn) {

		lsn = log_sys->lsn;
	}

	return(lsn);
}

/************************************************************//**
Opens the log for log_write_low. The log must be closed with log_close and
released with log_release.
@return	start lsn of the log record */
UNIV_INTERN
ib_uint64_t
log_reserve_and_open(
/*=================*/
	ulint	len)	/*!< in: length of data to be catenated */
{
	log_t*	log			= log_sys;
	ulint	len_upper_limit;
#ifdef UNIV_LOG_ARCHIVE
	ulint	archived_lsn_age;
	ulint	dummy;
#endif /* UNIV_LOG_ARCHIVE */
#ifdef UNIV_DEBUG
	ulint	count			= 0;
#endif /* UNIV_DEBUG */

	ut_a(len < log->buf_size / 2);
loop:
	log_acquire();
	ut_ad(!recv_no_log_write);

	/* Calculate an upper limit for the space the string may take in the
	log buffer */

	len_upper_limit = LOG_BUF_WRITE_MARGIN + (5 * len) / 4;

	if (log->buf_free + len_upper_limit > log->buf_size) {

		log_release();

		/* Not enough free space, do a syncronous flush of the log
		buffer */

		log_buffer_flush_to_disk();

		srv_log_waits++;

		ut_ad(++count < 50);

		goto loop;
	}

#ifdef UNIV_LOG_ARCHIVE
	if (log->archiving_state != LOG_ARCH_OFF) {

		archived_lsn_age = log->lsn - log->archived_lsn;
		if (archived_lsn_age + len_upper_limit
		    > log->max_archived_lsn_age) {
			/* Not enough free archived space in log groups: do a
			synchronous archive write batch: */

			log_release();

			ut_ad(len_upper_limit <= log->max_archived_lsn_age);

			log_archive_do(TRUE, &dummy);

			ut_ad(++count < 50);

			goto loop;
		}
	}
#endif /* UNIV_LOG_ARCHIVE */

#ifdef UNIV_LOG_DEBUG
	log->old_buf_free = log->buf_free;
	log->old_lsn = log->lsn;
#endif
	return(log->lsn);
}

/************************************************************//**
Writes to the log the string given. It is assumed that the caller holds the
log mutex. */
UNIV_INTERN
void
log_write_low(
/*==========*/
	byte*	str,		/*!< in: string */
	ulint	str_len)	/*!< in: string length */
{
	log_t*	log	= log_sys;
	ulint	len;
	ulint	data_len;
	byte*	log_block;

	ut_ad(mutex_own(&(log->mutex)));
part_loop:
	ut_ad(!recv_no_log_write);
	/* Calculate a part length */

	data_len = (log->buf_free % OS_FILE_LOG_BLOCK_SIZE) + str_len;

	if (data_len <= OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE) {

		/* The string fits within the current log block */

		len = str_len;
	} else {
		data_len = OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE;

		len = OS_FILE_LOG_BLOCK_SIZE
			- (log->buf_free % OS_FILE_LOG_BLOCK_SIZE)
			- LOG_BLOCK_TRL_SIZE;
	}

	ut_memcpy(log->buf + log->buf_free, str, len);

	str_len -= len;
	str = str + len;

	log_block = ut_align_down(log->buf + log->buf_free,
				  OS_FILE_LOG_BLOCK_SIZE);
	log_block_set_data_len(log_block, data_len);

	if (data_len == OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE) {
		/* This block became full */
		log_block_set_data_len(log_block, OS_FILE_LOG_BLOCK_SIZE);
		log_block_set_checkpoint_no(log_block,
					    log_sys->next_checkpoint_no);
		len += LOG_BLOCK_HDR_SIZE + LOG_BLOCK_TRL_SIZE;

		log->lsn += len;

		/* Initialize the next block header */
		log_block_init(log_block + OS_FILE_LOG_BLOCK_SIZE, log->lsn);
	} else {
		log->lsn += len;
	}

	log->buf_free += len;

	ut_ad(log->buf_free <= log->buf_size);

	if (str_len > 0) {
		goto part_loop;
	}

	srv_log_write_requests++;
}

/************************************************************//**
Closes the log.
@return	lsn */
UNIV_INTERN
ib_uint64_t
log_close(
/*======*/
	ib_recovery_t	recovery)	/*!< in: recovery flag */
{
	byte*		log_block;
	ulint		first_rec_group;
	ib_uint64_t	oldest_lsn;
	ib_uint64_t	lsn;
	log_t*		log	= log_sys;
	ib_uint64_t	checkpoint_age;

	ut_ad(mutex_own(&(log->mutex)));
	ut_ad(!recv_no_log_write);

	lsn = log->lsn;

	log_block = ut_align_down(log->buf + log->buf_free,
				  OS_FILE_LOG_BLOCK_SIZE);
	first_rec_group = log_block_get_first_rec_group(log_block);

	if (first_rec_group == 0) {
		/* We initialized a new log block which was not written
		full by the current mtr: the next mtr log record group
		will start within this block at the offset data_len */

		log_block_set_first_rec_group(
			log_block, log_block_get_data_len(log_block));
	}

	if (log->buf_free > log->max_buf_free) {

		log->check_flush_or_checkpoint = TRUE;
	}

	checkpoint_age = lsn - log->last_checkpoint_lsn;

	if (checkpoint_age >= log->log_group_capacity) {
		/* TODO: split btr_store_big_rec_extern_fields() into small
		steps so that we can release all latches in the middle, and
		call log_free_check() to ensure we never write over log written
		after the latest checkpoint. In principle, we should split all
		big_rec operations, but other operations are smaller. */

		if (!log_has_printed_chkp_warning
		    || difftime(time(NULL), log_last_warning_time) > 15) {

			log_has_printed_chkp_warning = TRUE;
			log_last_warning_time = time(NULL);

			ut_print_timestamp(ib_stream);
			ib_logger(ib_stream,
				"  InnoDB: ERROR: the age of the last"
				" checkpoint is %lu,\n"
				"InnoDB: which exceeds the log group"
				" capacity %lu.\n"
				"InnoDB: If you are using big"
				" BLOB or TEXT rows, you must set the\n"
				"InnoDB: combined size of log files"
				" at least 10 times bigger than the\n"
				"InnoDB: largest such row.\n",
				(ulong) checkpoint_age,
				(ulong) log->log_group_capacity);
		}
	}

	if (checkpoint_age <= log->max_modified_age_async) {

		goto function_exit;
	}

	oldest_lsn = buf_pool_get_oldest_modification();

	if (!oldest_lsn
	    || lsn - oldest_lsn > log->max_modified_age_async
	    || checkpoint_age > log->max_checkpoint_age_async) {

		log->check_flush_or_checkpoint = TRUE;
	}
function_exit:

#ifdef UNIV_LOG_DEBUG
	log_check_log_recs(recovery, log->buf + log->old_buf_free,
			   log->buf_free - log->old_buf_free, log->old_lsn);
#endif

	return(lsn);
}

#ifdef UNIV_LOG_ARCHIVE
/******************************************************//**
Pads the current log block full with dummy log records. Used in producing
consistent archived log files. */
UNIV_STATIC
void
log_pad_current_log_block(
/*======================*/
	ib_recovery_t	recovery)	/*!< in: recovery flag */
{
	byte		b		= MLOG_DUMMY_RECORD;
	ulint		pad_length;
	ulint		i;
	ib_uint64_t	lsn;

	/* We retrieve lsn only because otherwise gcc crashed on HP-UX */
	lsn = log_reserve_and_open(OS_FILE_LOG_BLOCK_SIZE);

	pad_length = OS_FILE_LOG_BLOCK_SIZE
		- (log_sys->buf_free % OS_FILE_LOG_BLOCK_SIZE)
		- LOG_BLOCK_TRL_SIZE;

	for (i = 0; i < pad_length; i++) {
		log_write_low(&b, 1);
	}

	lsn = log_sys->lsn;

	log_close(recovery);
	log_release();

	ut_a(lsn % OS_FILE_LOG_BLOCK_SIZE == LOG_BLOCK_HDR_SIZE);
}
#endif /* UNIV_LOG_ARCHIVE */

/******************************************************//**
Calculates the data capacity of a log group, when the log file headers are not
included.
@return	capacity in bytes */
UNIV_INTERN
ulint
log_group_get_capacity(
/*===================*/
	const log_group_t*	group)	/*!< in: log group */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	return((group->file_size - LOG_FILE_HDR_SIZE) * group->n_files);
}

/******************************************************//**
Calculates the offset within a log group, when the log file headers are not
included.
@return	size offset (<= offset) */
UNIV_INLINE
ulint
log_group_calc_size_offset(
/*=======================*/
	ulint			offset,	/*!< in: real offset within the
					log group */
	const log_group_t*	group)	/*!< in: log group */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	return(offset - LOG_FILE_HDR_SIZE * (1 + offset / group->file_size));
}

/******************************************************//**
Calculates the offset within a log group, when the log file headers are
included.
@return	real offset (>= offset) */
UNIV_INLINE
ulint
log_group_calc_real_offset(
/*=======================*/
	ulint			offset,	/*!< in: size offset within the
					log group */
	const log_group_t*	group)	/*!< in: log group */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	return(offset + LOG_FILE_HDR_SIZE
	       * (1 + offset / (group->file_size - LOG_FILE_HDR_SIZE)));
}

/******************************************************//**
Calculates the offset of an lsn within a log group.
@return	offset within the log group */
UNIV_STATIC
ulint
log_group_calc_lsn_offset(
/*======================*/
	ib_uint64_t		lsn,	/*!< in: lsn, must be within 4 GB of
					group->lsn */
	const log_group_t*	group)	/*!< in: log group */
{
	ib_uint64_t	gr_lsn;
	ib_int64_t	gr_lsn_size_offset;
	ib_int64_t	difference;
	ib_int64_t	group_size;
	ib_int64_t	offset;

	ut_ad(mutex_own(&(log_sys->mutex)));

	/* If total log file size is > 2 GB we can easily get overflows
	with 32-bit integers. Use 64-bit integers instead. */

	gr_lsn = group->lsn;

	gr_lsn_size_offset = (ib_int64_t)
		log_group_calc_size_offset(group->lsn_offset, group);

	group_size = (ib_int64_t) log_group_get_capacity(group);

	if (lsn >= gr_lsn) {

		difference = (ib_int64_t) (lsn - gr_lsn);
	} else {
		difference = (ib_int64_t) (gr_lsn - lsn);

		difference = difference % group_size;

		difference = group_size - difference;
	}

	offset = (gr_lsn_size_offset + difference) % group_size;

	ut_a(offset < (((ib_int64_t) 1) << 32)); /* offset must be < 4 GB */

	/* ib_logger(ib_stream,
	"Offset is %lu gr_lsn_offset is %lu difference is %lu\n",
	(ulint)offset,(ulint)gr_lsn_size_offset, (ulint)difference);
	*/

	return(log_group_calc_real_offset((ulint)offset, group));
}
#endif /* !UNIV_HOTBACKUP */

#ifdef UNIV_DEBUG
UNIV_INTERN ibool	log_debug_writes = FALSE;
#endif /* UNIV_DEBUG */

/*******************************************************************//**
Calculates where in log files we find a specified lsn.
@return	log file number */
UNIV_INTERN
ulint
log_calc_where_lsn_is(
/*==================*/
	ib_int64_t*	log_file_offset,	/*!< out: offset in that file
						(including the header) */
	ib_uint64_t	first_header_lsn,	/*!< in: first log file start
						lsn */
	ib_uint64_t	lsn,			/*!< in: lsn whose position to
						determine */
	ulint		n_log_files,		/*!< in: total number of log
						files */
	ib_int64_t	log_file_size)		/*!< in: log file size
						(including the header) */
{
	ib_int64_t	capacity	= log_file_size - LOG_FILE_HDR_SIZE;
	ulint		file_no;
	ib_int64_t	add_this_many;

	if (lsn < first_header_lsn) {
		add_this_many = 1 + (first_header_lsn - lsn)
			/ (capacity * (ib_int64_t)n_log_files);
		lsn += add_this_many
			* capacity * (ib_int64_t)n_log_files;
	}

	ut_a(lsn >= first_header_lsn);

	file_no = ((ulint)((lsn - first_header_lsn) / capacity))
		% n_log_files;
	*log_file_offset = (lsn - first_header_lsn) % capacity;

	*log_file_offset = *log_file_offset + LOG_FILE_HDR_SIZE;

	return(file_no);
}

#ifndef UNIV_HOTBACKUP
/********************************************************//**
Sets the field values in group to correspond to a given lsn. For this function
to work, the values must already be correctly initialized to correspond to
some lsn, for instance, a checkpoint lsn. */
UNIV_INTERN
void
log_group_set_fields(
/*=================*/
	log_group_t*	group,	/*!< in/out: group */
	ib_uint64_t	lsn)	/*!< in: lsn for which the values should be
				set */
{
	group->lsn_offset = log_group_calc_lsn_offset(lsn, group);
	group->lsn = lsn;
}

/*****************************************************************//**
Calculates the recommended highest values for lsn - last_checkpoint_lsn,
lsn - buf_get_oldest_modification(), and lsn - max_archive_lsn_age.
@return error value FALSE if the smallest log group is too small to
accommodate the number of OS threads in the database server */
UNIV_STATIC
ibool
log_calc_max_ages(void)
/*===================*/
{
	log_group_t*	group;
	ulint		margin;
	ulint		free;
	ibool		success		= TRUE;
	ulint		smallest_capacity;
	ulint		archive_margin;
	ulint		smallest_archive_margin;

	log_acquire();

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	ut_ad(group);

	smallest_capacity = ULINT_MAX;
	smallest_archive_margin = ULINT_MAX;

	while (group) {
		if (log_group_get_capacity(group) < smallest_capacity) {

			smallest_capacity = log_group_get_capacity(group);
		}

		archive_margin = log_group_get_capacity(group)
			- (group->file_size - LOG_FILE_HDR_SIZE)
			- LOG_ARCHIVE_EXTRA_MARGIN;

		if (archive_margin < smallest_archive_margin) {

			smallest_archive_margin = archive_margin;
		}

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	/* Add extra safety */
	smallest_capacity = smallest_capacity - smallest_capacity / 10;

	/* For each OS thread we must reserve so much free space in the
	smallest log group that it can accommodate the log entries produced
	by single query steps: running out of free log space is a serious
	system error which requires rebooting the database. */

	free = LOG_CHECKPOINT_FREE_PER_THREAD * 10 + LOG_CHECKPOINT_EXTRA_FREE;
	if (free >= smallest_capacity / 2) {
		success = FALSE;

		goto failure;
	} else {
		margin = smallest_capacity - free;
	}

	margin = ut_min(margin, log_sys->adm_checkpoint_interval);

	margin = margin - margin / 10;	/* Add still some extra safety */

	log_sys->log_group_capacity = smallest_capacity;

	log_sys->max_modified_age_async = margin
		- margin / LOG_POOL_PREFLUSH_RATIO_ASYNC;
	log_sys->max_modified_age_sync = margin
		- margin / LOG_POOL_PREFLUSH_RATIO_SYNC;

	log_sys->max_checkpoint_age_async = margin - margin
		/ LOG_POOL_CHECKPOINT_RATIO_ASYNC;
	log_sys->max_checkpoint_age = margin;

#ifdef UNIV_LOG_ARCHIVE
	log_sys->max_archived_lsn_age = smallest_archive_margin;

	log_sys->max_archived_lsn_age_async = smallest_archive_margin
		- smallest_archive_margin / LOG_ARCHIVE_RATIO_ASYNC;
#endif /* UNIV_LOG_ARCHIVE */
failure:
	log_release();

	if (!success) {
		ib_logger(ib_stream,
			"InnoDB: Error: ib_logfiles are too small"
			" for thread_concurrency %lu.\n"
			"InnoDB: The combined size of ib_logfiles"
			" should be bigger than\n"
			"InnoDB: 200 kB.\n"
			"InnoDB: To get the server to start up, set"
			" thread_concurrency variable\n"
			"InnoDB: to a lower value, for example, to 8."
			" After an ERROR-FREE shutdown\n"
			"InnoDB: of the server you can adjust the size of"
			" ib_logfiles, as explained on\n"
			"InnoDB: the InnoDB website."
			"InnoDB: Cannot continue operation."
			" Calling exit(1).\n");

		exit(1);
	}

	return(success);
}

/******************************************************//**
Initializes the log. */
UNIV_INTERN
void
innobase_log_init(void)
/*===================*/
{
	log_sys = mem_alloc(sizeof(log_t));

	mutex_create(&log_sys->mutex, SYNC_LOG);

	log_acquire();

	/* Start the lsn from one log block from zero: this way every
	log record has a start lsn != zero, a fact which we will use */

	log_sys->lsn = LOG_START_LSN;

	ut_a(LOG_BUFFER_SIZE >= 16 * OS_FILE_LOG_BLOCK_SIZE);
	ut_a(LOG_BUFFER_SIZE >= 4 * UNIV_PAGE_SIZE);

	log_sys->buf_ptr = mem_alloc(LOG_BUFFER_SIZE + OS_FILE_LOG_BLOCK_SIZE);
	log_sys->buf = ut_align(log_sys->buf_ptr, OS_FILE_LOG_BLOCK_SIZE);

	log_sys->buf_size = LOG_BUFFER_SIZE;

	memset(log_sys->buf, '\0', LOG_BUFFER_SIZE);

	log_sys->max_buf_free = log_sys->buf_size / LOG_BUF_FLUSH_RATIO
		- LOG_BUF_FLUSH_MARGIN;
	log_sys->check_flush_or_checkpoint = TRUE;
	UT_LIST_INIT(log_sys->log_groups);

	log_sys->n_log_ios = 0;

	log_sys->n_log_ios_old = log_sys->n_log_ios;
	log_sys->last_printout_time = time(NULL);
	/*----------------------------*/

	log_sys->buf_next_to_write = 0;

	log_sys->write_lsn = 0;
	log_sys->current_flush_lsn = 0;
	log_sys->flushed_to_disk_lsn = 0;

	log_sys->written_to_some_lsn = log_sys->lsn;
	log_sys->written_to_all_lsn = log_sys->lsn;

	log_sys->n_pending_writes = 0;

	log_sys->no_flush_event = os_event_create(NULL);

	os_event_set(log_sys->no_flush_event);

	log_sys->one_flushed_event = os_event_create(NULL);

	os_event_set(log_sys->one_flushed_event);

	/*----------------------------*/
	log_sys->adm_checkpoint_interval = ULINT_MAX;

	log_sys->next_checkpoint_no = 0;
	log_sys->last_checkpoint_lsn = log_sys->lsn;
	log_sys->n_pending_checkpoint_writes = 0;

	rw_lock_create(&log_sys->checkpoint_lock, SYNC_NO_ORDER_CHECK);

	log_sys->checkpoint_buf_ptr = mem_alloc(2 * OS_FILE_LOG_BLOCK_SIZE);

	log_sys->checkpoint_buf = ut_align(
		log_sys->checkpoint_buf_ptr, OS_FILE_LOG_BLOCK_SIZE);

	memset(log_sys->checkpoint_buf, '\0', OS_FILE_LOG_BLOCK_SIZE);
	/*----------------------------*/

#ifdef UNIV_LOG_ARCHIVE
	/* By default log archiving is always off */
	log_sys->archiving_state = LOG_ARCH_OFF;
	log_sys->archived_lsn = log_sys->lsn;
	log_sys->next_archived_lsn = 0;

	log_sys->n_pending_archive_ios = 0;

	rw_lock_create(&log_sys->archive_lock, SYNC_NO_ORDER_CHECK);

	log_sys->archive_buf = NULL;

	/* ut_align(
	ut_malloc(LOG_ARCHIVE_BUF_SIZE
	+ OS_FILE_LOG_BLOCK_SIZE),
	OS_FILE_LOG_BLOCK_SIZE); */
	log_sys->archive_buf_size = 0;

	/* memset(log_sys->archive_buf, '\0', LOG_ARCHIVE_BUF_SIZE); */

	log_sys->archiving_on = os_event_create(NULL);
#endif /* UNIV_LOG_ARCHIVE */

	/*----------------------------*/

	log_block_init(log_sys->buf, log_sys->lsn);
	log_block_set_first_rec_group(log_sys->buf, LOG_BLOCK_HDR_SIZE);

	log_sys->buf_free = LOG_BLOCK_HDR_SIZE;
	log_sys->lsn = LOG_START_LSN + LOG_BLOCK_HDR_SIZE;

	log_release();

#ifdef UNIV_LOG_DEBUG
	recv_sys_create();
	recv_sys_init(buf_pool_get_curr_size());

	recv_sys->parse_start_lsn = log_sys->lsn;
	recv_sys->scanned_lsn = log_sys->lsn;
	recv_sys->scanned_checkpoint_no = 0;
	recv_sys->recovered_lsn = log_sys->lsn;
	recv_sys->limit_lsn = IB_UINT64_T_MAX;
#endif
}

/******************************************************************//**
Inits a log group to the log system. */
UNIV_INTERN
void
log_group_init(
/*===========*/
	ulint	id,			/*!< in: group id */
	ulint	n_files,		/*!< in: number of log files */
	ulint	file_size,		/*!< in: log file size in bytes */
	ulint	space_id,		/*!< in: space id of the file space
					which contains the log files of this
					group */
	ulint	archive_space_id __attribute__((unused)))
					/*!< in: space id of the file space
					which contains some archived log
					files for this group; currently, only
					for the first log group this is
					used */
{
	ulint	i;

	log_group_t*	group;

	group = mem_alloc(sizeof(log_group_t));

	group->id = id;
	group->n_files = n_files;
	group->file_size = file_size;
	group->space_id = space_id;
	group->state = LOG_GROUP_OK;
	group->lsn = LOG_START_LSN;
	group->lsn_offset = LOG_FILE_HDR_SIZE;
	group->n_pending_writes = 0;

	group->file_header_bufs_ptr = mem_alloc(sizeof(byte*) * n_files);
	group->file_header_bufs = mem_alloc(sizeof(byte*) * n_files);
#ifdef UNIV_LOG_ARCHIVE
	group->archive_file_header_bufs_ptr = mem_alloc(
		sizeof(byte*) * n_files);

	group->archive_file_header_bufs = mem_alloc(sizeof(byte*) * n_files);
#endif /* UNIV_LOG_ARCHIVE */

	for (i = 0; i < n_files; i++) {
		group->file_header_bufs_ptr[i] = mem_alloc(
			LOG_FILE_HDR_SIZE + OS_FILE_LOG_BLOCK_SIZE);

		group->file_header_bufs[i] = ut_align(
			 group->file_header_bufs_ptr[i],
			OS_FILE_LOG_BLOCK_SIZE);

		memset(*(group->file_header_bufs + i), '\0',
		       LOG_FILE_HDR_SIZE);

#ifdef UNIV_LOG_ARCHIVE
		group->archive_file_header_bufs_ptr[i] = mem_alloc(
			LOG_FILE_HDR_SIZE + OS_FILE_LOG_BLOCK_SIZE);

		group->archive_file_header_bufs[i] = ut_align(
			group->archive_file_header_bufs_ptr[i],
			OS_FILE_LOG_BLOCK_SIZE);

		memset(*(group->archive_file_header_bufs + i), '\0',
		       LOG_FILE_HDR_SIZE);
#endif /* UNIV_LOG_ARCHIVE */
	}

#ifdef UNIV_LOG_ARCHIVE
	group->archive_space_id = archive_space_id;

	group->archived_file_no = 0;
	group->archived_offset = 0;
#endif /* UNIV_LOG_ARCHIVE */

	group->checkpoint_buf_ptr = mem_alloc(2 * OS_FILE_LOG_BLOCK_SIZE);

	group->checkpoint_buf = ut_align(
		group->checkpoint_buf_ptr, OS_FILE_LOG_BLOCK_SIZE);

	memset(group->checkpoint_buf, '\0', OS_FILE_LOG_BLOCK_SIZE);

	UT_LIST_ADD_LAST(log_groups, log_sys->log_groups, group);

	ut_a(log_calc_max_ages());
}

/******************************************************************//**
Does the unlockings needed in flush i/o completion. */
UNIV_INLINE
void
log_flush_do_unlocks(
/*=================*/
	ulint	code)	/*!< in: any ORed combination of LOG_UNLOCK_FLUSH_LOCK
			and LOG_UNLOCK_NONE_FLUSHED_LOCK */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	/* NOTE that we must own the log mutex when doing the setting of the
	events: this is because transactions will wait for these events to
	be set, and at that moment the log flush they were waiting for must
	have ended. If the log mutex were not reserved here, the i/o-thread
	calling this function might be preempted for a while, and when it
	resumed execution, it might be that a new flush had been started, and
	this function would erroneously signal the NEW flush as completed.
	Thus, the changes in the state of these events are performed
	atomically in conjunction with the changes in the state of
	log_sys->n_pending_writes etc. */

	if (code & LOG_UNLOCK_NONE_FLUSHED_LOCK) {
		os_event_set(log_sys->one_flushed_event);
	}

	if (code & LOG_UNLOCK_FLUSH_LOCK) {
		os_event_set(log_sys->no_flush_event);
	}
}

/******************************************************************//**
Checks if a flush is completed for a log group and does the completion
routine if yes.
@return	LOG_UNLOCK_NONE_FLUSHED_LOCK or 0 */
UNIV_INLINE
ulint
log_group_check_flush_completion(
/*=============================*/
	log_group_t*	group)	/*!< in: log group */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	if (!log_sys->one_flushed && group->n_pending_writes == 0) {
#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream,
				"Log flushed first to group %lu\n",
				(ulong) group->id);
		}
#endif /* UNIV_DEBUG */
		log_sys->written_to_some_lsn = log_sys->write_lsn;
		log_sys->one_flushed = TRUE;

		return(LOG_UNLOCK_NONE_FLUSHED_LOCK);
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes && (group->n_pending_writes == 0)) {

		ib_logger(ib_stream, "Log flushed to group %lu\n",
			(ulong) group->id);
	}
#endif /* UNIV_DEBUG */
	return(0);
}

/******************************************************//**
Checks if a flush is completed and does the completion routine if yes.
@return	LOG_UNLOCK_FLUSH_LOCK or 0 */
UNIV_STATIC
ulint
log_sys_check_flush_completion(void)
/*================================*/
{
	ulint	move_start;
	ulint	move_end;

	ut_ad(mutex_own(&(log_sys->mutex)));

	if (log_sys->n_pending_writes == 0) {

		log_sys->written_to_all_lsn = log_sys->write_lsn;
		log_sys->buf_next_to_write = log_sys->write_end_offset;

		if (log_sys->write_end_offset > log_sys->max_buf_free / 2) {
			/* Move the log buffer content to the start of the
			buffer */

			move_start = ut_calc_align_down(
				log_sys->write_end_offset,
				OS_FILE_LOG_BLOCK_SIZE);
			move_end = ut_calc_align(log_sys->buf_free,
						 OS_FILE_LOG_BLOCK_SIZE);

			ut_memmove(log_sys->buf, log_sys->buf + move_start,
				   move_end - move_start);
			log_sys->buf_free -= move_start;

			log_sys->buf_next_to_write -= move_start;
		}

		return(LOG_UNLOCK_FLUSH_LOCK);
	}

	return(0);
}

/******************************************************//**
Completes an i/o to a log file. */
UNIV_INTERN
void
log_io_complete(
/*============*/
	log_group_t*	group)	/*!< in: log group or a dummy pointer */
{
	ulint	unlock;

#ifdef UNIV_LOG_ARCHIVE
	if ((byte*)group == &log_archive_io) {
		/* It was an archive write */

		log_io_complete_archive();

		return;
	}
#endif /* UNIV_LOG_ARCHIVE */

	if ((ulint)group & 0x1UL) {
		/* It was a checkpoint write */
		group = (log_group_t*)((ulint)group - 1);

		if (srv_unix_file_flush_method != SRV_UNIX_O_DSYNC
		    && srv_unix_file_flush_method != SRV_UNIX_NOSYNC) {

			fil_flush(group->space_id);
		}

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream,
				"Checkpoint info written to group %lu\n",
				group->id);
		}
#endif /* UNIV_DEBUG */
		log_io_complete_checkpoint();

		return;
	}

	ut_error;	/*!< We currently use synchronous writing of the
			logs and cannot end up here! */

	if (srv_unix_file_flush_method != SRV_UNIX_O_DSYNC
	    && srv_unix_file_flush_method != SRV_UNIX_NOSYNC
	    && srv_flush_log_at_trx_commit != 2) {

		fil_flush(group->space_id);
	}

	log_acquire();
	ut_ad(!recv_no_log_write);

	ut_a(group->n_pending_writes > 0);
	ut_a(log_sys->n_pending_writes > 0);

	group->n_pending_writes--;
	log_sys->n_pending_writes--;

	unlock = log_group_check_flush_completion(group);
	unlock = unlock | log_sys_check_flush_completion();

	log_flush_do_unlocks(unlock);

	log_release();
}

/******************************************************//**
Writes a log file header to a log file space. */
UNIV_STATIC
void
log_group_file_header_flush(
/*========================*/
	log_group_t*	group,		/*!< in: log group */
	ulint		nth_file,	/*!< in: header to the nth file in the
					log file space */
	ib_uint64_t	start_lsn)	/*!< in: log file data starts at this
					lsn */
{
	byte*	buf;
	ulint	dest_offset;

	ut_ad(mutex_own(&(log_sys->mutex)));
	ut_ad(!recv_no_log_write);
	ut_a(nth_file < group->n_files);

	buf = group->file_header_bufs[nth_file];

	mach_write_to_4(buf + LOG_GROUP_ID, group->id);
	mach_write_ull(buf + LOG_FILE_START_LSN, start_lsn);

	/* Wipe over possible label of ibbackup --restore */
	memcpy(buf + LOG_FILE_WAS_CREATED_BY_HOT_BACKUP, "    ", 4);

	dest_offset = nth_file * group->file_size;

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			"Writing log file header to group %lu file %lu\n",
			(ulong) group->id, (ulong) nth_file);
	}
#endif /* UNIV_DEBUG */
	if (log_do_write) {
		log_sys->n_log_ios++;

		srv_os_log_pending_writes++;

		fil_io(OS_FILE_WRITE | OS_FILE_LOG,
		       TRUE,
		       group->space_id,
		       0, // FIXME: ARCHIVE: Zip size ?
		       dest_offset / UNIV_PAGE_SIZE,
		       dest_offset % UNIV_PAGE_SIZE,
		       OS_FILE_LOG_BLOCK_SIZE,
		       buf,
		       group);

		srv_os_log_pending_writes--;
	}
}

/******************************************************//**
Stores a 4-byte checksum to the trailer checksum field of a log block
before writing it to a log file. This checksum is used in recovery to
check the consistency of a log block. */
UNIV_STATIC
void
log_block_store_checksum(
/*=====================*/
	byte*	block)	/*!< in/out: pointer to a log block */
{
	log_block_set_checksum(block, log_block_calc_checksum(block));
}

/******************************************************//**
Writes a buffer to a log file group. */
UNIV_INTERN
void
log_group_write_buf(
/*================*/
	log_group_t*	group,		/*!< in: log group */
	byte*		buf,		/*!< in: buffer */
	ulint		len,		/*!< in: buffer len; must be divisible
					by OS_FILE_LOG_BLOCK_SIZE */
	ib_uint64_t	start_lsn,	/*!< in: start lsn of the buffer; must
					be divisible by
					OS_FILE_LOG_BLOCK_SIZE */
	ulint		new_data_offset)/*!< in: start offset of new data in
					buf: this parameter is used to decide
					if we have to write a new log file
					header */
{
	ulint	write_len;
	ibool	write_header;
	ulint	next_offset;
	ulint	i;

	ut_ad(mutex_own(&(log_sys->mutex)));
	ut_ad(!recv_no_log_write);
	ut_a(len % OS_FILE_LOG_BLOCK_SIZE == 0);
	ut_a(((ulint) start_lsn) % OS_FILE_LOG_BLOCK_SIZE == 0);

	if (new_data_offset == 0) {
		write_header = TRUE;
	} else {
		write_header = FALSE;
	}
loop:
	if (len == 0) {

		return;
	}

	next_offset = log_group_calc_lsn_offset(start_lsn, group);

	if ((next_offset % group->file_size == LOG_FILE_HDR_SIZE)
	    && write_header) {
		/* We start to write a new log file instance in the group */

		log_group_file_header_flush(group,
					    next_offset / group->file_size,
					    start_lsn);
		srv_os_log_written+= OS_FILE_LOG_BLOCK_SIZE;
		srv_log_writes++;
	}

	if ((next_offset % group->file_size) + len > group->file_size) {

		write_len = group->file_size
			- (next_offset % group->file_size);
	} else {
		write_len = len;
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes) {

		ib_logger(ib_stream,
			"Writing log file segment to group %lu"
			" offset %lu len %lu\n"
			"start lsn %llu\n"
			"First block n:o %lu last block n:o %lu\n",
			(ulong) group->id, (ulong) next_offset,
			(ulong) write_len,
			start_lsn,
			(ulong) log_block_get_hdr_no(buf),
			(ulong) log_block_get_hdr_no(
				buf + write_len - OS_FILE_LOG_BLOCK_SIZE));
		ut_a(log_block_get_hdr_no(buf)
		     == log_block_convert_lsn_to_no(start_lsn));

		for (i = 0; i < write_len / OS_FILE_LOG_BLOCK_SIZE; i++) {

			ut_a(log_block_get_hdr_no(buf) + i
			     == log_block_get_hdr_no(
				     buf + i * OS_FILE_LOG_BLOCK_SIZE));
		}
	}
#endif /* UNIV_DEBUG */
	/* Calculate the checksums for each log block and write them to
	the trailer fields of the log blocks */

	for (i = 0; i < write_len / OS_FILE_LOG_BLOCK_SIZE; i++) {
		log_block_store_checksum(buf + i * OS_FILE_LOG_BLOCK_SIZE);
	}

	if (log_do_write) {
		log_sys->n_log_ios++;

		srv_os_log_pending_writes++;

		fil_io(OS_FILE_WRITE | OS_FILE_LOG, TRUE, group->space_id, 0,
		       next_offset / UNIV_PAGE_SIZE,
		       next_offset % UNIV_PAGE_SIZE, write_len, buf, group);

		srv_os_log_pending_writes--;

		srv_os_log_written+= write_len;
		srv_log_writes++;
	}

	if (write_len < len) {
		start_lsn += write_len;
		len -= write_len;
		buf += write_len;

		write_header = TRUE;

		goto loop;
	}
}

/******************************************************//**
This function is called, e.g., when a transaction wants to commit. It checks
that the log has been written to the log file up to the last log entry written
by the transaction. If there is a flush running, it waits and checks if the
flush flushed enough. If not, starts a new flush. */
UNIV_INTERN
void
log_write_up_to(
/*============*/
	ib_uint64_t	lsn,	/*!< in: log sequence number up to which
				the log should be written,
				IB_UINT64_T_MAX if not specified */
	ulint		wait,	/*!< in: LOG_NO_WAIT, LOG_WAIT_ONE_GROUP,
				or LOG_WAIT_ALL_GROUPS */
	ibool		flush_to_disk)
				/*!< in: TRUE if we want the written log
				also to be flushed to disk */
{
	log_group_t*	group;
	ulint		start_offset;
	ulint		end_offset;
	ulint		area_start;
	ulint		area_end;
#ifdef UNIV_DEBUG
	ulint		loop_count	= 0;
#endif /* UNIV_DEBUG */
	ulint		unlock;

	if (recv_no_ibuf_operations) {
		/* Recovery is running and no operations on the log files are
		allowed yet (the variable name .._no_ibuf_.. is misleading) */

		return;
	}

loop:
#ifdef UNIV_DEBUG
	loop_count++;

	ut_ad(loop_count < 5);

# if 0
	if (loop_count > 2) {
		ib_logger(ib_stream, "Log loop count %lu\n", loop_count);
	}
# endif
#endif

	log_acquire();
	ut_ad(!recv_no_log_write);

	if (flush_to_disk
	    && log_sys->flushed_to_disk_lsn >= lsn) {

		log_release();

		return;
	}

	if (!flush_to_disk
	    && (log_sys->written_to_all_lsn >= lsn
		|| (log_sys->written_to_some_lsn >= lsn
		    && wait != LOG_WAIT_ALL_GROUPS))) {

		log_release();

		return;
	}

	if (log_sys->n_pending_writes > 0) {
		/* A write (+ possibly flush to disk) is running */

		if (flush_to_disk
		    && log_sys->current_flush_lsn >= lsn) {
			/* The write + flush will write enough: wait for it to
			complete  */

			goto do_waits;
		}

		if (!flush_to_disk
		    && log_sys->write_lsn >= lsn) {
			/* The write will write enough: wait for it to
			complete  */

			goto do_waits;
		}

		log_release();

		/* Wait for the write to complete and try to start a new
		write */

		os_event_wait(log_sys->no_flush_event);

		goto loop;
	}

	if (!flush_to_disk
	    && log_sys->buf_free == log_sys->buf_next_to_write) {
		/* Nothing to write and no flush to disk requested */

		log_release();

		return;
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			"Writing log from %llu up to lsn %llu\n",
			log_sys->written_to_all_lsn,
			log_sys->lsn);
	}
#endif /* UNIV_DEBUG */
	log_sys->n_pending_writes++;

	group = UT_LIST_GET_FIRST(log_sys->log_groups);
	group->n_pending_writes++;	/*!< We assume here that we have only
					one log group! */

	os_event_reset(log_sys->no_flush_event);
	os_event_reset(log_sys->one_flushed_event);

	start_offset = log_sys->buf_next_to_write;
	end_offset = log_sys->buf_free;

	area_start = ut_calc_align_down(start_offset, OS_FILE_LOG_BLOCK_SIZE);
	area_end = ut_calc_align(end_offset, OS_FILE_LOG_BLOCK_SIZE);

	ut_ad(area_end - area_start > 0);

	log_sys->write_lsn = log_sys->lsn;

	if (flush_to_disk) {
		log_sys->current_flush_lsn = log_sys->lsn;
	}

	log_sys->one_flushed = FALSE;

	log_block_set_flush_bit(log_sys->buf + area_start, TRUE);
	log_block_set_checkpoint_no(
		log_sys->buf + area_end - OS_FILE_LOG_BLOCK_SIZE,
		log_sys->next_checkpoint_no);

	/* Copy the last, incompletely written, log block a log block length
	up, so that when the flush operation writes from the log buffer, the
	segment to write will not be changed by writers to the log */

	ut_memcpy(log_sys->buf + area_end,
		  log_sys->buf + area_end - OS_FILE_LOG_BLOCK_SIZE,
		  OS_FILE_LOG_BLOCK_SIZE);

	log_sys->buf_free += OS_FILE_LOG_BLOCK_SIZE;
	log_sys->write_end_offset = log_sys->buf_free;

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	/* Do the write to the log files */

	while (group) {
		log_group_write_buf(
			group, log_sys->buf + area_start,
			area_end - area_start,
			ut_uint64_align_down(log_sys->written_to_all_lsn,
					     OS_FILE_LOG_BLOCK_SIZE),
			start_offset - area_start);

		log_group_set_fields(group, log_sys->write_lsn);

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	log_release();

	if (srv_unix_file_flush_method == SRV_UNIX_O_DSYNC) {
		/* O_DSYNC means the OS did not buffer the log file at all:
		so we have also flushed to disk what we have written */

		log_sys->flushed_to_disk_lsn = log_sys->write_lsn;

	} else if (flush_to_disk) {

		group = UT_LIST_GET_FIRST(log_sys->log_groups);

		fil_flush(group->space_id);
		log_sys->flushed_to_disk_lsn = log_sys->write_lsn;
	}

	log_acquire();

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	ut_a(group->n_pending_writes == 1);
	ut_a(log_sys->n_pending_writes == 1);

	group->n_pending_writes--;
	log_sys->n_pending_writes--;

	unlock = log_group_check_flush_completion(group);
	unlock = unlock | log_sys_check_flush_completion();

	log_flush_do_unlocks(unlock);

	log_release();

	return;

do_waits:
	log_release();

	switch (wait) {
	case LOG_WAIT_ONE_GROUP:
		os_event_wait(log_sys->one_flushed_event);
		break;
	case LOG_WAIT_ALL_GROUPS:
		os_event_wait(log_sys->no_flush_event);
		break;
#ifdef UNIV_DEBUG
	case LOG_NO_WAIT:
		break;
	default:
		ut_error;
#endif /* UNIV_DEBUG */
	}
}

/****************************************************************//**
Does a syncronous flush of the log buffer to disk. */
UNIV_INTERN
void
log_buffer_flush_to_disk(void)
/*==========================*/
{
	ib_uint64_t	lsn;

	log_acquire();

	lsn = log_sys->lsn;

	log_release();

	log_write_up_to(lsn, LOG_WAIT_ALL_GROUPS, TRUE);
}

/****************************************************************//**
This functions writes the log buffer to the log file and if 'flush'
is set it forces a flush of the log file as well. This is meant to be
called from background master thread only as it does not wait for
the write (+ possible flush) to finish. */
UNIV_INTERN
void
log_buffer_sync_in_background(
/*==========================*/
	ibool	flush)	/*!< in: flush the logs to disk */
{
	ib_uint64_t	lsn;

	mutex_enter(&(log_sys->mutex));

	lsn = log_sys->lsn;

	mutex_exit(&(log_sys->mutex));

	log_write_up_to(lsn, LOG_NO_WAIT, flush);
}

/********************************************************************

Tries to establish a big enough margin of free space in the log buffer, such
that a new log entry can be catenated without an immediate need for a flush. */
UNIV_STATIC
void
log_flush_margin(void)
/*==================*/
{
	log_t*		log	= log_sys;
	ib_uint64_t	lsn	= 0;

	log_acquire();

	if (log->buf_free > log->max_buf_free) {

		if (log->n_pending_writes > 0) {
			/* A flush is running: hope that it will provide enough
			free space */
		} else {
			lsn = log->lsn;
		}
	}

	log_release();

	if (lsn) {
		log_write_up_to(lsn, LOG_NO_WAIT, FALSE);
	}
}

/****************************************************************//**
Advances the smallest lsn for which there are unflushed dirty blocks in the
buffer pool. NOTE: this function may only be called if the calling thread owns
no synchronization objects!
@return FALSE if there was a flush batch of the same type running,
which means that we could not start this flush batch */
UNIV_INTERN
ibool
log_preflush_pool_modified_pages(
/*=============================*/
	ib_uint64_t	new_oldest,	/*!< in: try to advance
					oldest_modified_lsn at least
					to this lsn */
	ibool		sync)		/*!< in: TRUE if synchronous
					operation is desired */
{
	ulint	n_pages;

	if (recv_recovery_on) {
		/* If the recovery is running, we must first apply all
		log records to their respective file pages to get the
		right modify lsn values to these pages: otherwise, there
		might be pages on disk which are not yet recovered to the
		current lsn, and even after calling this function, we could
		not know how up-to-date the disk version of the database is,
		and we could not make a new checkpoint on the basis of the
		info on the buffer pool only. */

		recv_apply_hashed_log_recs(TRUE);
	}

	n_pages = buf_flush_batch(BUF_FLUSH_LIST, ULINT_MAX, new_oldest);

	if (sync) {
		buf_flush_wait_batch_end(BUF_FLUSH_LIST);
	}

	if (n_pages == ULINT_UNDEFINED) {

		return(FALSE);
	}

	return(TRUE);
}

/******************************************************//**
Completes a checkpoint. */
UNIV_STATIC
void
log_complete_checkpoint(void)
/*=========================*/
{
	ut_ad(mutex_own(&(log_sys->mutex)));
	ut_ad(log_sys->n_pending_checkpoint_writes == 0);

	log_sys->next_checkpoint_no++;

	log_sys->last_checkpoint_lsn = log_sys->next_checkpoint_lsn;

	rw_lock_x_unlock_gen(&(log_sys->checkpoint_lock), LOG_CHECKPOINT);
}

/******************************************************//**
Completes an asynchronous checkpoint info write i/o to a log file. */
UNIV_STATIC
void
log_io_complete_checkpoint(void)
/*============================*/
{
	log_acquire();

	ut_ad(log_sys->n_pending_checkpoint_writes > 0);

	log_sys->n_pending_checkpoint_writes--;

	if (log_sys->n_pending_checkpoint_writes == 0) {
		log_complete_checkpoint();
	}

	log_release();
}

/*******************************************************************//**
Writes info to a checkpoint about a log group. */
UNIV_STATIC
void
log_checkpoint_set_nth_group_info(
/*==============================*/
	byte*	buf,	/*!< in: buffer for checkpoint info */
	ulint	n,	/*!< in: nth slot */
	ulint	file_no,/*!< in: archived file number */
	ulint	offset)	/*!< in: archived file offset */
{
	ut_ad(n < LOG_MAX_N_GROUPS);

	mach_write_to_4(buf + LOG_CHECKPOINT_GROUP_ARRAY
			+ 8 * n + LOG_CHECKPOINT_ARCHIVED_FILE_NO, file_no);
	mach_write_to_4(buf + LOG_CHECKPOINT_GROUP_ARRAY
			+ 8 * n + LOG_CHECKPOINT_ARCHIVED_OFFSET, offset);
}

/*******************************************************************//**
Gets info from a checkpoint about a log group. */
UNIV_INTERN
void
log_checkpoint_get_nth_group_info(
/*==============================*/
	const byte*	buf,	/*!< in: buffer containing checkpoint info */
	ulint		n,	/*!< in: nth slot */
	ulint*		file_no,/*!< out: archived file number */
	ulint*		offset)	/*!< out: archived file offset */
{
	ut_ad(n < LOG_MAX_N_GROUPS);

	*file_no = mach_read_from_4(buf + LOG_CHECKPOINT_GROUP_ARRAY
				    + 8 * n + LOG_CHECKPOINT_ARCHIVED_FILE_NO);
	*offset = mach_read_from_4(buf + LOG_CHECKPOINT_GROUP_ARRAY
				   + 8 * n + LOG_CHECKPOINT_ARCHIVED_OFFSET);
}

/******************************************************//**
Writes the checkpoint info to a log group header. */
UNIV_STATIC
void
log_group_checkpoint(
/*=================*/
	log_group_t*	group)	/*!< in: log group */
{
	log_group_t*	group2;
#ifdef UNIV_LOG_ARCHIVE
	ib_uint64_t	archived_lsn;
	ib_uint64_t	next_archived_lsn;
#endif /* UNIV_LOG_ARCHIVE */
	ulint		write_offset;
	ulint		fold;
	byte*		buf;
	ulint		i;

	ut_ad(mutex_own(&(log_sys->mutex)));
#if LOG_CHECKPOINT_SIZE > OS_FILE_LOG_BLOCK_SIZE
# error "LOG_CHECKPOINT_SIZE > OS_FILE_LOG_BLOCK_SIZE"
#endif

	buf = group->checkpoint_buf;

	mach_write_ull(buf + LOG_CHECKPOINT_NO, log_sys->next_checkpoint_no);
	mach_write_ull(buf + LOG_CHECKPOINT_LSN, log_sys->next_checkpoint_lsn);

	mach_write_to_4(buf + LOG_CHECKPOINT_OFFSET,
			log_group_calc_lsn_offset(
				log_sys->next_checkpoint_lsn, group));

	mach_write_to_4(buf + LOG_CHECKPOINT_LOG_BUF_SIZE, log_sys->buf_size);

#ifdef UNIV_LOG_ARCHIVE
	if (log_sys->archiving_state == LOG_ARCH_OFF) {
		archived_lsn = IB_UINT64_T_MAX;
	} else {
		archived_lsn = log_sys->archived_lsn;

		if (archived_lsn != log_sys->next_archived_lsn) {
			next_archived_lsn = log_sys->next_archived_lsn;
			/* For debugging only */
		}
	}

	mach_write_ull(buf + LOG_CHECKPOINT_ARCHIVED_LSN, archived_lsn);
#else /* UNIV_LOG_ARCHIVE */
	mach_write_ull(buf + LOG_CHECKPOINT_ARCHIVED_LSN, IB_UINT64_T_MAX);
#endif /* UNIV_LOG_ARCHIVE */

	for (i = 0; i < LOG_MAX_N_GROUPS; i++) {
		log_checkpoint_set_nth_group_info(buf, i, 0, 0);
	}

	group2 = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group2) {
		log_checkpoint_set_nth_group_info(buf, group2->id,
#ifdef UNIV_LOG_ARCHIVE
						  group2->archived_file_no,
						  group2->archived_offset
#else /* UNIV_LOG_ARCHIVE */
						  0, 0
#endif /* UNIV_LOG_ARCHIVE */
						  );

		group2 = UT_LIST_GET_NEXT(log_groups, group2);
	}

	fold = ut_fold_binary(buf, LOG_CHECKPOINT_CHECKSUM_1);
	mach_write_to_4(buf + LOG_CHECKPOINT_CHECKSUM_1, fold);

	fold = ut_fold_binary(buf + LOG_CHECKPOINT_LSN,
			      LOG_CHECKPOINT_CHECKSUM_2 - LOG_CHECKPOINT_LSN);
	mach_write_to_4(buf + LOG_CHECKPOINT_CHECKSUM_2, fold);

	/* Starting from InnoDB-3.23.50, we also write info on allocated
	size in the tablespace */

	mach_write_to_4(buf + LOG_CHECKPOINT_FSP_FREE_LIMIT,
			log_fsp_current_free_limit);

	mach_write_to_4(buf + LOG_CHECKPOINT_FSP_MAGIC_N,
			LOG_CHECKPOINT_FSP_MAGIC_N_VAL);

	/* We alternate the physical place of the checkpoint info in the first
	log file */

	if ((log_sys->next_checkpoint_no & 1) == 0) {
		write_offset = LOG_CHECKPOINT_1;
	} else {
		write_offset = LOG_CHECKPOINT_2;
	}

	if (log_do_write) {
		if (log_sys->n_pending_checkpoint_writes == 0) {

			rw_lock_x_lock_gen(&(log_sys->checkpoint_lock),
					   LOG_CHECKPOINT);
		}

		log_sys->n_pending_checkpoint_writes++;

		log_sys->n_log_ios++;

		/* We send as the last parameter the group machine address
		added with 1, as we want to distinguish between a normal log
		file write and a checkpoint field write */

		fil_io(OS_FILE_WRITE | OS_FILE_LOG, FALSE, group->space_id, 0,
		       write_offset / UNIV_PAGE_SIZE,
		       write_offset % UNIV_PAGE_SIZE,
		       OS_FILE_LOG_BLOCK_SIZE,
		       buf, ((byte*)group + 1));

		ut_ad(((ulint)group & 0x1UL) == 0);
	}
}
#endif /* !UNIV_HOTBACKUP */

#ifdef UNIV_HOTBACKUP
/******************************************************//**
Writes info to a buffer of a log group when log files are created in
backup restoration. */
UNIV_INTERN
void
log_reset_first_header_and_checkpoint(
/*==================================*/
	byte*		hdr_buf,/*!< in: buffer which will be written to the
				start of the first log file */
	ib_uint64_t	start)	/*!< in: lsn of the start of the first log file;
				we pretend that there is a checkpoint at
				start + LOG_BLOCK_HDR_SIZE */
{
	ulint		fold;
	byte*		buf;
	ib_uint64_t	lsn;

	mach_write_to_4(hdr_buf + LOG_GROUP_ID, 0);
	mach_write_ull(hdr_buf + LOG_FILE_START_LSN, start);

	lsn = start + LOG_BLOCK_HDR_SIZE;

	/* Write the label of ibbackup --restore */
	strcpy((char*) hdr_buf + LOG_FILE_WAS_CREATED_BY_HOT_BACKUP,
	       "ibbackup ");
	ut_sprintf_timestamp((char*) hdr_buf
			     + (LOG_FILE_WAS_CREATED_BY_HOT_BACKUP
				+ (sizeof "ibbackup ") - 1));
	buf = hdr_buf + LOG_CHECKPOINT_1;

	mach_write_ull(buf + LOG_CHECKPOINT_NO, 0);
	mach_write_ull(buf + LOG_CHECKPOINT_LSN, lsn);

	mach_write_to_4(buf + LOG_CHECKPOINT_OFFSET,
			LOG_FILE_HDR_SIZE + LOG_BLOCK_HDR_SIZE);

	mach_write_to_4(buf + LOG_CHECKPOINT_LOG_BUF_SIZE, 2 * 1024 * 1024);

	mach_write_ull(buf + LOG_CHECKPOINT_ARCHIVED_LSN, IB_UINT64_T_MAX);

	fold = ut_fold_binary(buf, LOG_CHECKPOINT_CHECKSUM_1);
	mach_write_to_4(buf + LOG_CHECKPOINT_CHECKSUM_1, fold);

	fold = ut_fold_binary(buf + LOG_CHECKPOINT_LSN,
			      LOG_CHECKPOINT_CHECKSUM_2 - LOG_CHECKPOINT_LSN);
	mach_write_to_4(buf + LOG_CHECKPOINT_CHECKSUM_2, fold);

	/* Starting from InnoDB-3.23.50, we should also write info on
	allocated size in the tablespace, but unfortunately we do not
	know it here */
}
#endif /* UNIV_HOTBACKUP */

#ifndef UNIV_HOTBACKUP
/******************************************************//**
Reads a checkpoint info from a log group header to log_sys->checkpoint_buf. */
UNIV_INTERN
void
log_group_read_checkpoint_info(
/*===========================*/
	log_group_t*	group,	/*!< in: log group */
	ulint		field)	/*!< in: LOG_CHECKPOINT_1 or LOG_CHECKPOINT_2 */
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	log_sys->n_log_ios++;

	fil_io(OS_FILE_READ | OS_FILE_LOG, TRUE, group->space_id, 0,
	       field / UNIV_PAGE_SIZE, field % UNIV_PAGE_SIZE,
	       OS_FILE_LOG_BLOCK_SIZE, log_sys->checkpoint_buf, NULL);
}

/******************************************************//**
Writes checkpoint info to groups. */
UNIV_INTERN
void
log_groups_write_checkpoint_info(void)
/*==================================*/
{
	log_group_t*	group;

	ut_ad(mutex_own(&(log_sys->mutex)));

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group) {
		log_group_checkpoint(group);

		group = UT_LIST_GET_NEXT(log_groups, group);
	}
}

/******************************************************//**
Makes a checkpoint. Note that this function does not flush dirty
blocks from the buffer pool: it only checks what is lsn of the oldest
modification in the pool, and writes information about the lsn in
log files. Use log_make_checkpoint_at to flush also the pool.
@return	TRUE if success, FALSE if a checkpoint write was already running */
UNIV_INTERN
ibool
log_checkpoint(
/*===========*/
	ibool	sync,		/*!< in: TRUE if synchronous operation is
				desired */
	ibool	write_always)	/*!< in: the function normally checks if the
				the new checkpoint would have a greater
				lsn than the previous one: if not, then no
				physical write is done; by setting this
				parameter TRUE, a physical write will always be
				made to log files */
{
	ib_uint64_t	oldest_lsn;

	if (recv_recovery_is_on()) {
		recv_apply_hashed_log_recs(TRUE);
	}

	if (srv_unix_file_flush_method != SRV_UNIX_NOSYNC) {
		fil_flush_file_spaces(FIL_TABLESPACE);
	}

	log_acquire();

	ut_ad(!recv_no_log_write);
	oldest_lsn = log_buf_pool_get_oldest_modification();

	log_release();

	/* Because log also contains headers and dummy log records,
	if the buffer pool contains no dirty buffers, oldest_lsn
	gets the value log_sys->lsn from the previous function,
	and we must make sure that the log is flushed up to that
	lsn. If there are dirty buffers in the buffer pool, then our
	write-ahead-logging algorithm ensures that the log has been flushed
	up to oldest_lsn. */

	log_write_up_to(oldest_lsn, LOG_WAIT_ALL_GROUPS, TRUE);

	log_acquire();

	if (!write_always && log_sys->last_checkpoint_lsn >= oldest_lsn) {

		log_release();

		return(TRUE);
	}

	ut_ad(log_sys->flushed_to_disk_lsn >= oldest_lsn);

	if (log_sys->n_pending_checkpoint_writes > 0) {
		/* A checkpoint write is running */


		log_release();

		if (sync) {
			/* Wait for the checkpoint write to complete */
			rw_lock_s_lock(&(log_sys->checkpoint_lock));
			rw_lock_s_unlock(&(log_sys->checkpoint_lock));
		}

		return(FALSE);
	}

	log_sys->next_checkpoint_lsn = oldest_lsn;

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream, "Making checkpoint no %lu at lsn %llu\n",
			(ulong) log_sys->next_checkpoint_no,
			oldest_lsn);
	}
#endif /* UNIV_DEBUG */

	log_groups_write_checkpoint_info();

	log_release();

	if (sync) {
		/* Wait for the checkpoint write to complete */
		rw_lock_s_lock(&(log_sys->checkpoint_lock));
		rw_lock_s_unlock(&(log_sys->checkpoint_lock));
	}

	return(TRUE);
}

/****************************************************************//**
Makes a checkpoint at a given lsn or later. */
UNIV_INTERN
void
log_make_checkpoint_at(
/*===================*/
	ib_uint64_t	lsn,		/*!< in: make a checkpoint at this or a
					later lsn, if IB_UINT64_T_MAX, makes
					a checkpoint at the latest lsn */
	ibool		write_always)	/*!< in: the function normally checks if
					the new checkpoint would have a
					greater lsn than the previous one: if
					not, then no physical write is done;
					by setting this parameter TRUE, a
					physical write will always be made to
					log files */
{
	/* Preflush pages synchronously */

	while (!log_preflush_pool_modified_pages(lsn, TRUE));

	while (!log_checkpoint(TRUE, write_always));
}

/****************************************************************//**
Tries to establish a big enough margin of free space in the log groups, such
that a new log entry can be catenated without an immediate need for a
checkpoint. NOTE: this function may only be called if the calling thread
owns no synchronization objects! */
UNIV_STATIC
void
log_checkpoint_margin(void)
/*=======================*/
{
	log_t*		log		= log_sys;
	ib_uint64_t	age;
	ib_uint64_t	checkpoint_age;
	ib_uint64_t	advance;
	ib_uint64_t	oldest_lsn;
	ibool		sync;
	ibool		checkpoint_sync;
	ibool		do_checkpoint;
	ibool		success;
loop:
	sync = FALSE;
	checkpoint_sync = FALSE;
	do_checkpoint = FALSE;

	log_acquire();
	ut_ad(!recv_no_log_write);

	if (log->check_flush_or_checkpoint == FALSE) {
		log_release();

		return;
	}

	oldest_lsn = log_buf_pool_get_oldest_modification();

	age = log->lsn - oldest_lsn;

	if (age > log->max_modified_age_sync) {

		/* A flush is urgent: we have to do a synchronous preflush */

		sync = TRUE;
		advance = 2 * (age - log->max_modified_age_sync);
	} else if (age > log->max_modified_age_async) {

		/* A flush is not urgent: we do an asynchronous preflush */
		advance = age - log->max_modified_age_async;
	} else {
		advance = 0;
	}

	checkpoint_age = log->lsn - log->last_checkpoint_lsn;

	if (checkpoint_age > log->max_checkpoint_age) {
		/* A checkpoint is urgent: we do it synchronously */

		checkpoint_sync = TRUE;

		do_checkpoint = TRUE;

	} else if (checkpoint_age > log->max_checkpoint_age_async) {
		/* A checkpoint is not urgent: do it asynchronously */

		do_checkpoint = TRUE;

		log->check_flush_or_checkpoint = FALSE;
	} else {
		log->check_flush_or_checkpoint = FALSE;
	}


	log_release();

	if (advance) {
		ib_uint64_t	new_oldest = oldest_lsn + advance;

		success = log_preflush_pool_modified_pages(new_oldest, sync);

		/* If the flush succeeded, this thread has done its part
		and can proceed. If it did not succeed, there was another
		thread doing a flush at the same time. If sync was FALSE,
		the flush was not urgent, and we let this thread proceed.
		Otherwise, we let it start from the beginning again. */

		if (sync && !success) {

			log_acquire();

			log->check_flush_or_checkpoint = TRUE;

			log_release();
			goto loop;
		}
	}

	if (do_checkpoint) {
		log_checkpoint(checkpoint_sync, FALSE);

		if (checkpoint_sync) {

			goto loop;
		}
	}
}

/******************************************************//**
Reads a specified log segment to a buffer. */
UNIV_INTERN
void
log_group_read_log_seg(
/*===================*/
	ulint		type,		/*!< in: LOG_ARCHIVE or LOG_RECOVER */
	byte*		buf,		/*!< in: buffer where to read */
	log_group_t*	group,		/*!< in: log group */
	ib_uint64_t	start_lsn,	/*!< in: read area start */
	ib_uint64_t	end_lsn)	/*!< in: read area end */
{
	ulint	len;
	ulint	source_offset;
	ibool	sync;

	ut_ad(mutex_own(&(log_sys->mutex)));

	sync = (type == LOG_RECOVER);
loop:
	source_offset = log_group_calc_lsn_offset(start_lsn, group);

	len = (ulint) (end_lsn - start_lsn);

	ut_ad(len != 0);

	if ((source_offset % group->file_size) + len > group->file_size) {

		len = group->file_size - (source_offset % group->file_size);
	}

#ifdef UNIV_LOG_ARCHIVE
	if (type == LOG_ARCHIVE) {

		log_sys->n_pending_archive_ios++;
	}
#endif /* UNIV_LOG_ARCHIVE */

	log_sys->n_log_ios++;

	fil_io(OS_FILE_READ | OS_FILE_LOG, sync, group->space_id, 0,
	       source_offset / UNIV_PAGE_SIZE, source_offset % UNIV_PAGE_SIZE,
	       len, buf, NULL);

	start_lsn += len;
	buf += len;

	if (start_lsn != end_lsn) {

		goto loop;
	}
}

#ifdef UNIV_LOG_ARCHIVE
/******************************************************//**
Generates an archived log file name. */
UNIV_INTERN
void
log_archived_file_name_gen(
/*=======================*/
	char*	buf,	/*!< in: buffer where to write */
	ulint	id __attribute__((unused)),
			/*!< in: group id;
			currently we only archive the first group */
	ulint	file_no)/*!< in: file number */
{
	sprintf(buf, "%sib_arch_log_%010lu", srv_arch_dir, (ulong) file_no);
}

/******************************************************//**
Writes a log file header to a log file space. */
UNIV_STATIC
void
log_group_archive_file_header_write(
/*================================*/
	log_group_t*	group,		/*!< in: log group */
	ulint		nth_file,	/*!< in: header to the nth file in the
					archive log file space */
	ulint		file_no,	/*!< in: archived file number */
	ib_uint64_t	start_lsn)	/*!< in: log file data starts at this
					lsn */
{
	byte*	buf;
	ulint	dest_offset;

	ut_ad(mutex_own(&(log_sys->mutex)));

	ut_a(nth_file < group->n_files);

	buf = group->archive_file_header_bufs[nth_file];

	mach_write_to_4(buf + LOG_GROUP_ID, group->id);
	mach_write_ull(buf + LOG_FILE_START_LSN, start_lsn);
	mach_write_to_4(buf + LOG_FILE_NO, file_no);

	mach_write_to_4(buf + LOG_FILE_ARCH_COMPLETED, FALSE);

	dest_offset = nth_file * group->file_size;

	log_sys->n_log_ios++;

	fil_io(OS_FILE_WRITE | OS_FILE_LOG,
	       TRUE,
	       group->archive_space_id,
	       0, /* FIXME: ARCHIVE Zip size */
	       dest_offset / UNIV_PAGE_SIZE,
	       dest_offset % UNIV_PAGE_SIZE,
	       2 * OS_FILE_LOG_BLOCK_SIZE,
	       buf,
	       &log_archive_io);
}

/******************************************************//**
Writes a log file header to a completed archived log file. */
UNIV_STATIC
void
log_group_archive_completed_header_write(
/*=====================================*/
	log_group_t*	group,		/*!< in: log group */
	ulint		nth_file,	/*!< in: header to the nth file in the
					archive log file space */
	ib_uint64_t	end_lsn)	/*!< in: end lsn of the file */
{
	byte*	buf;
	ulint	dest_offset;

	ut_ad(mutex_own(&(log_sys->mutex)));
	ut_a(nth_file < group->n_files);

	buf = group->archive_file_header_bufs[nth_file];

	mach_write_to_4(buf + LOG_FILE_ARCH_COMPLETED, TRUE);
	mach_write_ull(buf + LOG_FILE_END_LSN, end_lsn);

	dest_offset = nth_file * group->file_size + LOG_FILE_ARCH_COMPLETED;

	log_sys->n_log_ios++;

	fil_io(OS_FILE_WRITE | OS_FILE_LOG,
	       TRUE,
	       group->archive_space_id,
	       0, /* FIXME: ARCHIVE Zip size */
	       dest_offset / UNIV_PAGE_SIZE,
	       dest_offset % UNIV_PAGE_SIZE,
	       OS_FILE_LOG_BLOCK_SIZE,
	       buf + LOG_FILE_ARCH_COMPLETED,
	       &log_archive_io);
}

/******************************************************//**
Does the archive writes for a single log group. */
UNIV_STATIC
void
log_group_archive(
/*==============*/
	log_group_t*	group)	/*!< in: log group */
{
	os_file_t	 file_handle;
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	char		name[1024];
	byte*		buf;
	ulint		len;
	ibool		ret;
	ulint		next_offset;
	ulint		n_files;
	ulint		open_mode;

	ut_ad(mutex_own(&(log_sys->mutex)));

	start_lsn = log_sys->archived_lsn;

	ut_a(start_lsn % OS_FILE_LOG_BLOCK_SIZE == 0);

	end_lsn = log_sys->next_archived_lsn;

	ut_a(end_lsn % OS_FILE_LOG_BLOCK_SIZE == 0);

	buf = log_sys->archive_buf;

	n_files = 0;

	next_offset = group->archived_offset;
loop:
	if ((next_offset % group->file_size == 0)
	    || (fil_space_get_size(group->archive_space_id) == 0)) {

		/* Add the file to the archive file space; create or open the
		file */

		if (next_offset % group->file_size == 0) {
			open_mode = OS_FILE_CREATE;
		} else {
			open_mode = OS_FILE_OPEN;
		}

		log_archived_file_name_gen(name, group->id,
					   group->archived_file_no + n_files);

		file_handle = os_file_create(name, open_mode, OS_FILE_AIO,
					     OS_DATA_FILE, &ret);

		if (!ret && (open_mode == OS_FILE_CREATE)) {
			file_handle = os_file_create(
				name, OS_FILE_OPEN, OS_FILE_AIO,
				OS_DATA_FILE, &ret);
		}

		if (!ret) {
			ib_logger(ib_stream,
				"InnoDB: Cannot create or open"
				" archive log file %s.\n"
				"InnoDB: Cannot continue operation.\n"
				"InnoDB: Check that the log archive"
				" directory exists,\n"
				"InnoDB: you have access rights to it, and\n"
				"InnoDB: there is space available.\n", name);
			exit(1);
		}

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream, "Created archive file %s\n", name);
		}
#endif /* UNIV_DEBUG */

		ret = os_file_close(file_handle);

		ut_a(ret);

		/* Add the archive file as a node to the space */

		fil_node_create(name, group->file_size / UNIV_PAGE_SIZE,
				group->archive_space_id, FALSE);

		if (next_offset % group->file_size == 0) {
			log_group_archive_file_header_write(
				group, n_files,
				group->archived_file_no + n_files,
				start_lsn);

			next_offset += LOG_FILE_HDR_SIZE;
		}
	}

	len = end_lsn - start_lsn;

	if (group->file_size < (next_offset % group->file_size) + len) {

		len = group->file_size - (next_offset % group->file_size);
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			"Archiving starting at lsn %llu, len %lu"
			" to group %lu\n",
			start_lsn,
			(ulong) len, (ulong) group->id);
	}
#endif /* UNIV_DEBUG */

	log_sys->n_pending_archive_ios++;

	log_sys->n_log_ios++;

	fil_io(OS_FILE_WRITE | OS_FILE_LOG,
	       FALSE,
	       group->archive_space_id,
	       0, // FIXME: ARCHIVE: Zip size
	       next_offset / UNIV_PAGE_SIZE, next_offset % UNIV_PAGE_SIZE,
	       ut_calc_align(len, OS_FILE_LOG_BLOCK_SIZE),
	       buf,
	       &log_archive_io);

	start_lsn += len;
	next_offset += len;
	buf += len;

	if (next_offset % group->file_size == 0) {
		n_files++;
	}

	if (end_lsn != start_lsn) {

		goto loop;
	}

	group->next_archived_file_no = group->archived_file_no + n_files;
	group->next_archived_offset = next_offset % group->file_size;

	ut_a(group->next_archived_offset % OS_FILE_LOG_BLOCK_SIZE == 0);
}

/*****************************************************//**
(Writes to the archive of each log group.) Currently, only the first
group is archived. */
UNIV_STATIC
void
log_archive_groups(void)
/*====================*/
{
	log_group_t*	group;

	ut_ad(mutex_own(&(log_sys->mutex)));

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	log_group_archive(group);
}

/*****************************************************//**
Completes the archiving write phase for (each log group), currently,
the first log group. */
UNIV_STATIC
void
log_archive_write_complete_groups(void)
/*===================================*/
{
	log_group_t*	group;
	ulint		end_offset;
	ulint		trunc_files;
	ulint		n_files;
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	ulint		i;

	ut_ad(mutex_own(&(log_sys->mutex)));

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	group->archived_file_no = group->next_archived_file_no;
	group->archived_offset = group->next_archived_offset;

	/* Truncate from the archive file space all but the last
	file, or if it has been written full, all files */

	n_files = (UNIV_PAGE_SIZE
		   * fil_space_get_size(group->archive_space_id))
		/ group->file_size;
	ut_ad(n_files > 0);

	end_offset = group->archived_offset;

	if (end_offset % group->file_size == 0) {

		trunc_files = n_files;
	} else {
		trunc_files = n_files - 1;
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes && trunc_files) {
		ib_logger(ib_stream,
			"Complete file(s) archived to group %lu\n",
			(ulong) group->id);
	}
#endif /* UNIV_DEBUG */

	/* Calculate the archive file space start lsn */
	start_lsn = log_sys->next_archived_lsn
		- (end_offset - LOG_FILE_HDR_SIZE + trunc_files
		   * (group->file_size - LOG_FILE_HDR_SIZE));
	end_lsn = start_lsn;

	for (i = 0; i < trunc_files; i++) {

		end_lsn += group->file_size - LOG_FILE_HDR_SIZE;

		/* Write a notice to the headers of archived log
		files that the file write has been completed */

		log_group_archive_completed_header_write(group, i, end_lsn);
	}

	fil_space_truncate_start(group->archive_space_id,
				 trunc_files * group->file_size);

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger("Archiving writes completed\n", ib_stream);
	}
#endif /* UNIV_DEBUG */
}

/******************************************************//**
Completes an archiving i/o. */
UNIV_STATIC
void
log_archive_check_completion_low(void)
/*==================================*/
{
	ut_ad(mutex_own(&(log_sys->mutex)));

	if (log_sys->n_pending_archive_ios == 0
	    && log_sys->archiving_phase == LOG_ARCHIVE_READ) {

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger("Archiving read completed\n", ib_stream);
		}
#endif /* UNIV_DEBUG */

		/* Archive buffer has now been read in: start archive writes */

		log_sys->archiving_phase = LOG_ARCHIVE_WRITE;

		log_archive_groups();
	}

	if (log_sys->n_pending_archive_ios == 0
	    && log_sys->archiving_phase == LOG_ARCHIVE_WRITE) {

		log_archive_write_complete_groups();

		log_sys->archived_lsn = log_sys->next_archived_lsn;

		rw_lock_x_unlock_gen(&(log_sys->archive_lock), LOG_ARCHIVE);
	}
}

/******************************************************//**
Completes an archiving i/o. */
UNIV_STATIC
void
log_io_complete_archive(void)
/*=========================*/
{
	log_group_t*	group;

	log_acquire();

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	log_release();

	fil_flush(group->archive_space_id);

	log_acquire();

	ut_ad(log_sys->n_pending_archive_ios > 0);

	log_sys->n_pending_archive_ios--;

	log_archive_check_completion_low();

	log_release();
}

/********************************************************************//**
Starts an archiving operation.
@return	TRUE if succeed, FALSE if an archiving operation was already running */
UNIV_INTERN
ibool
log_archive_do(
/*===========*/
	ibool	sync,	/*!< in: TRUE if synchronous operation is desired */
	ulint*	n_bytes)/*!< out: archive log buffer size, 0 if nothing to
			archive */
{
	ibool		calc_new_limit;
	ib_uint64_t	start_lsn;
	ib_uint64_t	limit_lsn;

	calc_new_limit = TRUE;
loop:
	log_acquire();

	switch (log_sys->archiving_state) {
	case LOG_ARCH_OFF:
arch_none:
		log_release();

		*n_bytes = 0;

		return(TRUE);
	case LOG_ARCH_STOPPED:
	case LOG_ARCH_STOPPING2:
		log_release();

		os_event_wait(log_sys->archiving_on);

		goto loop;
	}

	start_lsn = log_sys->archived_lsn;

	if (calc_new_limit) {
		ut_a(log_sys->archive_buf_size % OS_FILE_LOG_BLOCK_SIZE == 0);
		limit_lsn = start_lsn + log_sys->archive_buf_size;

		*n_bytes = log_sys->archive_buf_size;

		if (limit_lsn >= log_sys->lsn) {

			limit_lsn = ut_uint64_align_down(
				log_sys->lsn, OS_FILE_LOG_BLOCK_SIZE);
		}
	}

	if (log_sys->archived_lsn >= limit_lsn) {

		goto arch_none;
	}

	if (log_sys->written_to_all_lsn < limit_lsn) {

		log_release();

		log_write_up_to(limit_lsn, LOG_WAIT_ALL_GROUPS, TRUE);

		calc_new_limit = FALSE;

		goto loop;
	}

	if (log_sys->n_pending_archive_ios > 0) {
		/* An archiving operation is running */

		log_release();

		if (sync) {
			rw_lock_s_lock(&(log_sys->archive_lock));
			rw_lock_s_unlock(&(log_sys->archive_lock));
		}

		*n_bytes = log_sys->archive_buf_size;

		return(FALSE);
	}

	rw_lock_x_lock_gen(&(log_sys->archive_lock), LOG_ARCHIVE);

	log_sys->archiving_phase = LOG_ARCHIVE_READ;

	log_sys->next_archived_lsn = limit_lsn;

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			"Archiving from lsn %llu to lsn %llu\n",
			log_sys->archived_lsn, limit_lsn);
	}
#endif /* UNIV_DEBUG */

	/* Read the log segment to the archive buffer */

	log_group_read_log_seg(LOG_ARCHIVE, log_sys->archive_buf,
			       UT_LIST_GET_FIRST(log_sys->log_groups),
			       start_lsn, limit_lsn);

	log_release();

	if (sync) {
		rw_lock_s_lock(&(log_sys->archive_lock));
		rw_lock_s_unlock(&(log_sys->archive_lock));
	}

	*n_bytes = log_sys->archive_buf_size;

	return(TRUE);
}

/****************************************************************//**
Writes the log contents to the archive at least up to the lsn when this
function was called. */
UNIV_STATIC
void
log_archive_all(
/*============*/
	ib_recovery_t	recovery)	/*!< in: recovery flag */
{
	ib_uint64_t	present_lsn;
	ulint		dummy;

	log_acquire();

	if (log_sys->archiving_state == LOG_ARCH_OFF) {
		log_release();

		return;
	}

	present_lsn = log_sys->lsn;

	log_release();

	log_pad_current_log_block(recovery);

	for (;;) {

		log_acquire();

		if (present_lsn <= log_sys->archived_lsn) {

			log_release();

			return;
		}

		log_release();

		log_archive_do(TRUE, &dummy);
	}
}

/*****************************************************//**
Closes the possible open archive log file (for each group) the first group,
and if it was open, increments the group file count by 2, if desired. */
UNIV_STATIC
void
log_archive_close_groups(
/*=====================*/
	ibool	increment_file_count)	/*!< in: TRUE if we want to increment
					the file count */
{
	log_group_t*	group;
	ulint		trunc_len;

	ut_ad(mutex_own(&(log_sys->mutex)));

	if (log_sys->archiving_state == LOG_ARCH_OFF) {

		return;
	}

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	trunc_len = UNIV_PAGE_SIZE
		* fil_space_get_size(group->archive_space_id);
	if (trunc_len > 0) {
		ut_a(trunc_len == group->file_size);

		/* Write a notice to the headers of archived log
		files that the file write has been completed */

		log_group_archive_completed_header_write(
			group, 0, log_sys->archived_lsn);

		fil_space_truncate_start(group->archive_space_id,
					 trunc_len);
		if (increment_file_count) {
			group->archived_offset = 0;
			group->archived_file_no += 2;
		}

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream,
				"Incrementing arch file no to %lu"
				" in log group %lu\n",
				(ulong) group->archived_file_no + 2,
				(ulong) group->id);
		}
#endif /* UNIV_DEBUG */
	}
}

/****************************************************************//**
Writes the log contents to the archive up to the lsn when this function was
called, and stops the archiving. When archiving is started again, the archived
log file numbers start from 2 higher, so that the archiving will not write
again to the archived log files which exist when this function returns.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_stop(void)
/*==================*/
{
	ibool	success;

	log_acquire();

	if (log_sys->archiving_state != LOG_ARCH_ON) {

		log_release();

		return(DB_ERROR);
	}

	log_sys->archiving_state = LOG_ARCH_STOPPING;

	log_release();

	log_archive_all();

	log_acquire();

	log_sys->archiving_state = LOG_ARCH_STOPPING2;
	os_event_reset(log_sys->archiving_on);

	log_release();

	/* Wait for a possible archiving operation to end */

	rw_lock_s_lock(&(log_sys->archive_lock));
	rw_lock_s_unlock(&(log_sys->archive_lock));

	log_acquire();

	/* Close all archived log files, incrementing the file count by 2,
	if appropriate */

	log_archive_close_groups(TRUE);

	log_release();

	/* Make a checkpoint, so that if recovery is needed, the file numbers
	of new archived log files will start from the right value */

	success = FALSE;

	while (!success) {
		success = log_checkpoint(TRUE, TRUE);
	}

	log_acquire();

	log_sys->archiving_state = LOG_ARCH_STOPPED;

	log_release();

	return(DB_SUCCESS);
}

/****************************************************************//**
Starts again archiving which has been stopped.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_start(void)
/*===================*/
{
	mutex_enter(&(log_sys->mutex));

	if (log_sys->archiving_state != LOG_ARCH_STOPPED) {

		mutex_exit(&(log_sys->mutex));

		return(DB_ERROR);
	}

	log_sys->archiving_state = LOG_ARCH_ON;

	os_event_set(log_sys->archiving_on);

	mutex_exit(&(log_sys->mutex));

	return(DB_SUCCESS);
}

/****************************************************************//**
Stop archiving the log so that a gap may occur in the archived log files.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_noarchivelog(void)
/*==========================*/
{
loop:
	log_acquire();

	if (log_sys->archiving_state == LOG_ARCH_STOPPED
	    || log_sys->archiving_state == LOG_ARCH_OFF) {

		log_sys->archiving_state = LOG_ARCH_OFF;

		os_event_set(log_sys->archiving_on);

		log_release();

		return(DB_SUCCESS);
	}

	log_release();

	log_archive_stop();

	os_thread_sleep(500000);

	goto loop;
}

/****************************************************************//**
Start archiving the log so that a gap may occur in the archived log files.
@return	DB_SUCCESS or DB_ERROR */
UNIV_INTERN
ulint
log_archive_archivelog(void)
/*========================*/
{
	log_acquire();

	if (log_sys->archiving_state == LOG_ARCH_OFF) {

		log_sys->archiving_state = LOG_ARCH_ON;

		log_sys->archived_lsn
			= ut_uint64_align_down(log_sys->lsn,
					       OS_FILE_LOG_BLOCK_SIZE);
		log_release();

		return(DB_SUCCESS);
	}

	log_release();

	return(DB_ERROR);
}

/****************************************************************//**
Tries to establish a big enough margin of free space in the log groups, such
that a new log entry can be catenated without an immediate need for
archiving. */
UNIV_STATIC
void
log_archive_margin(void)
/*====================*/
{
	log_t*	log		= log_sys;
	ulint	age;
	ibool	sync;
	ulint	dummy;
loop:
	log_acquire();

	if (log->archiving_state == LOG_ARCH_OFF) {
		log_release();

		return;
	}

	age = log->lsn - log->archived_lsn;

	if (age > log->max_archived_lsn_age) {

		/* An archiving is urgent: we have to do synchronous i/o */

		sync = TRUE;

	} else if (age > log->max_archived_lsn_age_async) {

		/* An archiving is not urgent: we do asynchronous i/o */

		sync = FALSE;
	} else {
		/* No archiving required yet */

		log_release();

		return;
	}

	log_release();

	log_archive_do(sync, &dummy);

	if (sync == TRUE) {
		/* Check again that enough was written to the archive */

		goto loop;
	}
}
#endif /* UNIV_LOG_ARCHIVE */

/********************************************************************//**
Checks that there is enough free space in the log to start a new query step.
Flushes the log buffer or makes a new checkpoint if necessary. NOTE: this
function may only be called if the calling thread owns no synchronization
objects! */
UNIV_INTERN
void
log_check_margins(void)
/*===================*/
{
loop:
	log_flush_margin();

	log_checkpoint_margin();

#ifdef UNIV_LOG_ARCHIVE
	log_archive_margin();
#endif /* UNIV_LOG_ARCHIVE */

	log_acquire();
	ut_ad(!recv_no_log_write);

	if (log_sys->check_flush_or_checkpoint) {

		log_release();

		goto loop;
	}

	log_release();
}

/****************************************************************//**
Makes a checkpoint at the latest lsn and writes it to first page of each
data file in the database, so that we know that the file spaces contain
all modifications up to that lsn. This can only be called at database
shutdown. This function also writes all log in log files to the log archive. */
UNIV_INTERN
void
logs_empty_and_mark_files_at_shutdown(
/*==================================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	ib_shutdown_t	shutdown)	/*!< in: shutdown flag */
{
	ib_uint64_t	lsn;
	ulint		arch_log_no;

	/* If we have to abort during the startup phase then it's possible
	that the log sub-system hasn't as yet been initialized. We simply
	attempt to close all open files and return. */
	if (log_sys == NULL || UT_LIST_GET_LEN(log_sys->log_groups) == 0) {

		fil_close_all_files();

		return;
	}

	if (srv_print_verbose_log) {
		ut_print_timestamp(ib_stream);
		ib_logger(ib_stream, "  InnoDB: Starting shutdown...\n");
	}
	/* Wait until the master thread and all other operations are idle: our
	algorithm only works if the server is idle at shutdown */

	srv_shutdown_state = SRV_SHUTDOWN_CLEANUP;
loop:
	os_thread_sleep(100000);

	mutex_enter(&kernel_mutex);

	/* We need the monitor threads to stop before we proceed with a
	normal shutdown. In case of very fast shutdown, however, we can
	proceed without waiting for monitor threads. */

	if (shutdown != IB_SHUTDOWN_NO_BUFPOOL_FLUSH
	   && (srv_error_monitor_active
	      || srv_lock_timeout_active || srv_monitor_active)) {

		mutex_exit(&kernel_mutex);

		goto loop;
	}

	/* Check that there are no longer transactions. We need this wait even
	for the 'very fast' shutdown, because the InnoDB layer may have
	committed or prepared transactions and we don't want to lose them. */

	if (trx_n_transactions > 0
	    || (trx_sys != NULL && UT_LIST_GET_LEN(trx_sys->trx_list) > 0)) {

		mutex_exit(&kernel_mutex);

		goto loop;
	}

	if (shutdown == IB_SHUTDOWN_NO_BUFPOOL_FLUSH) {
		/* In this fastest shutdown we do not flush the buffer pool:
		it is essentially a 'crash' of the InnoDB server. Make sure
		that the log is all flushed to disk, so that we can recover
		all committed transactions in a crash recovery. We must not
		write the lsn stamps to the data files, since at a startup
		InnoDB deduces from the stamps if the previous shutdown was
		clean. */

		log_buffer_flush_to_disk();

		mutex_exit(&kernel_mutex);

		return; /* We SKIP ALL THE REST !! */
	}

	/* Check that the master thread is suspended */

	if (srv_n_threads_active[SRV_MASTER] != 0) {

		mutex_exit(&kernel_mutex);

		goto loop;
	}

	mutex_exit(&kernel_mutex);

	log_acquire();

	if (log_sys->n_pending_checkpoint_writes
#ifdef UNIV_LOG_ARCHIVE
	    || log_sys->n_pending_archive_ios
#endif /* UNIV_LOG_ARCHIVE */
	    || log_sys->n_pending_writes) {

		log_release();

		goto loop;
	}

	log_release();

	if (!buf_pool_check_no_pending_io()) {

		goto loop;
	}

#ifdef UNIV_LOG_ARCHIVE
	log_archive_all(recovery);
#endif /* UNIV_LOG_ARCHIVE */

	log_make_checkpoint_at(IB_UINT64_T_MAX, TRUE);

	log_acquire();

	lsn = log_sys->lsn;

	if (lsn != log_sys->last_checkpoint_lsn
#ifdef UNIV_LOG_ARCHIVE
	    || (srv_log_archive_on
		&& lsn != log_sys->archived_lsn + LOG_BLOCK_HDR_SIZE)
#endif /* UNIV_LOG_ARCHIVE */
	    ) {

		log_release();

		goto loop;
	}

	arch_log_no = 0;

#ifdef UNIV_LOG_ARCHIVE
	// FIXME: ARCHIVE: Statement has no effect
	//UT_LIST_GET_FIRST(log_sys->log_groups)->archived_file_no;

	if (0 == UT_LIST_GET_FIRST(log_sys->log_groups)->archived_offset) {

		arch_log_no--;
	}

	log_archive_close_groups(TRUE);
#endif /* UNIV_LOG_ARCHIVE */

	log_release();

	mutex_enter(&kernel_mutex);
	/* Check that the master thread has stayed suspended */
	if (srv_n_threads_active[SRV_MASTER] != 0) {
		ib_logger(ib_stream,
			"InnoDB: Warning: the master thread woke up"
			" during shutdown\n");

		mutex_exit(&kernel_mutex);

		goto loop;
	}
	mutex_exit(&kernel_mutex);

	fil_flush_file_spaces(FIL_TABLESPACE);
	fil_flush_file_spaces(FIL_LOG);

	/* The call fil_write_flushed_lsn_to_data_files() will pass the buffer
	pool: therefore it is essential that the buffer pool has been
	completely flushed to disk! (We do not call fil_write... if the
	'very fast' shutdown is enabled.) */

	if (!buf_all_freed()) {

		goto loop;
	}

	srv_shutdown_state = SRV_SHUTDOWN_LAST_PHASE;

	/* Make some checks that the server really is quiet */
	ut_a(srv_n_threads_active[SRV_MASTER] == 0);
	ut_a(buf_all_freed());
	ut_a(lsn == log_sys->lsn);

	if (lsn < srv_start_lsn) {
		ib_logger(ib_stream,
			"InnoDB: Error: log sequence number"
			" at shutdown %llu\n"
			"InnoDB: is lower than at startup %llu!\n",
			lsn, srv_start_lsn);
	}

	srv_shutdown_lsn = lsn;

	fil_write_flushed_lsn_to_data_files(lsn, arch_log_no);

	fil_flush_file_spaces(FIL_TABLESPACE);

	fil_close_all_files();

	/* Make some checks that the server really is quiet */
	ut_a(srv_n_threads_active[SRV_MASTER] == 0);
	ut_a(buf_all_freed());
	ut_a(lsn == log_sys->lsn);
}

#ifdef UNIV_LOG_DEBUG
/******************************************************//**
Checks by parsing that the catenated log segment for a single mtr is
consistent. */
UNIV_INTERN
ibool
log_check_log_recs(
/*===============*/
	const byte*	buf,		/*!< in: pointer to the start of
					the log segment in the
					log_sys->buf log buffer */
	ulint		len,		/*!< in: segment length in bytes */
	ib_uint64_t	buf_start_lsn)	/*!< in: buffer start lsn */
{
	ib_uint64_t	contiguous_lsn;
	ib_uint64_t	scanned_lsn;
	const byte*	start;
	const byte*	end;
	byte*		buf1;
	byte*		scan_buf;

	ut_ad(mutex_own(&(log_sys->mutex)));

	if (len == 0) {

		return(TRUE);
	}

	start = ut_align_down(buf, OS_FILE_LOG_BLOCK_SIZE);
	end = ut_align(buf + len, OS_FILE_LOG_BLOCK_SIZE);

	buf1 = mem_alloc((end - start) + OS_FILE_LOG_BLOCK_SIZE);
	scan_buf = ut_align(buf1, OS_FILE_LOG_BLOCK_SIZE);

	ut_memcpy(scan_buf, start, end - start);

	recv_scan_log_recs(recovery,
			   (buf_pool->curr_size
			    - recv_n_pool_free_frames) * UNIV_PAGE_SIZE,
			   FALSE, scan_buf, end - start,
			   ut_uint64_align_down(buf_start_lsn,
						OS_FILE_LOG_BLOCK_SIZE),
			   &contiguous_lsn, &scanned_lsn);

	ut_a(scanned_lsn == buf_start_lsn + len);
	ut_a(recv_sys->recovered_lsn == scanned_lsn);

	mem_free(buf1);

	return(TRUE);
}
#endif /* UNIV_LOG_DEBUG */

/******************************************************//**
Peeks the current lsn.
@return	TRUE if success, FALSE if could not get the log system mutex */
UNIV_INTERN
ibool
log_peek_lsn(
/*=========*/
	ib_uint64_t*	lsn)	/*!< out: if returns TRUE, current lsn is here */
{
	if (0 == mutex_enter_nowait(&(log_sys->mutex))) {
		*lsn = log_sys->lsn;

		log_release();

		return(TRUE);
	}

	return(FALSE);
}

/******************************************************//**
Prints info of the log. */
UNIV_INTERN
void
log_print(
/*======*/
	ib_stream_t	ib_stream)	/*!< in: file where to print */
{
	double	time_elapsed;
	time_t	current_time;

	log_acquire();

	ib_logger(ib_stream,
		"Log sequence number %llu\n"
		"Log flushed up to   %llu\n"
		"Last checkpoint at  %llu\n",
		log_sys->lsn,
		log_sys->flushed_to_disk_lsn,
		log_sys->last_checkpoint_lsn);

	current_time = time(NULL);

	time_elapsed = 0.001 + difftime(current_time,
					log_sys->last_printout_time);
	ib_logger(ib_stream,
		"%lu pending log writes, %lu pending chkp writes\n"
		"%lu log i/o's done, %.2f log i/o's/second\n",
		(ulong) log_sys->n_pending_writes,
		(ulong) log_sys->n_pending_checkpoint_writes,
		(ulong) log_sys->n_log_ios,
		((log_sys->n_log_ios - log_sys->n_log_ios_old)
		 / time_elapsed));

	log_sys->n_log_ios_old = log_sys->n_log_ios;
	log_sys->last_printout_time = current_time;

	log_release();
}

/**********************************************************************//**
Refreshes the statistics used to print per-second averages. */
UNIV_INTERN
void
log_refresh_stats(void)
/*===================*/
{
	log_sys->n_log_ios_old = log_sys->n_log_ios;
	log_sys->last_printout_time = time(NULL);
}

/**********************************************************************
Closes a log group. */
UNIV_STATIC
void
log_group_close(
/*===========*/
	log_group_t*	group)		/*!< in,own: log group to close */
{
	ulint		i;

	for (i = 0; i < group->n_files; ++i) {
		mem_free(group->file_header_bufs_ptr[i]);
#ifdef UNIV_LOG_ARCHIVE
		mem_free(group->archive_file_header_bufs_ptr[i]);
#endif
	}

	mem_free(group->file_header_bufs);
	mem_free(group->file_header_bufs_ptr);

#ifdef UNIV_LOG_ARCHIVE
	mem_free(group->archive_file_header_bufs);
	mem_free(group->archive_file_header_bufs_ptr);
#endif /* UNIV_LOG_ARCHIVE */

	mem_free(group->checkpoint_buf_ptr);

	mem_free(group);
}

/**********************************************************
Shutdown log system but doesn't release all the memory. */
UNIV_INTERN
void
log_shutdown(void)
/*==============*/
{
	log_group_t*	group;

	/* This can happen if we have to abort during startup. */
	if (log_sys == NULL || UT_LIST_GET_LEN(log_sys->log_groups) == 0) {
		return;
	}

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (UT_LIST_GET_LEN(log_sys->log_groups) > 0) {
		log_group_t*	prev_group = group;

		group = UT_LIST_GET_NEXT(log_groups, group);
		UT_LIST_REMOVE(log_groups, log_sys->log_groups, prev_group);

		log_group_close(prev_group);
	}

	mem_free(log_sys->buf_ptr);
	log_sys->buf_ptr = NULL;
	mem_free(log_sys->checkpoint_buf_ptr);
	log_sys->checkpoint_buf_ptr = NULL;

	os_event_free(log_sys->no_flush_event);
	os_event_free(log_sys->one_flushed_event);

	rw_lock_free(&log_sys->checkpoint_lock);

#ifdef UNIV_LOG_ARCHIVE
	rw_lock_free(&log_sys->archive_lock);
	// FIXME: ARCHIVE, changed to NULL
	os_event_create(NULL);
#endif /* UNIV_LOG_ARCHIVE */

#ifdef UNIV_LOG_DEBUG
	recv_sys_debug_free();
#endif

	recv_sys_close();
}

/**********************************************************
Free the log system data structures. */
UNIV_INTERN
void
log_mem_free(void)
/*==============*/
{
	if (log_sys != NULL) {
		recv_sys_mem_free();
		mem_free(log_sys);

		log_sys = NULL;
	}
}
#endif /* !UNIV_HOTBACKUP */
/*****************************************************************************

Copyright (c) 1997, 2010, Innobase Oy. All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA 02111-1307 USA

*****************************************************************************/

/**************************************************//**
@file log/log0recv.c
Recovery

Created 9/20/1997 Heikki Tuuri
*******************************************************/

#include "log0recv.h"

#ifdef UNIV_NONINL
#include "log0recv.ic"
#endif

#include "mem0mem.h"
#include "buf0buf.h"
#include "buf0flu.h"
#include "mtr0mtr.h"
#include "mtr0log.h"
#include "page0cur.h"
#ifdef WITH_ZIP
#include "page0zip.h"
#endif /* WITH_ZIP */
#include "btr0btr.h"
#include "btr0cur.h"
#include "ibuf0ibuf.h"
#include "trx0undo.h"
#include "trx0rec.h"
#include "fil0fil.h"
#ifndef UNIV_HOTBACKUP
# include "buf0rea.h"
# include "srv0srv.h"
# include "srv0start.h"
# include "trx0roll.h"
# include "ddl0ddl.h"
# include "sync0sync.h"
#else /* !UNIV_HOTBACKUP */
#include "btr0btr.h"

/** This is set to FALSE if the backup was originally taken with the
ibbackup --include regexp option: then we do not want to create tables in
directories which were not included */
UNIV_INTERN ibool	recv_replay_file_ops	= TRUE;
#endif /* !UNIV_HOTBACKUP */

/** Log records are stored in the hash table in chunks at most of this size;
this must be less than UNIV_PAGE_SIZE as it is stored in the buffer pool */
#define RECV_DATA_BLOCK_SIZE	(MEM_MAX_ALLOC_IN_BUF - sizeof(recv_data_t))

/** Read-ahead area in applying log records to file pages */
#define RECV_READ_AHEAD_AREA	32

/** The recovery system */
UNIV_INTERN recv_sys_t*	recv_sys = NULL;
/** TRUE when applying redo log records during crash recovery; FALSE
otherwise.  Note that this is FALSE while a background thread is
rolling back incomplete transactions. */
UNIV_INTERN ibool	recv_recovery_on;
#ifdef UNIV_LOG_ARCHIVE
/** TRUE when applying redo log records from an archived log file */
UNIV_INTERN ibool	recv_recovery_from_backup_on;
#endif /* UNIV_LOG_ARCHIVE */

#ifndef UNIV_HOTBACKUP
/** TRUE when recv_init_crash_recovery() has been called. */
UNIV_INTERN ibool	recv_needed_recovery;
# ifdef UNIV_DEBUG
/** TRUE if writing to the redo log (mtr_commit) is forbidden.
Protected by log_sys->mutex. */
UNIV_INTERN ibool	recv_no_log_write = FALSE;
# endif /* UNIV_DEBUG */

/** TRUE if buf_page_is_corrupted() should check if the log sequence
number (FIL_PAGE_LSN) is in the future.  Initially FALSE, and set by
recv_recovery_from_checkpoint_start_func(). */
UNIV_INTERN ibool	recv_lsn_checks_on;

/* User callback function that is called before InnoDB attempts to
rollback incomplete transaction after crash recovery. */
UNIV_INTERN ib_cb_t	recv_pre_rollback_hook = NULL;

/* There are two conditions under which we scan the logs, the first
is normal startup and the second is when we do a recovery from an
archive.
This flag is set if we are doing a scan from the last checkpoint during
startup. If we find log entries that were written after the last checkpoint
we know that the server was not cleanly shutdown. We must then initialize
the crash recovery environment before attempting to store these entries in
the log hash table. */
UNIV_STATIC ibool		recv_log_scan_is_startup_type;

/** If the following is TRUE, the buffer pool file pages must be invalidated
after recovery and no ibuf operations are allowed; this becomes TRUE if
the log record hash table becomes too full, and log records must be merged
to file pages already before the recovery is finished: in this case no
ibuf operations are allowed, as they could modify the pages read in the
buffer pool before the pages have been recovered to the up-to-date state.

TRUE means that recovery is running and no operations on the log files
are allowed yet: the variable name is misleading. */
UNIV_INTERN ibool	recv_no_ibuf_operations;
/** TRUE when the redo log is being backed up */
# define recv_is_making_a_backup		FALSE
/** TRUE when recovering from a backed up redo log file */
# define recv_is_from_backup			FALSE
#else /* !UNIV_HOTBACKUP */
# define recv_needed_recovery			FALSE
/** TRUE when the redo log is being backed up */
UNIV_INTERN ibool	recv_is_making_a_backup	= FALSE;
/** TRUE when recovering from a backed up redo log file */
UNIV_INTERN ibool	recv_is_from_backup	= FALSE;
# define buf_pool_get_curr_size() (5 * 1024 * 1024)
#endif /* !UNIV_HOTBACKUP */
/** The following counter is used to decide when to print info on
log scan */
UNIV_STATIC ulint	recv_scan_print_counter;

/** The type of the previous parsed redo log record */
UNIV_STATIC ulint	recv_previous_parsed_rec_type;
/** The offset of the previous parsed redo log record */
UNIV_STATIC ulint	recv_previous_parsed_rec_offset;
/** The 'multi' flag of the previous parsed redo log record */
UNIV_STATIC ulint	recv_previous_parsed_rec_is_multi;

/** Maximum page number encountered in the redo log */
UNIV_INTERN ulint	recv_max_parsed_page_no;

/** This many frames must be left free in the buffer pool when we scan
the log and store the scanned log records in the buffer pool: we will
use these free frames to read in pages when we start applying the
log records to the database. */
UNIV_INTERN ulint	recv_n_pool_free_frames;

/** The maximum lsn we see for a page during the recovery process. If this
is bigger than the lsn we are able to scan up to, that is an indication that
the recovery failed and the database may be corrupt. */
UNIV_INTERN ib_uint64_t	recv_max_page_lsn;

/* prototypes */

#ifndef UNIV_HOTBACKUP
/*******************************************************//**
Initialize crash recovery environment. Can be called iff
recv_needed_recovery == FALSE. */
UNIV_STATIC
void
recv_start_crash_recovery(
/*======================*/
	ib_recovery_t	recovery);	/*!< in: recovery flag */
#endif /* !UNIV_HOTBACKUP */

/********************************************************//**
Reset the state of the recovery system variables. */
UNIV_INTERN
void
recv_sys_var_init(void)
/*===================*/
{
	recv_sys = NULL;

	recv_lsn_checks_on = FALSE;

	recv_n_pool_free_frames = 256;

	recv_recovery_on = FALSE;

#ifdef UNIV_HOTBACKUP
	recv_recovery_from_backup_on = FALSE;
	recv_is_from_backup = FALSE;
#endif

	recv_needed_recovery = FALSE;

	recv_lsn_checks_on = FALSE;

	recv_log_scan_is_startup_type = FALSE;

	recv_no_ibuf_operations = FALSE;

	recv_scan_print_counter	= 0;


	recv_previous_parsed_rec_type	= 999999;

	recv_previous_parsed_rec_offset	= 0;

	recv_previous_parsed_rec_is_multi = 0;

	recv_max_parsed_page_no	= 0;

	recv_n_pool_free_frames	= 256;

	recv_max_page_lsn = 0;
}

/************************************************************
Creates the recovery system. */
UNIV_INTERN
void
recv_sys_create(void)
/*=================*/
{
	if (recv_sys != NULL) {

		return;
	}

	recv_sys = mem_alloc(sizeof(*recv_sys));
	memset(recv_sys, 0x0, sizeof(*recv_sys));

	mutex_create(&recv_sys->mutex, SYNC_RECV);

	recv_sys->heap = NULL;
	recv_sys->addr_hash = NULL;
}

/********************************************************//**
Release recovery system mutexes. */
UNIV_INTERN
void
recv_sys_close(void)
/*===============*/
{
	if (recv_sys != NULL) {
		mutex_free(&recv_sys->mutex);
		memset(&recv_sys->mutex, 0x0, sizeof(recv_sys->mutex));
	}
}

/************************************************************
Frees the recovery system memory. */
UNIV_INTERN
void
recv_sys_mem_free(void)
/*===================*/
{
	if (recv_sys != NULL) {
		if (recv_sys->addr_hash != NULL) {
			hash_table_free(recv_sys->addr_hash);
		}

		if (recv_sys->heap != NULL) {
			mem_heap_free(recv_sys->heap);
		}

		if (recv_sys->buf != NULL) {
			ut_free(recv_sys->buf);
		}

		if (recv_sys->last_block_buf_start != NULL) {
			mem_free(recv_sys->last_block_buf_start);
		}

		mem_free(recv_sys);
		recv_sys = NULL;
	}
}

/************************************************************
Inits the recovery system for a recovery operation. */
UNIV_INTERN
void
recv_sys_init(
/*==========*/
	ulint	available_memory)	/*!< in: available memory in bytes */
{
	if (recv_sys->heap != NULL) {

		return;
	}

	mutex_enter(&(recv_sys->mutex));

#ifndef UNIV_HOTBACKUP
	recv_sys->heap = mem_heap_create_in_buffer(256);
#else /* !UNIV_HOTBACKUP */
	recv_sys->heap = mem_heap_create(256);
	recv_is_from_backup = TRUE;
#endif /* !UNIV_HOTBACKUP */

	recv_sys->buf = ut_malloc(RECV_PARSING_BUF_SIZE);
	recv_sys->len = 0;
	recv_sys->recovered_offset = 0;

	recv_sys->addr_hash = hash_create(available_memory / 64);
	recv_sys->n_addrs = 0;

	recv_sys->apply_log_recs = FALSE;
	recv_sys->apply_batch_on = FALSE;

	recv_sys->last_block_buf_start = mem_alloc(2 * OS_FILE_LOG_BLOCK_SIZE);

	recv_sys->last_block = ut_align(recv_sys->last_block_buf_start,
					OS_FILE_LOG_BLOCK_SIZE);
	recv_sys->found_corrupt_log = FALSE;

	recv_max_page_lsn = 0;

	mutex_exit(&(recv_sys->mutex));
}

/********************************************************//**
Empties the hash table when it has been fully processed. */
UNIV_STATIC
void
recv_sys_empty_hash(void)
/*=====================*/
{
	ut_ad(mutex_own(&(recv_sys->mutex)));

	if (recv_sys->n_addrs != 0) {
		ib_logger(ib_stream,
			  "InnoDB: Error: %lu pages with log records"
			  " were left unprocessed!\n"
			  "InnoDB: Maximum page number with"
			  " log records on it %lu\n",
			  (ulong) recv_sys->n_addrs,
			  (ulong) recv_max_parsed_page_no);
		ut_error;
	}

	hash_table_free(recv_sys->addr_hash);
	mem_heap_empty(recv_sys->heap);

	recv_sys->addr_hash = hash_create(buf_pool_get_curr_size() / 256);
}

#ifndef UNIV_HOTBACKUP
# ifndef UNIV_LOG_DEBUG
/********************************************************//**
Frees the recovery system. */
UNIV_STATIC
void
recv_sys_debug_free(void)
/*=====================*/
{
	mutex_enter(&(recv_sys->mutex));

	hash_table_free(recv_sys->addr_hash);
	mem_heap_free(recv_sys->heap);
	ut_free(recv_sys->buf);
	mem_free(recv_sys->last_block_buf_start);

	recv_sys->buf = NULL;
	recv_sys->heap = NULL;
	recv_sys->addr_hash = NULL;
	recv_sys->last_block_buf_start = NULL;

	mutex_exit(&(recv_sys->mutex));
}
# endif /* UNIV_LOG_DEBUG */

/********************************************************//**
Truncates possible corrupted or extra records from a log group. */
UNIV_STATIC
void
recv_truncate_group(
/*================*/
	log_group_t*	group,		/*!< in: log group */
	ib_uint64_t	recovered_lsn,	/*!< in: recovery succeeded up to this
					lsn */
	ib_uint64_t	limit_lsn,	/*!< in: this was the limit for
					recovery */
	ib_uint64_t	checkpoint_lsn,	/*!< in: recovery was started from this
					checkpoint */
	ib_uint64_t	archived_lsn)	/*!< in: the log has been archived up to
					this lsn */
{
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	ib_uint64_t	finish_lsn1;
	ib_uint64_t	finish_lsn2;
	ib_uint64_t	finish_lsn;
	ulint		len;
	ulint		i;

	if (archived_lsn == IB_UINT64_T_MAX) {
		/* Checkpoint was taken in the NOARCHIVELOG mode */
		archived_lsn = checkpoint_lsn;
	}

	finish_lsn1 = ut_uint64_align_down(archived_lsn,
					   OS_FILE_LOG_BLOCK_SIZE)
		+ log_group_get_capacity(group);

	finish_lsn2 = ut_uint64_align_up(recovered_lsn,
					 OS_FILE_LOG_BLOCK_SIZE)
		+ recv_sys->last_log_buf_size;

	if (limit_lsn != IB_UINT64_T_MAX) {
		/* We do not know how far we should erase log records: erase
		as much as possible */

		finish_lsn = finish_lsn1;
	} else {
		/* It is enough to erase the length of the log buffer */
		finish_lsn = finish_lsn1 < finish_lsn2
			? finish_lsn1 : finish_lsn2;
	}

	ut_a(RECV_SCAN_SIZE <= log_sys->buf_size);

	/* Write the log buffer full of zeros */
	for (i = 0; i < RECV_SCAN_SIZE; i++) {

		*(log_sys->buf + i) = '\0';
	}

	start_lsn = ut_uint64_align_down(recovered_lsn,
					 OS_FILE_LOG_BLOCK_SIZE);

	if (start_lsn != recovered_lsn) {
		/* Copy the last incomplete log block to the log buffer and
		edit its data length: */

		ut_memcpy(log_sys->buf, recv_sys->last_block,
			  OS_FILE_LOG_BLOCK_SIZE);
		log_block_set_data_len(log_sys->buf,
				       (ulint) (recovered_lsn - start_lsn));
	}

	if (start_lsn >= finish_lsn) {

		return;
	}

	for (;;) {
		end_lsn = start_lsn + RECV_SCAN_SIZE;

		if (end_lsn > finish_lsn) {

			end_lsn = finish_lsn;
		}

		len = (ulint) (end_lsn - start_lsn);

		log_group_write_buf(group, log_sys->buf, len, start_lsn, 0);
		if (end_lsn >= finish_lsn) {

			return;
		}

		/* Write the log buffer full of zeros */
		for (i = 0; i < RECV_SCAN_SIZE; i++) {

			*(log_sys->buf + i) = '\0';
		}

		start_lsn = end_lsn;
	}
}

/********************************************************//**
Copies the log segment between group->recovered_lsn and recovered_lsn from the
most up-to-date log group to group, so that it contains the latest log data. */
UNIV_STATIC
void
recv_copy_group(
/*============*/
	log_group_t*	up_to_date_group,	/*!< in: the most up-to-date log
						group */
	log_group_t*	group,			/*!< in: copy to this log
						group */
	ib_uint64_t	recovered_lsn)		/*!< in: recovery succeeded up
						to this lsn */
{
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	ulint		len;

	if (group->scanned_lsn >= recovered_lsn) {

		return;
	}

	ut_a(RECV_SCAN_SIZE <= log_sys->buf_size);

	start_lsn = ut_uint64_align_down(group->scanned_lsn,
					 OS_FILE_LOG_BLOCK_SIZE);
	for (;;) {
		end_lsn = start_lsn + RECV_SCAN_SIZE;

		if (end_lsn > recovered_lsn) {
			end_lsn = ut_uint64_align_up(recovered_lsn,
						     OS_FILE_LOG_BLOCK_SIZE);
		}

		log_group_read_log_seg(LOG_RECOVER, log_sys->buf,
				       up_to_date_group, start_lsn, end_lsn);

		len = (ulint) (end_lsn - start_lsn);

		log_group_write_buf(group, log_sys->buf, len, start_lsn, 0);

		if (end_lsn >= recovered_lsn) {

			return;
		}

		start_lsn = end_lsn;
	}
}

/********************************************************//**
Copies a log segment from the most up-to-date log group to the other log
groups, so that they all contain the latest log data. Also writes the info
about the latest checkpoint to the groups, and inits the fields in the group
memory structs to up-to-date values. */
UNIV_STATIC
void
recv_synchronize_groups(
/*====================*/
	log_group_t*	up_to_date_group)	/*!< in: the most up-to-date
						log group */
{
	log_group_t*	group;
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	ib_uint64_t	recovered_lsn;
	ib_uint64_t	limit_lsn;

	recovered_lsn = recv_sys->recovered_lsn;
	limit_lsn = recv_sys->limit_lsn;

	/* Read the last recovered log block to the recovery system buffer:
	the block is always incomplete */

	start_lsn = ut_uint64_align_down(recovered_lsn,
					 OS_FILE_LOG_BLOCK_SIZE);
	end_lsn = ut_uint64_align_up(recovered_lsn, OS_FILE_LOG_BLOCK_SIZE);

	ut_a(start_lsn != end_lsn);

	log_group_read_log_seg(LOG_RECOVER, recv_sys->last_block,
			       up_to_date_group, start_lsn, end_lsn);

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group) {
		if (group != up_to_date_group) {

			/* Copy log data if needed */

			recv_copy_group(group, up_to_date_group,
					recovered_lsn);
		}

		/* Update the fields in the group struct to correspond to
		recovered_lsn */

		log_group_set_fields(group, recovered_lsn);

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	/* Copy the checkpoint info to the groups; remember that we have
	incremented checkpoint_no by one, and the info will not be written
	over the max checkpoint info, thus making the preservation of max
	checkpoint info on disk certain */

	log_groups_write_checkpoint_info();

	mutex_exit(&(log_sys->mutex));

	/* Wait for the checkpoint write to complete */
	rw_lock_s_lock(&(log_sys->checkpoint_lock));
	rw_lock_s_unlock(&(log_sys->checkpoint_lock));

	mutex_enter(&(log_sys->mutex));
}
#endif /* !UNIV_HOTBACKUP */

/***********************************************************************//**
Checks the consistency of the checkpoint info
@return	TRUE if ok */
UNIV_STATIC
ibool
recv_check_cp_is_consistent(
/*========================*/
	const byte*	buf)	/*!< in: buffer containing checkpoint info */
{
	ulint	fold;

	fold = ut_fold_binary(buf, LOG_CHECKPOINT_CHECKSUM_1);

	if ((fold & 0xFFFFFFFFUL) != mach_read_from_4(
		    buf + LOG_CHECKPOINT_CHECKSUM_1)) {
		return(FALSE);
	}

	fold = ut_fold_binary(buf + LOG_CHECKPOINT_LSN,
			      LOG_CHECKPOINT_CHECKSUM_2 - LOG_CHECKPOINT_LSN);

	if ((fold & 0xFFFFFFFFUL) != mach_read_from_4(
		    buf + LOG_CHECKPOINT_CHECKSUM_2)) {
		return(FALSE);
	}

	return(TRUE);
}

#ifndef UNIV_HOTBACKUP
/********************************************************//**
Looks for the maximum consistent checkpoint from the log groups.
@return	error code or DB_SUCCESS */
UNIV_STATIC
ulint
recv_find_max_checkpoint(
/*=====================*/
	log_group_t**	max_group,	/*!< out: max group */
	ulint*		max_field)	/*!< out: LOG_CHECKPOINT_1 or
					LOG_CHECKPOINT_2 */
{
	log_group_t*	group;
	ib_uint64_t	max_no;
	ib_uint64_t	checkpoint_no;
	ulint		field;
	byte*		buf;

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	max_no = 0;
	*max_group = NULL;
	*max_field = 0;

	buf = log_sys->checkpoint_buf;

	while (group) {
		group->state = LOG_GROUP_CORRUPTED;

		for (field = LOG_CHECKPOINT_1; field <= LOG_CHECKPOINT_2;
		     field += LOG_CHECKPOINT_2 - LOG_CHECKPOINT_1) {

			log_group_read_checkpoint_info(group, field);

			if (!recv_check_cp_is_consistent(buf)) {
#ifdef UNIV_DEBUG
				if (log_debug_writes) {
					ib_logger(ib_stream,
						  "InnoDB: Checkpoint in group"
						  " %lu at %lu invalid, %lu\n",
						  (ulong) group->id,
						  (ulong) field,
						  (ulong) mach_read_from_4(
							  buf
							  + LOG_CHECKPOINT_CHECKSUM_1));

				}
#endif /* UNIV_DEBUG */
				goto not_consistent;
			}

			group->state = LOG_GROUP_OK;

			group->lsn = mach_read_ull(
				buf + LOG_CHECKPOINT_LSN);
			group->lsn_offset = mach_read_from_4(
				buf + LOG_CHECKPOINT_OFFSET);
			checkpoint_no = mach_read_ull(
				buf + LOG_CHECKPOINT_NO);

#ifdef UNIV_DEBUG
			if (log_debug_writes) {
				ib_logger(ib_stream,
					  "InnoDB: Checkpoint number %lu"
					  " found in group %lu\n",
					  (ulong) checkpoint_no,
					  (ulong) group->id);
			}
#endif /* UNIV_DEBUG */

			if (checkpoint_no >= max_no) {
				*max_group = group;
				*max_field = field;
				max_no = checkpoint_no;
			}

not_consistent:
			;
		}

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	if (*max_group == NULL) {

		ib_logger(ib_stream,
			  "InnoDB: No valid checkpoint found.\n"
			  "InnoDB: If this error appears when you are"
			  " creating an InnoDB database,\n"
			  "InnoDB: the problem may be that during"
			  " an earlier attempt you managed\n"
			  "InnoDB: to create the InnoDB data files,"
			  " but log file creation failed.\n"
			  "InnoDB: If that is the case, please refer to\n"
			  "InnoDB: the InnoDB website for details\n");
		return(DB_ERROR);
	}

	return(DB_SUCCESS);
}
#else /* !UNIV_HOTBACKUP */
/*******************************************************************//**
Reads the checkpoint info needed in hot backup.
@return	TRUE if success */
UNIV_INTERN
ibool
recv_read_cp_info_for_backup(
/*=========================*/
	const byte*	hdr,	/*!< in: buffer containing the log group
				header */
	ib_uint64_t*	lsn,	/*!< out: checkpoint lsn */
	ulint*		offset,	/*!< out: checkpoint offset in the log group */
	ulint*		fsp_limit,/*!< out: fsp limit of space 0,
				1000000000 if the database is running
				with < version 3.23.50 of InnoDB */
	ib_uint64_t*	cp_no,	/*!< out: checkpoint number */
	ib_uint64_t*	first_header_lsn)
				/*!< out: lsn of of the start of the
				first log file */
{
	ulint		max_cp		= 0;
	ib_uint64_t	max_cp_no	= 0;
	const byte*	cp_buf;

	cp_buf = hdr + LOG_CHECKPOINT_1;

	if (recv_check_cp_is_consistent(cp_buf)) {
		max_cp_no = mach_read_ull(cp_buf + LOG_CHECKPOINT_NO);
		max_cp = LOG_CHECKPOINT_1;
	}

	cp_buf = hdr + LOG_CHECKPOINT_2;

	if (recv_check_cp_is_consistent(cp_buf)) {
		if (mach_read_ull(cp_buf + LOG_CHECKPOINT_NO) > max_cp_no) {
			max_cp = LOG_CHECKPOINT_2;
		}
	}

	if (max_cp == 0) {
		return(FALSE);
	}

	cp_buf = hdr + max_cp;

	*lsn = mach_read_ull(cp_buf + LOG_CHECKPOINT_LSN);
	*offset = mach_read_from_4(cp_buf + LOG_CHECKPOINT_OFFSET);

	/* If the user is running a pre-3.23.50 version of InnoDB, its
	checkpoint data does not contain the fsp limit info */
	if (mach_read_from_4(cp_buf + LOG_CHECKPOINT_FSP_MAGIC_N)
	    == LOG_CHECKPOINT_FSP_MAGIC_N_VAL) {

		*fsp_limit = mach_read_from_4(
			cp_buf + LOG_CHECKPOINT_FSP_FREE_LIMIT);

		if (*fsp_limit == 0) {
			*fsp_limit = 1000000000;
		}
	} else {
		*fsp_limit = 1000000000;
	}

	/* ib_logger(ib_stream, "fsp limit %lu MB\n", *fsp_limit); */

	*cp_no = mach_read_ull(cp_buf + LOG_CHECKPOINT_NO);

	*first_header_lsn = mach_read_ull(hdr + LOG_FILE_START_LSN);

	return(TRUE);
}
#endif /* !UNIV_HOTBACKUP */

/******************************************************//**
Checks the 4-byte checksum to the trailer checksum field of a log
block.  We also accept a log block in the old format before
InnoDB-3.23.52 where the checksum field contains the log block number.
@return TRUE if ok, or if the log block may be in the format of InnoDB
version predating 3.23.52 */
UNIV_STATIC
ibool
log_block_checksum_is_ok_or_old_format(
/*===================================*/
	const byte*	block)	/*!< in: pointer to a log block */
{
#ifdef UNIV_LOG_DEBUG
	return(TRUE);
#endif /* UNIV_LOG_DEBUG */
	if (log_block_calc_checksum(block) == log_block_get_checksum(block)) {

		return(TRUE);
	}

	if (log_block_get_hdr_no(block) == log_block_get_checksum(block)) {

		/* We assume the log block is in the format of
		InnoDB version < 3.23.52 and the block is ok */
#if 0
		ib_logger(ib_stream,
			  "InnoDB: Scanned old format < InnoDB-3.23.52"
			  " log block number %lu\n",
			  log_block_get_hdr_no(block));
#endif
		return(TRUE);
	}

	return(FALSE);
}

#ifdef UNIV_HOTBACKUP
/*******************************************************************//**
Scans the log segment and n_bytes_scanned is set to the length of valid
log scanned. */
UNIV_INTERN
void
recv_scan_log_seg_for_backup(
/*=========================*/
	byte*		buf,		/*!< in: buffer containing log data */
	ulint		buf_len,	/*!< in: data length in that buffer */
	ib_uint64_t*	scanned_lsn,	/*!< in/out: lsn of buffer start,
					we return scanned lsn */
	ulint*		scanned_checkpoint_no,
					/*!< in/out: 4 lowest bytes of the
					highest scanned checkpoint number so
					far */
	ulint*		n_bytes_scanned)/*!< out: how much we were able to
					scan, smaller than buf_len if log
					data ended here */
{
	ulint	data_len;
	byte*	log_block;
	ulint	no;

	*n_bytes_scanned = 0;

	for (log_block = buf; log_block < buf + buf_len;
	     log_block += OS_FILE_LOG_BLOCK_SIZE) {

		no = log_block_get_hdr_no(log_block);

#if 0
		ib_logger(ib_stream, "Log block header no %lu\n", no);
#endif

		if (no != log_block_convert_lsn_to_no(*scanned_lsn)
		    || !log_block_checksum_is_ok_or_old_format(log_block)) {
#if 0
			ib_logger(ib_stream,
				  "Log block n:o %lu, scanned lsn n:o %lu\n",
				  no,
				  log_block_convert_lsn_to_no(*scanned_lsn));
#endif
			/* Garbage or an incompletely written log block */

			log_block += OS_FILE_LOG_BLOCK_SIZE;
#if 0
			ib_logger(ib_stream,
				  "Next log block n:o %lu\n",
				  log_block_get_hdr_no(log_block));
#endif
			break;
		}

		if (*scanned_checkpoint_no > 0
		    && log_block_get_checkpoint_no(log_block)
		    < *scanned_checkpoint_no
		    && *scanned_checkpoint_no
		    - log_block_get_checkpoint_no(log_block)
		    > 0x80000000UL) {

			/* Garbage from a log buffer flush which was made
			before the most recent database recovery */
#if 0
			ib_logger(ib_stream,
				  "Scanned cp n:o %lu, block cp n:o %lu\n",
				  *scanned_checkpoint_no,
				  log_block_get_checkpoint_no(log_block));
#endif
			break;
		}

		data_len = log_block_get_data_len(log_block);

		*scanned_checkpoint_no
			= log_block_get_checkpoint_no(log_block);
		*scanned_lsn += data_len;

		*n_bytes_scanned += data_len;

		if (data_len < OS_FILE_LOG_BLOCK_SIZE) {
			/* Log data ends here */

#if 0
			ib_logger(ib_stream, "Log block data len %lu\n",
				  data_len);
#endif
			break;
		}
	}
}
#endif /* UNIV_HOTBACKUP */

/*******************************************************************//**
Tries to parse a single log record body and also applies it to a page if
specified. File ops are parsed, but not applied in this function.
@return	log record end, NULL if not a complete record */
UNIV_STATIC
byte*
recv_parse_or_apply_log_rec_body(
/*=============================*/
	byte		type,	/*!< in: type */
	byte*		ptr,	/*!< in: pointer to a buffer */
	byte*		end_ptr,/*!< in: pointer to the buffer end */
	buf_block_t*	block,	/*!< in/out: buffer block or NULL; if
				not NULL, then the log record is
				applied to the page, and the log
				record should be complete then */
	mtr_t*		mtr)	/*!< in: mtr or NULL; should be non-NULL
				if and only if block is non-NULL */
{
	dict_index_t*	index	= NULL;
	page_t*		page;
	page_zip_des_t*	page_zip;
#ifdef UNIV_DEBUG
	ulint		page_type;
#endif /* UNIV_DEBUG */

	ut_ad(!block == !mtr);

	if (block) {
		page = block->frame;
		page_zip = buf_block_get_page_zip(block);
		ut_d(page_type = fil_page_get_type(page));
	} else {
		page = NULL;
		page_zip = NULL;
		ut_d(page_type = FIL_PAGE_TYPE_ALLOCATED);
	}

	switch (type) {
#ifdef UNIV_LOG_LSN_DEBUG
	case MLOG_LSN:
		/* The LSN is checked in recv_parse_log_rec(). */
		break;
#endif /* UNIV_LOG_LSN_DEBUG */
	case MLOG_1BYTE: case MLOG_2BYTES: case MLOG_4BYTES: case MLOG_8BYTES:
#ifdef UNIV_DEBUG
		if (page && page_type == FIL_PAGE_TYPE_ALLOCATED
		    && end_ptr >= ptr + 2) {
			/* It is OK to set FIL_PAGE_TYPE and certain
			list node fields on an empty page.  Any other
			write is not OK. */

			/* NOTE: There may be bogus assertion failures for
			dict_hdr_create(), trx_rseg_header_create(),
			trx_sys_create_doublewrite_buf(), and
			trx_sysf_create().
			These are only called during database creation. */
			ulint	offs = mach_read_from_2(ptr);

			switch (type) {
			default:
				ut_error;
			case MLOG_2BYTES:
				/* Note that this can fail when the
				redo log been written with something
				older than InnoDB Plugin 1.0.4. */
				ut_ad(offs == FIL_PAGE_TYPE
				      || offs == IBUF_TREE_SEG_HEADER
				      + IBUF_HEADER + FSEG_HDR_OFFSET
				      || offs == PAGE_BTR_IBUF_FREE_LIST
				      + PAGE_HEADER + FIL_ADDR_BYTE
				      || offs == PAGE_BTR_IBUF_FREE_LIST
				      + PAGE_HEADER + FIL_ADDR_BYTE
				      + FIL_ADDR_SIZE
				      || offs == PAGE_BTR_SEG_LEAF
				      + PAGE_HEADER + FSEG_HDR_OFFSET
				      || offs == PAGE_BTR_SEG_TOP
				      + PAGE_HEADER + FSEG_HDR_OFFSET
				      || offs == PAGE_BTR_IBUF_FREE_LIST_NODE
				      + PAGE_HEADER + FIL_ADDR_BYTE
				      + 0 /*FLST_PREV*/
				      || offs == PAGE_BTR_IBUF_FREE_LIST_NODE
				      + PAGE_HEADER + FIL_ADDR_BYTE
				      + FIL_ADDR_SIZE /*FLST_NEXT*/);
				break;
			case MLOG_4BYTES:
				/* Note that this can fail when the
				redo log been written with something
				older than InnoDB Plugin 1.0.4. */
				ut_ad(0
				      || offs == IBUF_TREE_SEG_HEADER
				      + IBUF_HEADER + FSEG_HDR_SPACE
				      || offs == IBUF_TREE_SEG_HEADER
				      + IBUF_HEADER + FSEG_HDR_PAGE_NO
				      || offs == PAGE_BTR_IBUF_FREE_LIST
				      + PAGE_HEADER/* flst_init */
				      || offs == PAGE_BTR_IBUF_FREE_LIST
				      + PAGE_HEADER + FIL_ADDR_PAGE
				      || offs == PAGE_BTR_IBUF_FREE_LIST
				      + PAGE_HEADER + FIL_ADDR_PAGE
				      + FIL_ADDR_SIZE
				      || offs == PAGE_BTR_SEG_LEAF
				      + PAGE_HEADER + FSEG_HDR_PAGE_NO
				      || offs == PAGE_BTR_SEG_LEAF
				      + PAGE_HEADER + FSEG_HDR_SPACE
				      || offs == PAGE_BTR_SEG_TOP
				      + PAGE_HEADER + FSEG_HDR_PAGE_NO
				      || offs == PAGE_BTR_SEG_TOP
				      + PAGE_HEADER + FSEG_HDR_SPACE
				      || offs == PAGE_BTR_IBUF_FREE_LIST_NODE
				      + PAGE_HEADER + FIL_ADDR_PAGE
				      + 0 /*FLST_PREV*/
				      || offs == PAGE_BTR_IBUF_FREE_LIST_NODE
				      + PAGE_HEADER + FIL_ADDR_PAGE
				      + FIL_ADDR_SIZE /*FLST_NEXT*/);
				break;
			}
		}
#endif /* UNIV_DEBUG */
		ptr = mlog_parse_nbytes(type, ptr, end_ptr, page, page_zip);
		break;
	case MLOG_REC_INSERT: case MLOG_COMP_REC_INSERT:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_REC_INSERT,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = page_cur_parse_insert_rec(FALSE, ptr, end_ptr,
							block, index, mtr);
		}
		break;
	case MLOG_REC_CLUST_DELETE_MARK: case MLOG_COMP_REC_CLUST_DELETE_MARK:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_REC_CLUST_DELETE_MARK,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = btr_cur_parse_del_mark_set_clust_rec(
				ptr, end_ptr, page, page_zip, index);
		}
		break;
	case MLOG_COMP_REC_SEC_DELETE_MARK:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		/* This log record type is obsolete, but we process it for
		backward compatibility with v5.0.3 and v5.0.4. */
		ut_a(!page || page_is_comp(page));
		ut_a(!page_zip);
		ptr = mlog_parse_index(ptr, end_ptr, TRUE, &index);
		if (!ptr) {
			break;
		}
		/* Fall through */
	case MLOG_REC_SEC_DELETE_MARK:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		ptr = btr_cur_parse_del_mark_set_sec_rec(ptr, end_ptr,
							 page, page_zip);
		break;
	case MLOG_REC_UPDATE_IN_PLACE: case MLOG_COMP_REC_UPDATE_IN_PLACE:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_REC_UPDATE_IN_PLACE,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = btr_cur_parse_update_in_place(ptr, end_ptr, page,
							    page_zip, index);
		}
		break;
	case MLOG_LIST_END_DELETE: case MLOG_COMP_LIST_END_DELETE:
	case MLOG_LIST_START_DELETE: case MLOG_COMP_LIST_START_DELETE:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_LIST_END_DELETE
				     || type == MLOG_COMP_LIST_START_DELETE,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = page_parse_delete_rec_list(type, ptr, end_ptr,
							 block, index, mtr);
		}
		break;
	case MLOG_LIST_END_COPY_CREATED: case MLOG_COMP_LIST_END_COPY_CREATED:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_LIST_END_COPY_CREATED,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = page_parse_copy_rec_list_to_created_page(
				ptr, end_ptr, block, index, mtr);
		}
		break;
	case MLOG_PAGE_REORGANIZE: case MLOG_COMP_PAGE_REORGANIZE:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_PAGE_REORGANIZE,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = btr_parse_page_reorganize(ptr, end_ptr, index,
							block, mtr);
		}
		break;
	case MLOG_PAGE_CREATE: case MLOG_COMP_PAGE_CREATE:
		/* Allow anything in page_type when creating a page. */
		ut_a(!page_zip);
		ptr = page_parse_create(ptr, end_ptr,
					type == MLOG_COMP_PAGE_CREATE,
					block, mtr);
		break;
	case MLOG_UNDO_INSERT:
		ut_ad(!page || page_type == FIL_PAGE_UNDO_LOG);
		ptr = trx_undo_parse_add_undo_rec(ptr, end_ptr, page);
		break;
	case MLOG_UNDO_ERASE_END:
		ut_ad(!page || page_type == FIL_PAGE_UNDO_LOG);
		ptr = trx_undo_parse_erase_page_end(ptr, end_ptr, page, mtr);
		break;
	case MLOG_UNDO_INIT:
		/* Allow anything in page_type when creating a page. */
		ptr = trx_undo_parse_page_init(ptr, end_ptr, page, mtr);
		break;
	case MLOG_UNDO_HDR_DISCARD:
		ut_ad(!page || page_type == FIL_PAGE_UNDO_LOG);
		ptr = trx_undo_parse_discard_latest(ptr, end_ptr, page, mtr);
		break;
	case MLOG_UNDO_HDR_CREATE:
	case MLOG_UNDO_HDR_REUSE:
		ut_ad(!page || page_type == FIL_PAGE_UNDO_LOG);
		ptr = trx_undo_parse_page_header(type, ptr, end_ptr,
						 page, mtr);
		break;
	case MLOG_REC_MIN_MARK: case MLOG_COMP_REC_MIN_MARK:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		/* On a compressed page, MLOG_COMP_REC_MIN_MARK
		will be followed by MLOG_COMP_REC_DELETE
		or MLOG_ZIP_WRITE_HEADER(FIL_PAGE_PREV, FIL_NULL)
		in the same mini-transaction. */
		ut_a(type == MLOG_COMP_REC_MIN_MARK || !page_zip);
		ptr = btr_parse_set_min_rec_mark(
			ptr, end_ptr, type == MLOG_COMP_REC_MIN_MARK,
			page, mtr);
		break;
	case MLOG_REC_DELETE: case MLOG_COMP_REC_DELETE:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);

		if (NULL != (ptr = mlog_parse_index(
				     ptr, end_ptr,
				     type == MLOG_COMP_REC_DELETE,
				     &index))) {
			ut_a(!page
			     || (ibool)!!page_is_comp(page)
			     == dict_table_is_comp(index->table));
			ptr = page_cur_parse_delete_rec(ptr, end_ptr,
							block, index, mtr);
		}
		break;
	case MLOG_IBUF_BITMAP_INIT:
		/* Allow anything in page_type when creating a page. */
		ptr = ibuf_parse_bitmap_init(ptr, end_ptr, block, mtr);
		break;
	case MLOG_INIT_FILE_PAGE:
		/* Allow anything in page_type when creating a page. */
		ptr = fsp_parse_init_file_page(ptr, end_ptr, block);
		break;
	case MLOG_WRITE_STRING:
		ut_ad(!page || page_type != FIL_PAGE_TYPE_ALLOCATED);
		ptr = mlog_parse_string(ptr, end_ptr, page, page_zip);
		break;
	case MLOG_FILE_CREATE:
	case MLOG_FILE_RENAME:
	case MLOG_FILE_DELETE:
	case MLOG_FILE_CREATE2:
		ptr = fil_op_log_parse_or_replay(ptr, end_ptr, type, 0, 0);
		break;
#ifdef WITH_ZIP
	case MLOG_ZIP_WRITE_NODE_PTR:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		ptr = page_zip_parse_write_node_ptr(ptr, end_ptr,
						    page, page_zip);
		break;
	case MLOG_ZIP_WRITE_BLOB_PTR:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		ptr = page_zip_parse_write_blob_ptr(ptr, end_ptr,
						    page, page_zip);
		break;
	case MLOG_ZIP_WRITE_HEADER:
		ut_ad(!page || page_type == FIL_PAGE_INDEX);
		ptr = page_zip_parse_write_header(ptr, end_ptr,
						  page, page_zip);
		break;
	case MLOG_ZIP_PAGE_COMPRESS:
		/* Allow anything in page_type when creating a page. */
		ptr = page_zip_parse_compress(ptr, end_ptr,
					      page, page_zip);
		break;
#endif /* WITH_ZIP */
	default:
		ptr = NULL;
		recv_sys->found_corrupt_log = TRUE;
	}

	if (index) {
		dict_table_t*	table = index->table;

		dict_mem_index_free(index);
		dict_mem_table_free(table);
	}

	return(ptr);
}

/*********************************************************************//**
Calculates the fold value of a page file address: used in inserting or
searching for a log record in the hash table.
@return	folded value */
UNIV_INLINE
ulint
recv_fold(
/*======*/
	ulint	space,	/*!< in: space */
	ulint	page_no)/*!< in: page number */
{
	return(ut_fold_ulint_pair(space, page_no));
}

/*********************************************************************//**
Calculates the hash value of a page file address: used in inserting or
searching for a log record in the hash table.
@return	folded value */
UNIV_INLINE
ulint
recv_hash(
/*======*/
	ulint	space,	/*!< in: space */
	ulint	page_no)/*!< in: page number */
{
	return(hash_calc_hash(recv_fold(space, page_no), recv_sys->addr_hash));
}

/*********************************************************************//**
Gets the hashed file address struct for a page.
@return	file address struct, NULL if not found from the hash table */
UNIV_STATIC
recv_addr_t*
recv_get_fil_addr_struct(
/*=====================*/
	ulint	space,	/*!< in: space id */
	ulint	page_no)/*!< in: page number */
{
	recv_addr_t*	recv_addr;

	recv_addr = HASH_GET_FIRST(recv_sys->addr_hash,
				   recv_hash(space, page_no));
	while (recv_addr) {
		if ((recv_addr->space == space)
		    && (recv_addr->page_no == page_no)) {

			break;
		}

		recv_addr = HASH_GET_NEXT(addr_hash, recv_addr);
	}

	return(recv_addr);
}

/*******************************************************************//**
Adds a new log record to the hash table of log records. */
UNIV_STATIC
void
recv_add_to_hash_table(
/*===================*/
	byte		type,		/*!< in: log record type */
	ulint		space,		/*!< in: space id */
	ulint		page_no,	/*!< in: page number */
	byte*		body,		/*!< in: log record body */
	byte*		rec_end,	/*!< in: log record end */
	ib_uint64_t	start_lsn,	/*!< in: start lsn of the mtr */
	ib_uint64_t	end_lsn)	/*!< in: end lsn of the mtr */
{
	recv_t*		recv;
	ulint		len;
	recv_data_t*	recv_data;
	recv_data_t**	prev_field;
	recv_addr_t*	recv_addr;

	if (fil_tablespace_deleted_or_being_deleted_in_mem(space, -1)) {
		/* The tablespace does not exist any more: do not store the
		log record */

		return;
	}

	len = rec_end - body;

	recv = mem_heap_alloc(recv_sys->heap, sizeof(recv_t));
	recv->type = type;
	recv->len = rec_end - body;
	recv->start_lsn = start_lsn;
	recv->end_lsn = end_lsn;

	recv_addr = recv_get_fil_addr_struct(space, page_no);

	if (recv_addr == NULL) {
		recv_addr = mem_heap_alloc(recv_sys->heap,
					   sizeof(recv_addr_t));
		recv_addr->space = space;
		recv_addr->page_no = page_no;
		recv_addr->state = RECV_NOT_PROCESSED;

		UT_LIST_INIT(recv_addr->rec_list);

		HASH_INSERT(recv_addr_t, addr_hash, recv_sys->addr_hash,
			    recv_fold(space, page_no), recv_addr);
		recv_sys->n_addrs++;
#if 0
		ib_logger(ib_stream, "Inserting log rec for space %lu, page %lu\n",
			  space, page_no);
#endif
	}

	UT_LIST_ADD_LAST(rec_list, recv_addr->rec_list, recv);

	prev_field = &(recv->data);

	/* Store the log record body in chunks of less than UNIV_PAGE_SIZE:
	recv_sys->heap grows into the buffer pool, and bigger chunks could not
	be allocated */

	while (rec_end > body) {

		len = rec_end - body;

		if (len > RECV_DATA_BLOCK_SIZE) {
			len = RECV_DATA_BLOCK_SIZE;
		}

		recv_data = mem_heap_alloc(recv_sys->heap,
					   sizeof(recv_data_t) + len);
		*prev_field = recv_data;

		memcpy(recv_data + 1, body, len);

		prev_field = &(recv_data->next);

		body += len;
	}

	*prev_field = NULL;
}

/*********************************************************************//**
Copies the log record body from recv to buf. */
UNIV_STATIC
void
recv_data_copy_to_buf(
/*==================*/
	byte*	buf,	/*!< in: buffer of length at least recv->len */
	recv_t*	recv)	/*!< in: log record */
{
	recv_data_t*	recv_data;
	ulint		part_len;
	ulint		len;

	len = recv->len;
	recv_data = recv->data;

	while (len > 0) {
		if (len > RECV_DATA_BLOCK_SIZE) {
			part_len = RECV_DATA_BLOCK_SIZE;
		} else {
			part_len = len;
		}

		ut_memcpy(buf, ((byte*)recv_data) + sizeof(recv_data_t),
			  part_len);
		buf += part_len;
		len -= part_len;

		recv_data = recv_data->next;
	}
}

/************************************************************************//**
Applies the hashed log records to the page, if the page lsn is less than the
lsn of a log record. This can be called when a buffer page has just been
read in, or also for a page already in the buffer pool. */
UNIV_INTERN
void
recv_recover_page_func(
/*===================*/
#ifndef UNIV_HOTBACKUP
	ibool		just_read_in,
				/*!< in: TRUE if the i/o handler calls
				this for a freshly read page */
#endif /* !UNIV_HOTBACKUP */
	buf_block_t*	block)	/*!< in/out: buffer block */
{
	page_t*		page;
	page_zip_des_t*	page_zip;
	recv_addr_t*	recv_addr;
	recv_t*		recv;
	byte*		buf;
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;
	ib_uint64_t	page_lsn;
	ib_uint64_t	page_newest_lsn;
	ibool		modification_to_page;
#ifndef UNIV_HOTBACKUP
	ibool		success;
#endif /* !UNIV_HOTBACKUP */
	mtr_t		mtr;

	mutex_enter(&(recv_sys->mutex));

	if (recv_sys->apply_log_recs == FALSE) {

		/* Log records should not be applied now */

		mutex_exit(&(recv_sys->mutex));

		return;
	}

	recv_addr = recv_get_fil_addr_struct(buf_block_get_space(block),
					     buf_block_get_page_no(block));

	if ((recv_addr == NULL)
	    || (recv_addr->state == RECV_BEING_PROCESSED)
	    || (recv_addr->state == RECV_PROCESSED)) {

		mutex_exit(&(recv_sys->mutex));

		return;
	}

#if 0
	ib_logger(ib_stream, "Recovering space %lu, page %lu\n",
		  buf_block_get_space(block), buf_block_get_page_no(block));
#endif

	recv_addr->state = RECV_BEING_PROCESSED;

	mutex_exit(&(recv_sys->mutex));

	mtr_start(&mtr);
	mtr_set_log_mode(&mtr, MTR_LOG_NONE);

	page = block->frame;
	page_zip = buf_block_get_page_zip(block);

#ifndef UNIV_HOTBACKUP
	if (just_read_in) {
		/* Move the ownership of the x-latch on the page to
		this OS thread, so that we can acquire a second
		x-latch on it.  This is needed for the operations to
		the page to pass the debug checks. */

		rw_lock_x_lock_move_ownership(&block->lock);
	}

	success = buf_page_get_known_nowait(RW_X_LATCH, block,
					    BUF_KEEP_OLD,
					    __FILE__, __LINE__,
					    &mtr);
	ut_a(success);

	buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
#endif /* !UNIV_HOTBACKUP */

	/* Read the newest modification lsn from the page */
	page_lsn = mach_read_ull(page + FIL_PAGE_LSN);

#ifndef UNIV_HOTBACKUP
	/* It may be that the page has been modified in the buffer
	pool: read the newest modification lsn there */

	page_newest_lsn = buf_page_get_newest_modification(&block->page);

	if (page_newest_lsn) {

		page_lsn = page_newest_lsn;
	}
#else /* !UNIV_HOTBACKUP */
	/* In recovery from a backup we do not really use the buffer pool */
	page_newest_lsn = 0;
#endif /* !UNIV_HOTBACKUP */

	modification_to_page = FALSE;
	start_lsn = end_lsn = 0;

	recv = UT_LIST_GET_FIRST(recv_addr->rec_list);

	while (recv) {
		end_lsn = recv->end_lsn;

		if (recv->len > RECV_DATA_BLOCK_SIZE) {
			/* We have to copy the record body to a separate
			buffer */

			buf = mem_alloc(recv->len);

			recv_data_copy_to_buf(buf, recv);
		} else {
			buf = ((byte*)(recv->data)) + sizeof(recv_data_t);
		}

		if (recv->type == MLOG_INIT_FILE_PAGE) {
			page_lsn = page_newest_lsn;

			memset(FIL_PAGE_LSN + page, 0, 8);
			memset(UNIV_PAGE_SIZE - FIL_PAGE_END_LSN_OLD_CHKSUM
			       + page, 0, 8);

			if (page_zip) {
				memset(FIL_PAGE_LSN + page_zip->data, 0, 8);
			}
		}

		if (recv->start_lsn >= page_lsn) {

			ib_uint64_t	end_lsn;

			if (!modification_to_page) {

				modification_to_page = TRUE;
				start_lsn = recv->start_lsn;
			}

#ifdef UNIV_DEBUG
			if (log_debug_writes) {
				ib_logger(ib_stream,
					  "InnoDB: Applying log rec"
					  " type %lu len %lu"
					  " to space %lu page no %lu\n",
					  (ulong) recv->type,
					  (ulong) recv->len,
					  (ulong) recv_addr->space,
					  (ulong) recv_addr->page_no);
			}
#endif /* UNIV_DEBUG */

			recv_parse_or_apply_log_rec_body(recv->type, buf,
							 buf + recv->len,
							 block, &mtr);

			end_lsn = recv->start_lsn + recv->len;
			mach_write_ull(FIL_PAGE_LSN + page, end_lsn);
			mach_write_ull(UNIV_PAGE_SIZE
				       - FIL_PAGE_END_LSN_OLD_CHKSUM
				       + page, end_lsn);

			if (page_zip) {
				mach_write_ull(FIL_PAGE_LSN
					       + page_zip->data, end_lsn);
			}
		}

		if (recv->len > RECV_DATA_BLOCK_SIZE) {
			mem_free(buf);
		}

		recv = UT_LIST_GET_NEXT(rec_list, recv);
	}

#ifdef UNIV_ZIP_DEBUG
	if (fil_page_get_type(page) == FIL_PAGE_INDEX) {
		page_zip_des_t*	page_zip = buf_block_get_page_zip(block);

		if (page_zip) {
			ut_a(page_zip_validate_low(page_zip, page, FALSE));
		}
	}
#endif /* UNIV_ZIP_DEBUG */

	mutex_enter(&(recv_sys->mutex));

	if (recv_max_page_lsn < page_lsn) {
		recv_max_page_lsn = page_lsn;
	}

	recv_addr->state = RECV_PROCESSED;

	ut_a(recv_sys->n_addrs);
	recv_sys->n_addrs--;

	mutex_exit(&(recv_sys->mutex));

#ifndef UNIV_HOTBACKUP
	if (modification_to_page) {
		ut_a(block);

		buf_flush_recv_note_modification(block, start_lsn, end_lsn);
	}
#endif /* !UNIV_HOTBACKUP */

	/* Make sure that committing mtr does not change the modification
	lsn values of page */

	mtr.modifications = FALSE;

	mtr_commit(&mtr);
}

#ifndef UNIV_HOTBACKUP
/*******************************************************************//**
Reads in pages which have hashed log records, from an area around a given
page number.
@return	number of pages found */
UNIV_STATIC
ulint
recv_read_in_area(
/*==============*/
	ulint	space,	/*!< in: space */
	ulint	zip_size,/*!< in: compressed page size in bytes, or 0 */
	ulint	page_no)/*!< in: page number */
{
	recv_addr_t* recv_addr;
	ulint	page_nos[RECV_READ_AHEAD_AREA];
	ulint	low_limit;
	ulint	n;

	low_limit = page_no - (page_no % RECV_READ_AHEAD_AREA);

	n = 0;

	for (page_no = low_limit; page_no < low_limit + RECV_READ_AHEAD_AREA;
	     page_no++) {
		recv_addr = recv_get_fil_addr_struct(space, page_no);

		if (recv_addr && !buf_page_peek(space, page_no)) {

			mutex_enter(&(recv_sys->mutex));

			if (recv_addr->state == RECV_NOT_PROCESSED) {
				recv_addr->state = RECV_BEING_READ;

				page_nos[n] = page_no;

				n++;
			}

			mutex_exit(&(recv_sys->mutex));
		}
	}

	buf_read_recv_pages(FALSE, space, zip_size, page_nos, n);
	/*
	ib_logger(ib_stream, "Recv pages at %lu n %lu\n", page_nos[0], n);
	*/
	return(n);
}

/*******************************************************************//**
Empties the hash table of stored log records, applying them to appropriate
pages. */
UNIV_INTERN
void
recv_apply_hashed_log_recs(
/*=======================*/
	ibool	allow_ibuf)	/*!< in: if TRUE, also ibuf operations are
				allowed during the application; if FALSE,
				no ibuf operations are allowed, and after
				the application all file pages are flushed to
				disk and invalidated in buffer pool: this
				alternative means that no new log records
				can be generated during the application;
				the caller must in this case own the log
				mutex */
{
	recv_addr_t* recv_addr;
	ulint	i;
	ulint	n_pages;
	ibool	has_printed	= FALSE;
	mtr_t	mtr;
loop:
	mutex_enter(&(recv_sys->mutex));

	if (recv_sys->apply_batch_on) {

		mutex_exit(&(recv_sys->mutex));

		os_thread_sleep(500000);

		goto loop;
	}

	ut_ad(!allow_ibuf == mutex_own(&log_sys->mutex));

	if (!allow_ibuf) {
		recv_no_ibuf_operations = TRUE;
	}

	recv_sys->apply_log_recs = TRUE;
	recv_sys->apply_batch_on = TRUE;

	for (i = 0; i < hash_get_n_cells(recv_sys->addr_hash); i++) {

		recv_addr = HASH_GET_FIRST(recv_sys->addr_hash, i);

		while (recv_addr) {
			ulint	space = recv_addr->space;
			ulint	zip_size = fil_space_get_zip_size(space);
			ulint	page_no = recv_addr->page_no;

			if (recv_addr->state == RECV_NOT_PROCESSED) {
				if (!has_printed) {
					ut_print_timestamp(ib_stream);
					ib_logger(ib_stream,
						  " InnoDB: Starting an apply "
						  "batch of log records to the "
						  "database...\n"
						  "InnoDB: Progress in percents: ");
					has_printed = TRUE;
				}

				mutex_exit(&(recv_sys->mutex));

				if (buf_page_peek(space, page_no)) {
					buf_block_t*	block;

					mtr_start(&mtr);

					block = buf_page_get(
						space, zip_size, page_no,
						RW_X_LATCH, &mtr);
					buf_block_dbg_add_level(
						block, SYNC_NO_ORDER_CHECK);

					recv_recover_page(FALSE, block);
					mtr_commit(&mtr);
				} else {
					recv_read_in_area(space, zip_size,
							  page_no);
				}

				mutex_enter(&(recv_sys->mutex));
			}

			recv_addr = HASH_GET_NEXT(addr_hash, recv_addr);
		}

		if (has_printed
		    && (i * 100) / hash_get_n_cells(recv_sys->addr_hash)
		    != ((i + 1) * 100)
		    / hash_get_n_cells(recv_sys->addr_hash)) {

			ib_logger(ib_stream, "%lu ", (ulong)
				  ((i * 100)
				   / hash_get_n_cells(recv_sys->addr_hash)));
		}
	}

	/* Wait until all the pages have been processed */

	while (recv_sys->n_addrs != 0) {

		mutex_exit(&(recv_sys->mutex));

		os_thread_sleep(500000);

		mutex_enter(&(recv_sys->mutex));
	}

	if (has_printed) {
		ib_logger(ib_stream, "\n");
	}

	if (!allow_ibuf) {
		/* Flush all the file pages to disk and invalidate them in
		the buffer pool */

		ut_d(recv_no_log_write = TRUE);
		mutex_exit(&(recv_sys->mutex));
		mutex_exit(&(log_sys->mutex));

		n_pages = buf_flush_batch(BUF_FLUSH_LIST, ULINT_MAX,
					  IB_UINT64_T_MAX);
		ut_a(n_pages != ULINT_UNDEFINED);

		buf_flush_wait_batch_end(BUF_FLUSH_LIST);

		buf_pool_invalidate();

		mutex_enter(&(log_sys->mutex));
		mutex_enter(&(recv_sys->mutex));
		ut_d(recv_no_log_write = FALSE);

		recv_no_ibuf_operations = FALSE;
	}

	recv_sys->apply_log_recs = FALSE;
	recv_sys->apply_batch_on = FALSE;

	recv_sys_empty_hash();

	if (has_printed) {
		ib_logger(ib_stream, "InnoDB: Apply batch completed\n");
	}

	mutex_exit(&(recv_sys->mutex));
}
#else /* !UNIV_HOTBACKUP */
/*******************************************************************//**
Applies log records in the hash table to a backup. */
UNIV_INTERN
void
recv_apply_log_recs_for_backup(void)
/*================================*/
{
	recv_addr_t*	recv_addr;
	ulint		n_hash_cells;
	buf_block_t*	block;
	ulint		actual_size;
	ibool		success;
	ulint		error;
	ulint		i;

	recv_sys->apply_log_recs = TRUE;
	recv_sys->apply_batch_on = TRUE;

	block = back_block1;

	ib_logger(ib_stream,
		  "InnoDB: Starting an apply batch of log records "
		  "to the database...\n"
		  "InnoDB: Progress in percents: ");

	n_hash_cells = hash_get_n_cells(recv_sys->addr_hash);

	for (i = 0; i < n_hash_cells; i++) {
		/* The address hash table is externally chained */
		recv_addr = hash_get_nth_cell(recv_sys->addr_hash, i)->node;

		while (recv_addr != NULL) {

			ulint	zip_size
				= fil_space_get_zip_size(recv_addr->space);

			if (zip_size == ULINT_UNDEFINED) {
#if 0
				ib_logger(ib_stream,
					  "InnoDB: Warning: cannot apply"
					  " log record to"
					  " tablespace %lu page %lu,\n"
					  "InnoDB: because tablespace with"
					  " that id does not exist.\n",
					  recv_addr->space, recv_addr->page_no);
#endif
				recv_addr->state = RECV_PROCESSED;

				ut_a(recv_sys->n_addrs);
				recv_sys->n_addrs--;

				goto skip_this_recv_addr;
			}

			/* We simulate a page read made by the buffer pool, to
			make sure the recovery apparatus works ok. We must init
			the block. */

			buf_page_init_for_backup_restore(
				recv_addr->space, recv_addr->page_no,
				zip_size, block);

			/* Extend the tablespace's last file if the page_no
			does not fall inside its bounds; we assume the last
			file is auto-extending, and ibbackup copied the file
			when it still was smaller */

			success = fil_extend_space_to_desired_size(
				&actual_size,
				recv_addr->space, recv_addr->page_no + 1);
			if (!success) {
				ib_logger(ib_stream,
					  "InnoDB: Fatal error: cannot extend"
					  " tablespace %lu to hold %lu pages\n",
					  recv_addr->space,
					  recv_addr->page_no);
				exit(1);
			}

			/* Read the page from the tablespace file using the
			fil0fil.c routines */

			if (zip_size) {
				error = fil_io(OS_FILE_READ, TRUE,
					       recv_addr->space, zip_size,
					       recv_addr->page_no, 0, zip_size,
					       block->page.zip.data, NULL);
				if (error == DB_SUCCESS
				    && !buf_zip_decompress(block, TRUE)) {
					exit(1);
				}
			} else {
				error = fil_io(OS_FILE_READ, TRUE,
					       recv_addr->space, 0,
					       recv_addr->page_no, 0,
					       UNIV_PAGE_SIZE,
					       block->frame, NULL);
			}

			if (error != DB_SUCCESS) {
				ib_logger(ib_stream,
					  "InnoDB: Fatal error: cannot read "
					  "from tablespace %lu page "
					  "number %lu\n",
					  (ulong) recv_addr->space,
					  (ulong) recv_addr->page_no);

				exit(1);
			}

			/* Apply the log records to this page */
			recv_recover_page(FALSE, block);

			/* Write the page back to the tablespace file using the
			fil0fil.c routines */

			buf_flush_init_for_writing(
				block->frame, buf_block_get_page_zip(block),
				mach_read_ull(block->frame + FIL_PAGE_LSN));

			if (zip_size) {
				error = fil_io(OS_FILE_WRITE, TRUE,
					       recv_addr->space, zip_size,
					       recv_addr->page_no, 0,
					       zip_size,
					       block->page.zip.data, NULL);
			} else {
				error = fil_io(OS_FILE_WRITE, TRUE,
					       recv_addr->space, 0,
					       recv_addr->page_no, 0,
					       UNIV_PAGE_SIZE,
					       block->frame, NULL);
			}
skip_this_recv_addr:
			recv_addr = HASH_GET_NEXT(addr_hash, recv_addr);
		}

		if ((100 * i) / n_hash_cells
		    != (100 * (i + 1)) / n_hash_cells) {
			ib_logger(ib_stream, "%lu ",
				  (ulong) ((100 * i) / n_hash_cells));
		}
	}

	recv_sys_empty_hash();
}
#endif /* !UNIV_HOTBACKUP */

/*******************************************************************//**
Tries to parse a single log record and returns its length.
@return	length of the record, or 0 if the record was not complete */
UNIV_STATIC
ulint
recv_parse_log_rec(
/*===============*/
	byte*	ptr,	/*!< in: pointer to a buffer */
	byte*	end_ptr,/*!< in: pointer to the buffer end */
	byte*	type,	/*!< out: type */
	ulint*	space,	/*!< out: space id */
	ulint*	page_no,/*!< out: page number */
	byte**	body)	/*!< out: log record body start */
{
	byte*	new_ptr;

	*body = NULL;

	if (ptr == end_ptr) {

		return(0);
	}

	if (*ptr == MLOG_MULTI_REC_END) {

		*type = *ptr;

		return(1);
	}

	if (*ptr == MLOG_DUMMY_RECORD) {
		*type = *ptr;

		*space = ULINT_UNDEFINED - 1; /* For debugging */

		return(1);
	}

	new_ptr = mlog_parse_initial_log_record(ptr, end_ptr, type, space,
						page_no);
	*body = new_ptr;

	if (UNIV_UNLIKELY(!new_ptr)) {

		return(0);
	}

#ifdef UNIV_LOG_LSN_DEBUG
	if (*type == MLOG_LSN) {
		ib_uint64_t	lsn = (ib_uint64_t) *space << 32 | *page_no;
# ifdef UNIV_LOG_DEBUG
		ut_a(lsn == log_sys->old_lsn);
# else /* UNIV_LOG_DEBUG */
		ut_a(lsn == recv_sys->recovered_lsn);
# endif /* UNIV_LOG_DEBUG */
	}
#endif /* UNIV_LOG_LSN_DEBUG */

	/* Check that page_no is sensible */

	if (UNIV_UNLIKELY(*page_no > 0x8FFFFFFFUL)) {

		recv_sys->found_corrupt_log = TRUE;

		return(0);
	}

	new_ptr = recv_parse_or_apply_log_rec_body(*type, new_ptr, end_ptr,
						   NULL, NULL);
	if (UNIV_UNLIKELY(new_ptr == NULL)) {

		return(0);
	}

	if (*page_no > recv_max_parsed_page_no) {
		recv_max_parsed_page_no = *page_no;
	}

	return(new_ptr - ptr);
}

/*******************************************************//**
Calculates the new value for lsn when more data is added to the log. */
UNIV_STATIC
ib_uint64_t
recv_calc_lsn_on_data_add(
/*======================*/
	ib_uint64_t	lsn,	/*!< in: old lsn */
	ib_uint64_t	len)	/*!< in: this many bytes of data is
				added, log block headers not included */
{
	ulint	frag_len;
	ulint	lsn_len;

	frag_len = (((ulint) lsn) % OS_FILE_LOG_BLOCK_SIZE)
		- LOG_BLOCK_HDR_SIZE;
	ut_ad(frag_len < OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_HDR_SIZE
	      - LOG_BLOCK_TRL_SIZE);
	lsn_len = (ulint) len;
	lsn_len += (lsn_len + frag_len)
		/ (OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_HDR_SIZE
		   - LOG_BLOCK_TRL_SIZE)
		* (LOG_BLOCK_HDR_SIZE + LOG_BLOCK_TRL_SIZE);

	return(lsn + lsn_len);
}

#ifdef UNIV_LOG_DEBUG
/*******************************************************//**
Checks that the parser recognizes incomplete initial segments of a log
record as incomplete. */
UNIV_STATIC
void
recv_check_incomplete_log_recs(
/*===========================*/
	byte*	ptr,	/*!< in: pointer to a complete log record */
	ulint	len)	/*!< in: length of the log record */
{
	ulint	i;
	byte	type;
	ulint	space;
	ulint	page_no;
	byte*	body;

	for (i = 0; i < len; i++) {
		ut_a(0 == recv_parse_log_rec(ptr, ptr + i, &type, &space,
					     &page_no, &body));
	}
}
#endif /* UNIV_LOG_DEBUG */

/*******************************************************//**
Prints diagnostic info of corrupt log. */
UNIV_STATIC
void
recv_report_corrupt_log(
/*====================*/
	byte*	ptr,	/*!< in: pointer to corrupt log record */
	byte	type,	/*!< in: type of the record */
	ulint	space,	/*!< in: space id, this may also be garbage */
	ulint	page_no)/*!< in: page number, this may also be garbage */
{
	ib_logger(ib_stream,
		  "InnoDB: ############### CORRUPT LOG RECORD FOUND\n"
		  "InnoDB: Log record type %lu, space id %lu, page number %lu\n"
		  "InnoDB: Log parsing proceeded successfully up to %llu\n"
		  "InnoDB: Previous log record type %lu, is multi %lu\n"
		  "InnoDB: Recv offset %lu, prev %lu\n",
		  (ulong) type, (ulong) space, (ulong) page_no,
		  recv_sys->recovered_lsn,
		  (ulong) recv_previous_parsed_rec_type,
		  (ulong) recv_previous_parsed_rec_is_multi,
		  (ulong) (ptr - recv_sys->buf),
		  (ulong) recv_previous_parsed_rec_offset);

	if ((ulint)(ptr - recv_sys->buf + 100)
	    > recv_previous_parsed_rec_offset
	    && (ulint)(ptr - recv_sys->buf + 100
		       - recv_previous_parsed_rec_offset)
	    < 200000) {
		ib_logger(ib_stream,
			  "InnoDB: Hex dump of corrupt log starting"
			  " 100 bytes before the start\n"
			  "InnoDB: of the previous log rec,\n"
			  "InnoDB: and ending 100 bytes after the start"
			  " of the corrupt rec:\n");

		ut_print_buf(ib_stream,
			     recv_sys->buf
			     + recv_previous_parsed_rec_offset - 100,
			     ptr - recv_sys->buf + 200
			     - recv_previous_parsed_rec_offset);
		ib_logger(ib_stream, "\n");
	}

	ib_logger(ib_stream,
		  "InnoDB: WARNING: the log file may have been corrupt and it\n"
		  "InnoDB: is possible that the log scan did not proceed\n"
		  "InnoDB: far enough in recovery! Please run CHECK TABLE\n"
		  "InnoDB: on your InnoDB tables to check that they are ok!\n"
		  "InnoDB: If the engine crashes after this recovery, check\n"
		  "InnoDB: the InnoDB website for details\n"
		  "InnoDB: about forcing recovery.\n");
}

/*******************************************************//**
Parses log records from a buffer and stores them to a hash table to wait
merging to file pages.
@return	currently always returns FALSE */
UNIV_STATIC
ibool
recv_parse_log_recs(
/*================*/
	ibool	store_to_hash)	/*!< in: TRUE if the records should be stored
				to the hash table; this is set to FALSE if just
				debug checking is needed */
{
	byte*		ptr;
	byte*		end_ptr;
	ulint		single_rec;
	ulint		len;
	ulint		total_len;
	ib_uint64_t	new_recovered_lsn;
	ib_uint64_t	old_lsn;
	byte		type;
	ulint		space;
	ulint		page_no;
	byte*		body;
	ulint		n_recs;

	ut_ad(mutex_own(&(log_sys->mutex)));
	ut_ad(recv_sys->parse_start_lsn != 0);
loop:
	ptr = recv_sys->buf + recv_sys->recovered_offset;

	end_ptr = recv_sys->buf + recv_sys->len;

	if (ptr == end_ptr) {

		return(FALSE);
	}

	single_rec = (ulint)*ptr & MLOG_SINGLE_REC_FLAG;

	if (single_rec || *ptr == MLOG_DUMMY_RECORD) {
		/* The mtr only modified a single page, or this is a file op */

		old_lsn = recv_sys->recovered_lsn;

		/* Try to parse a log record, fetching its type, space id,
		page no, and a pointer to the body of the log record */

		len = recv_parse_log_rec(ptr, end_ptr, &type, &space,
					 &page_no, &body);

		if (len == 0 || recv_sys->found_corrupt_log) {
			if (recv_sys->found_corrupt_log) {

				recv_report_corrupt_log(ptr,
							type, space, page_no);
			}

			return(FALSE);
		}

		new_recovered_lsn = recv_calc_lsn_on_data_add(old_lsn, len);

		if (new_recovered_lsn > recv_sys->scanned_lsn) {
			/* The log record filled a log block, and we require
			that also the next log block should have been scanned
			in */

			return(FALSE);
		}

		recv_previous_parsed_rec_type = (ulint)type;
		recv_previous_parsed_rec_offset = recv_sys->recovered_offset;
		recv_previous_parsed_rec_is_multi = 0;

		recv_sys->recovered_offset += len;
		recv_sys->recovered_lsn = new_recovered_lsn;

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream,
				  "InnoDB: Parsed a single log rec "
				  "type %lu len %lu space %lu page no %lu\n",
				  (ulong) type, (ulong) len, (ulong) space,
				  (ulong) page_no);
		}
#endif /* UNIV_DEBUG */

		if (type == MLOG_DUMMY_RECORD) {
			/* Do nothing */

		} else if (!store_to_hash) {
			/* In debug checking, update a replicate page
			according to the log record, and check that it
			becomes identical with the original page */
#ifdef UNIV_LOG_DEBUG
			recv_check_incomplete_log_recs(ptr, len);
#endif/* UNIV_LOG_DEBUG */

		} else if (type == MLOG_FILE_CREATE
			   || type == MLOG_FILE_CREATE2
			   || type == MLOG_FILE_RENAME
			   || type == MLOG_FILE_DELETE) {
			ut_a(space);

			/* In normal crash recovery we do not try to
			replay file operations */
#ifdef UNIV_LOG_LSN_DEBUG
		} else if (type == MLOG_LSN) {
			/* Do not add these records to the hash table.
			The page number and space id fields are misused
			for something else. */
#endif /* UNIV_LOG_LSN_DEBUG */
		} else {
			recv_add_to_hash_table(type, space, page_no, body,
					       ptr + len, old_lsn,
					       recv_sys->recovered_lsn);
		}
	} else {
		/* Check that all the records associated with the single mtr
		are included within the buffer */

		total_len = 0;
		n_recs = 0;

		for (;;) {
			len = recv_parse_log_rec(ptr, end_ptr, &type, &space,
						 &page_no, &body);
			if (len == 0 || recv_sys->found_corrupt_log) {

				if (recv_sys->found_corrupt_log) {

					recv_report_corrupt_log(
						ptr, type, space, page_no);
				}

				return(FALSE);
			}

			recv_previous_parsed_rec_type = (ulint)type;
			recv_previous_parsed_rec_offset
				= recv_sys->recovered_offset + total_len;
			recv_previous_parsed_rec_is_multi = 1;

#ifdef UNIV_LOG_DEBUG
			if ((!store_to_hash) && (type != MLOG_MULTI_REC_END)) {
				recv_check_incomplete_log_recs(ptr, len);
			}
#endif /* UNIV_LOG_DEBUG */

#ifdef UNIV_DEBUG
			if (log_debug_writes) {
				ib_logger(ib_stream,
					  "InnoDB: Parsed a multi log rec "
					  "type %lu len %lu "
					  "space %lu page no %lu\n",
					  (ulong) type, (ulong) len,
					  (ulong) space, (ulong) page_no);
			}
#endif /* UNIV_DEBUG */

			total_len += len;
			n_recs++;

			ptr += len;

			if (type == MLOG_MULTI_REC_END) {

				/* Found the end mark for the records */

				break;
			}
		}

		new_recovered_lsn = recv_calc_lsn_on_data_add(
			recv_sys->recovered_lsn, total_len);

		if (new_recovered_lsn > recv_sys->scanned_lsn) {
			/* The log record filled a log block, and we require
			that also the next log block should have been scanned
			in */

			return(FALSE);
		}

		/* Add all the records to the hash table */

		ptr = recv_sys->buf + recv_sys->recovered_offset;

		for (;;) {
			old_lsn = recv_sys->recovered_lsn;
			len = recv_parse_log_rec(ptr, end_ptr, &type, &space,
						 &page_no, &body);
			if (recv_sys->found_corrupt_log) {

				recv_report_corrupt_log(ptr,
							type, space, page_no);
			}

			ut_a(len != 0);
			ut_a(0 == ((ulint)*ptr & MLOG_SINGLE_REC_FLAG));

			recv_sys->recovered_offset += len;
			recv_sys->recovered_lsn
				= recv_calc_lsn_on_data_add(old_lsn, len);
			if (type == MLOG_MULTI_REC_END) {

				/* Found the end mark for the records */

				break;
			}

			if (store_to_hash
#ifdef UNIV_LOG_LSN_DEBUG
			    && type != MLOG_LSN
#endif /* UNIV_LOG_LSN_DEBUG */
			    ) {
				recv_add_to_hash_table(type, space, page_no,
						       body, ptr + len,
						       old_lsn,
						       new_recovered_lsn);
			}

			ptr += len;
		}
	}

	goto loop;
}

/*******************************************************//**
Adds data from a new log block to the parsing buffer of recv_sys if
recv_sys->parse_start_lsn is non-zero.
@return	TRUE if more data added */
UNIV_STATIC
ibool
recv_sys_add_to_parsing_buf(
/*========================*/
	const byte*	log_block,	/*!< in: log block */
	ib_uint64_t	scanned_lsn)	/*!< in: lsn of how far we were able
					to find data in this log block */
{
	ulint	more_len;
	ulint	data_len;
	ulint	start_offset;
	ulint	end_offset;

	ut_ad(scanned_lsn >= recv_sys->scanned_lsn);

	if (!recv_sys->parse_start_lsn) {
		/* Cannot start parsing yet because no start point for
		it found */

		return(FALSE);
	}

	data_len = log_block_get_data_len(log_block);

	if (recv_sys->parse_start_lsn >= scanned_lsn) {

		return(FALSE);

	} else if (recv_sys->scanned_lsn >= scanned_lsn) {

		return(FALSE);

	} else if (recv_sys->parse_start_lsn > recv_sys->scanned_lsn) {
		more_len = (ulint) (scanned_lsn - recv_sys->parse_start_lsn);
	} else {
		more_len = (ulint) (scanned_lsn - recv_sys->scanned_lsn);
	}

	if (more_len == 0) {

		return(FALSE);
	}

	ut_ad(data_len >= more_len);

	start_offset = data_len - more_len;

	if (start_offset < LOG_BLOCK_HDR_SIZE) {
		start_offset = LOG_BLOCK_HDR_SIZE;
	}

	end_offset = data_len;

	if (end_offset > OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE) {
		end_offset = OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE;
	}

	ut_ad(start_offset <= end_offset);

	if (start_offset < end_offset) {
		ut_memcpy(recv_sys->buf + recv_sys->len,
			  log_block + start_offset, end_offset - start_offset);

		recv_sys->len += end_offset - start_offset;

		ut_a(recv_sys->len <= RECV_PARSING_BUF_SIZE);
	}

	return(TRUE);
}

/*******************************************************//**
Moves the parsing buffer data left to the buffer start. */
UNIV_STATIC
void
recv_sys_justify_left_parsing_buf(void)
/*===================================*/
{
	ut_memmove(recv_sys->buf, recv_sys->buf + recv_sys->recovered_offset,
		   recv_sys->len - recv_sys->recovered_offset);

	recv_sys->len -= recv_sys->recovered_offset;

	recv_sys->recovered_offset = 0;
}

/*******************************************************//**
Scans log from a buffer and stores new log data to the parsing buffer.
Parses and hashes the log records if new data found.  Unless
UNIV_HOTBACKUP is defined, this function will apply log records
automatically when the hash table becomes full.
@return TRUE if limit_lsn has been reached, or not able to scan any
more in this log group */
UNIV_INTERN
ibool
recv_scan_log_recs(
/*===============*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	ulint		available_memory,/*!< in: we let the hash table of recs
					to grow to this size, at the maximum */
	ibool		store_to_hash,	/*!< in: TRUE if the records should be
					stored to the hash table; this is set
					to FALSE if just debug checking is
					needed */
	const byte*	buf,		/*!< in: buffer containing a log
					segment or garbage */
	ulint		len,		/*!< in: buffer length */
	ib_uint64_t	start_lsn,	/*!< in: buffer start lsn */
	ib_uint64_t*	contiguous_lsn,	/*!< in/out: it is known that all log
					groups contain contiguous log data up
					to this lsn */
	ib_uint64_t*	group_scanned_lsn)/*!< out: scanning succeeded up to
					this lsn */
{
	const byte*	log_block;
	ulint		no;
	ib_uint64_t	scanned_lsn;
	ibool		finished;
	ulint		data_len;
	ibool		more_data;

	ut_ad(start_lsn % OS_FILE_LOG_BLOCK_SIZE == 0);
	ut_ad(len % OS_FILE_LOG_BLOCK_SIZE == 0);
	ut_ad(len >= OS_FILE_LOG_BLOCK_SIZE);
	ut_a(store_to_hash <= TRUE);

	finished = FALSE;

	log_block = buf;
	scanned_lsn = start_lsn;
	more_data = FALSE;

	do {
		no = log_block_get_hdr_no(log_block);
		/*
		ib_logger(ib_stream, "Log block header no %lu\n", no);

		ib_logger(ib_stream, "Scanned lsn no %lu\n",
		log_block_convert_lsn_to_no(scanned_lsn));
		*/
		if (no != log_block_convert_lsn_to_no(scanned_lsn)
		    || !log_block_checksum_is_ok_or_old_format(log_block)) {

			if (no == log_block_convert_lsn_to_no(scanned_lsn)
			    && !log_block_checksum_is_ok_or_old_format(
				    log_block)) {
				ib_logger(ib_stream,
					  "InnoDB: Log block no %lu at "
					  "lsn %llu has\n"
					  "InnoDB: ok header, but checksum "
					  "field contains %lu, "
					  "should be %lu\n",
					  (ulong) no,
					  scanned_lsn,
					  (ulong) log_block_get_checksum(
						  log_block),
					  (ulong) log_block_calc_checksum(
						  log_block));
			}

			/* Garbage or an incompletely written log block */

			finished = TRUE;

			break;
		}

		if (log_block_get_flush_bit(log_block)) {
			/* This block was a start of a log flush operation:
			we know that the previous flush operation must have
			been completed for all log groups before this block
			can have been flushed to any of the groups. Therefore,
			we know that log data is contiguous up to scanned_lsn
			in all non-corrupt log groups. */

			if (scanned_lsn > *contiguous_lsn) {
				*contiguous_lsn = scanned_lsn;
			}
		}

		data_len = log_block_get_data_len(log_block);

		if ((store_to_hash || (data_len == OS_FILE_LOG_BLOCK_SIZE))
		    && scanned_lsn + data_len > recv_sys->scanned_lsn
		    && (recv_sys->scanned_checkpoint_no > 0)
		    && (log_block_get_checkpoint_no(log_block)
			< recv_sys->scanned_checkpoint_no)
		    && (recv_sys->scanned_checkpoint_no
			- log_block_get_checkpoint_no(log_block)
			> 0x80000000UL)) {

			/* Garbage from a log buffer flush which was made
			before the most recent database recovery */

			finished = TRUE;
#ifdef UNIV_LOG_DEBUG
			/* This is not really an error, but currently
			we stop here in the debug version: */

			ut_error;
#endif
			break;
		}

		if (!recv_sys->parse_start_lsn
		    && (log_block_get_first_rec_group(log_block) > 0)) {

			/* We found a point from which to start the parsing
			of log records */

			recv_sys->parse_start_lsn = scanned_lsn
				+ log_block_get_first_rec_group(log_block);
			recv_sys->scanned_lsn = recv_sys->parse_start_lsn;
			recv_sys->recovered_lsn = recv_sys->parse_start_lsn;
		}

		scanned_lsn += data_len;

		if (scanned_lsn > recv_sys->scanned_lsn) {

			/* We have found more entries. If this scan is
 			of startup type, we must initiate crash recovery
			environment before parsing these log records. */

#ifndef UNIV_HOTBACKUP
			if (recv_log_scan_is_startup_type
			    && !recv_needed_recovery) {

				ib_logger(ib_stream,
					  "InnoDB: Log scan progressed"
					  " past the checkpoint lsn %llu\n",
					  recv_sys->scanned_lsn);
				recv_start_crash_recovery(recovery);
			}
#endif /* !UNIV_HOTBACKUP */

			/* We were able to find more log data: add it to the
			parsing buffer if parse_start_lsn is already
			non-zero */

			if (recv_sys->len + 4 * OS_FILE_LOG_BLOCK_SIZE
			    >= RECV_PARSING_BUF_SIZE) {
				ib_logger(ib_stream,
					  "InnoDB: Error: log parsing"
					  " buffer overflow."
					  " Recovery may have failed!\n");

				recv_sys->found_corrupt_log = TRUE;

			} else if (!recv_sys->found_corrupt_log) {
				more_data = recv_sys_add_to_parsing_buf(
					log_block, scanned_lsn);
			}

			recv_sys->scanned_lsn = scanned_lsn;
			recv_sys->scanned_checkpoint_no
				= log_block_get_checkpoint_no(log_block);
		}

		if (data_len < OS_FILE_LOG_BLOCK_SIZE) {
			/* Log data for this group ends here */

			finished = TRUE;
			break;
		} else {
			log_block += OS_FILE_LOG_BLOCK_SIZE;
		}
	} while (log_block < buf + len && !finished);

	*group_scanned_lsn = scanned_lsn;

	if (recv_needed_recovery
	    || (recv_is_from_backup && !recv_is_making_a_backup)) {
		recv_scan_print_counter++;

		if (finished || (recv_scan_print_counter % 80 == 0)) {

			ib_logger(ib_stream,
				  "InnoDB: Doing recovery: scanned up to"
				  " log sequence number %llu\n",
				  *group_scanned_lsn);
		}
	}

	if (more_data && !recv_sys->found_corrupt_log) {
		/* Try to parse more log records */

		recv_parse_log_recs(store_to_hash);

#ifndef UNIV_HOTBACKUP
		if (store_to_hash && mem_heap_get_size(recv_sys->heap)
		    > available_memory) {

			/* Hash table of log records has grown too big:
			empty it; FALSE means no ibuf operations
			allowed, as we cannot add new records to the
			log yet: they would be produced by ibuf
			operations */

			recv_apply_hashed_log_recs(FALSE);
		}
#endif /* !UNIV_HOTBACKUP */

		if (recv_sys->recovered_offset > RECV_PARSING_BUF_SIZE / 4) {
			/* Move parsing buffer data to the buffer start */

			recv_sys_justify_left_parsing_buf();
		}
	}

	return(finished);
}

#ifndef UNIV_HOTBACKUP
/*******************************************************//**
Scans log from a buffer and stores new log data to the parsing buffer. Parses
and hashes the log records if new data found. */
UNIV_STATIC
void
recv_group_scan_log_recs(
/*=====================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	log_group_t*	group,		/*!< in: log group */
	ib_uint64_t*	contiguous_lsn,	/*!< in/out: it is known that all log
					groups contain contiguous log data up
					to this lsn */
	ib_uint64_t*	group_scanned_lsn)/*!< out: scanning succeeded up to
					this lsn */
{
	ibool		finished;
	ib_uint64_t	start_lsn;
	ib_uint64_t	end_lsn;

	finished = FALSE;

	start_lsn = *contiguous_lsn;

	while (!finished) {
		end_lsn = start_lsn + RECV_SCAN_SIZE;

		log_group_read_log_seg(LOG_RECOVER, log_sys->buf,
				       group, start_lsn, end_lsn);

		finished = recv_scan_log_recs(
			recovery,
			(buf_pool->curr_size - recv_n_pool_free_frames)
			* UNIV_PAGE_SIZE, TRUE, log_sys->buf, RECV_SCAN_SIZE,
			start_lsn, contiguous_lsn, group_scanned_lsn);
		start_lsn = end_lsn;
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			  "InnoDB: Scanned group %lu up to"
			  " log sequence number %llu\n",
			  (ulong) group->id,
			  *group_scanned_lsn);
	}
#endif /* UNIV_DEBUG */
}

/*******************************************************//**
Initialize crash recovery environment. Can be called iff
recv_needed_recovery == FALSE. */
UNIV_STATIC
void
recv_start_crash_recovery(
/*======================*/
	ib_recovery_t	recovery)	/*!< in: recovery flag */
{
	ut_a(!recv_needed_recovery);

	recv_needed_recovery = TRUE;

	ut_print_timestamp(ib_stream);

	ib_logger(ib_stream,
		  " InnoDB: Database was not shut down normally!\n"
		  "InnoDB: Starting crash recovery.\n");

	ib_logger(ib_stream,
		  "InnoDB: Reading tablespace information"
		  " from the .ibd files...\n");

	fil_load_single_table_tablespaces(recovery);

	/* If we are using the doublewrite method, we will
	check if there are half-written pages in data files,
	and restore them from the doublewrite buffer if
	possible */

	if (recovery < IB_RECOVERY_NO_LOG_REDO) {

		ib_logger(ib_stream,
			  "InnoDB: Restoring possible half-written data "
			  "pages from the doublewrite\n"
			  "InnoDB: buffer...\n");
		trx_sys_doublewrite_init_or_restore_pages(TRUE);
	}
}

/********************************************************//**
Recover form ibbackup log file. */
UNIV_STATIC
void
recv_recover_from_ibbackup(
/*=======================*/
	log_group_t*	max_cp_group)	/*!< in/out: log group that contains the
					maximum consistent checkpoint */
{
	byte		log_hdr_buf[LOG_FILE_HDR_SIZE];

	/* Read the first log file header to print a note if this is
	a recovery from a restored InnoDB Hot Backup */

	fil_io(OS_FILE_READ | OS_FILE_LOG, TRUE, max_cp_group->space_id, 0,
	       0, 0, LOG_FILE_HDR_SIZE,
	       log_hdr_buf, max_cp_group);

	if (0 == ut_memcmp(log_hdr_buf + LOG_FILE_WAS_CREATED_BY_HOT_BACKUP,
			   (byte*)"ibbackup", (sizeof "ibbackup") - 1)) {
		/* This log file was created by ibbackup --restore: print
		a note to the user about it */

		ib_logger(ib_stream,
			  "InnoDB: The log file was created by"
			  " ibbackup --apply-log at\n"
			  "InnoDB: %s\n",
			  log_hdr_buf + LOG_FILE_WAS_CREATED_BY_HOT_BACKUP);
		ib_logger(ib_stream,
			  "InnoDB: NOTE: the following crash recovery"
			  " is part of a normal restore.\n");

		/* Wipe over the label now */

		memset(log_hdr_buf + LOG_FILE_WAS_CREATED_BY_HOT_BACKUP,
		       ' ', 4);
		/* Write to the log file to wipe over the label */
		fil_io(OS_FILE_WRITE | OS_FILE_LOG, TRUE,
		       max_cp_group->space_id, 0,
		       0, 0, OS_FILE_LOG_BLOCK_SIZE,
		       log_hdr_buf, max_cp_group);
	}
}

/************************************************************
Compare the checkpoint lsn with the lsn recorded in the data files
and start crash recovery if required. */
UNIV_STATIC
void
recv_init_crash_recovery(
/*=====================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	ib_uint64_t	checkpoint_lsn,	/*!< in: checkpoint lsn */
	ib_uint64_t	min_flushed_lsn,/*!< in: min flushed lsn from
					data files */
	ib_uint64_t	max_flushed_lsn)/*!< in: max flushed lsn from
					data files */
{
	/* NOTE: we always do a 'recovery' at startup, but only if
	there is something wrong we will print a message to the
	user about recovery: */

	if (checkpoint_lsn != max_flushed_lsn
	    || checkpoint_lsn != min_flushed_lsn) {

		if (checkpoint_lsn < max_flushed_lsn) {
			ib_logger(ib_stream,
				"InnoDB: #########################"
				"#################################\n"
				"InnoDB:                          "
				"WARNING!\n"
				"InnoDB: The log sequence number"
				" in ibdata files is higher\n"
				"InnoDB: than the log sequence number"
				" in the ib_logfiles! Are you sure\n"
				"InnoDB: you are using the right"
				" ib_logfiles to start up"
				" the database?\n"
				"InnoDB: Log sequence number in"
				" ib_logfiles is %llu, log\n"
				"InnoDB: sequence numbers stamped"
				" to ibdata file headers are between\n"
				"InnoDB: %llu and %llu.\n"
				"InnoDB: #########################"
				"#################################\n",
				checkpoint_lsn,
				min_flushed_lsn,
				max_flushed_lsn);
		}

		if (!recv_needed_recovery) {
			ib_logger(ib_stream,
				"InnoDB: The log sequence number"
				" in ibdata files does not match\n"
				"InnoDB: the log sequence number"
				" in the ib_logfiles!\n");

			recv_start_crash_recovery(recovery);
		}
	}

	if (!recv_needed_recovery) {
		/* Init the doublewrite buffer memory structure */
		trx_sys_doublewrite_init_or_restore_pages(FALSE);
	}
}

/************************************************************
Recovers from a checkpoint. When this function returns, the database is able
to start processing of new user transactions, but the function
recv_recovery_from_checkpoint_finish should be called later to complete
the recovery and free the resources used in it.
@return	error code or DB_SUCCESS */
UNIV_INTERN
ulint
recv_recovery_from_checkpoint_start_func(
/*=====================================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
#ifdef UNIV_LOG_ARCHIVE
	ulint		type,		/*!< in: LOG_CHECKPOINT or
					LOG_ARCHIVE */
	ib_uint64_t	limit_lsn,	/*!< in: recover up to this lsn
					if possible */
#endif /* UNIV_LOG_ARCHIVE */
	ib_uint64_t	min_flushed_lsn,/*!< in: min flushed lsn from
					data files */
	ib_uint64_t	max_flushed_lsn)/*!< in: max flushed lsn from
					data files */
{
	log_group_t*	group;
	log_group_t*	max_cp_group;
	log_group_t*	up_to_date_group;
	ulint		max_cp_field;
	ib_uint64_t	checkpoint_lsn;
	ib_uint64_t	checkpoint_no;
	ib_uint64_t	old_scanned_lsn;
	ib_uint64_t	group_scanned_lsn;
	ib_uint64_t	contiguous_lsn;
	ib_uint64_t	archived_lsn;
	byte*		buf;
	ulint		err;

#ifdef UNIV_LOG_ARCHIVE
	ut_ad(type != LOG_CHECKPOINT || limit_lsn == IB_UINT64_T_MAX);
/** TRUE when recovering from a checkpoint */
# define TYPE_CHECKPOINT	(type == LOG_CHECKPOINT)
/** Recover up to this log sequence number */
# define LIMIT_LSN		limit_lsn
#else /* UNIV_LOG_ARCHIVE */
/** TRUE when recovering from a checkpoint */
# define TYPE_CHECKPOINT	1
/** Recover up to this log sequence number */
# define LIMIT_LSN		IB_UINT64_T_MAX
#endif /* UNIV_LOG_ARCHIVE */

	if (TYPE_CHECKPOINT) {
		recv_sys_create();
		recv_sys_init(buf_pool_get_curr_size());
	}

	if (recovery >= IB_RECOVERY_NO_LOG_REDO) {
		ib_logger(ib_stream,
			  "InnoDB: The user has set "
			  "IB_RECOVERY_NO_LOG_REDO on\n");
		ib_logger(ib_stream,
			  "InnoDB: Skipping log redo\n");

		return(DB_SUCCESS);
	}

	recv_recovery_on = TRUE;

	recv_sys->limit_lsn = LIMIT_LSN;

	mutex_enter(&(log_sys->mutex));

	/* Look for the latest checkpoint from any of the log groups */

	err = recv_find_max_checkpoint(&max_cp_group, &max_cp_field);

	if (err != DB_SUCCESS) {

		mutex_exit(&(log_sys->mutex));

		return(err);
	}

	log_group_read_checkpoint_info(max_cp_group, max_cp_field);

	buf = log_sys->checkpoint_buf;

	checkpoint_lsn = mach_read_ull(buf + LOG_CHECKPOINT_LSN);
	checkpoint_no = mach_read_ull(buf + LOG_CHECKPOINT_NO);
	archived_lsn = mach_read_ull(buf + LOG_CHECKPOINT_ARCHIVED_LSN);

	recv_recover_from_ibbackup(max_cp_group);

#ifdef UNIV_LOG_ARCHIVE
	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group) {
		log_checkpoint_get_nth_group_info(buf, group->id,
						  &(group->archived_file_no),
						  &(group->archived_offset));

		group = UT_LIST_GET_NEXT(log_groups, group);
	}
#endif /* UNIV_LOG_ARCHIVE */

	if (TYPE_CHECKPOINT) {
		/* Start reading the log groups from the checkpoint lsn up. The
		variable contiguous_lsn contains an lsn up to which the log is
		known to be contiguously written to all log groups. */

		recv_sys->parse_start_lsn = checkpoint_lsn;
		recv_sys->scanned_lsn = checkpoint_lsn;
		recv_sys->scanned_checkpoint_no = 0;
		recv_sys->recovered_lsn = checkpoint_lsn;

		srv_start_lsn = checkpoint_lsn;
	}

	contiguous_lsn = ut_uint64_align_down(recv_sys->scanned_lsn,
					      OS_FILE_LOG_BLOCK_SIZE);
	if (TYPE_CHECKPOINT) {
		up_to_date_group = max_cp_group;
#ifdef UNIV_LOG_ARCHIVE
	} else {
		ulint	capacity;

		/* Try to recover the remaining part from logs: first from
		the logs of the archived group */

		group = recv_sys->archive_group;
		capacity = log_group_get_capacity(group);

		if (recv_sys->scanned_lsn > checkpoint_lsn + capacity
		    || checkpoint_lsn > recv_sys->scanned_lsn + capacity) {

			mutex_exit(&(log_sys->mutex));

			/* The group does not contain enough log: probably
			an archived log file was missing or corrupt */

			return(DB_ERROR);
		}

		recv_group_scan_log_recs(recovery, group, &contiguous_lsn,
					 &group_scanned_lsn);
		if (recv_sys->scanned_lsn < checkpoint_lsn) {

			mutex_exit(&(log_sys->mutex));

			/* The group did not contain enough log: an archived
			log file was missing or invalid, or the log group
			was corrupt */

			return(DB_ERROR);
		}

		group->scanned_lsn = group_scanned_lsn;
		up_to_date_group = group;
#endif /* UNIV_LOG_ARCHIVE */
	}

	ut_ad(RECV_SCAN_SIZE <= log_sys->buf_size);

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

#ifdef UNIV_LOG_ARCHIVE
	if ((type == LOG_ARCHIVE) && (group == recv_sys->archive_group)) {
		group = UT_LIST_GET_NEXT(log_groups, group);
	}
#endif /* UNIV_LOG_ARCHIVE */

	/* Set the flag to publish that we are doing startup scan. */
	recv_log_scan_is_startup_type = TYPE_CHECKPOINT;
	while (group) {
		old_scanned_lsn = recv_sys->scanned_lsn;

		recv_group_scan_log_recs(recovery, group, &contiguous_lsn,
					 &group_scanned_lsn);
		group->scanned_lsn = group_scanned_lsn;

		if (old_scanned_lsn < group_scanned_lsn) {
			/* We found a more up-to-date group */

			up_to_date_group = group;
		}

#ifdef UNIV_LOG_ARCHIVE
		if ((type == LOG_ARCHIVE)
		    && (group == recv_sys->archive_group)) {
			group = UT_LIST_GET_NEXT(log_groups, group);
		}
#endif /* UNIV_LOG_ARCHIVE */

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	/* Done with startup scan. Clear the flag. */
	recv_log_scan_is_startup_type = FALSE;

	if (TYPE_CHECKPOINT) {
		recv_init_crash_recovery(
			recovery, checkpoint_lsn,
		       	min_flushed_lsn, max_flushed_lsn);
	}

	/* We currently have only one log group */
	if (group_scanned_lsn < checkpoint_lsn) {
		ut_print_timestamp(ib_stream);
		ib_logger(ib_stream,
			  " InnoDB: ERROR: We were only able to scan the log"
			  " up to\n"
			  "InnoDB: %llu, but a checkpoint was at %llu.\n"
			  "InnoDB: It is possible that"
			  " the database is now corrupt!\n",
			  group_scanned_lsn,
			  checkpoint_lsn);
	}

	if (group_scanned_lsn < recv_max_page_lsn) {
		ut_print_timestamp(ib_stream);
		ib_logger(ib_stream,
			  " InnoDB: ERROR: We were only able to scan the log"
			  " up to %llu\n"
			  "InnoDB: but a database page a had an lsn %llu."
			  " It is possible that the\n"
			  "InnoDB: database is now corrupt!\n",
			  group_scanned_lsn,
			  recv_max_page_lsn);
	}

	if (recv_sys->recovered_lsn < checkpoint_lsn) {

		mutex_exit(&(log_sys->mutex));

		if (recv_sys->recovered_lsn >= LIMIT_LSN) {

			return(DB_SUCCESS);
		}

		ut_error;

		return(DB_ERROR);
	}

	/* Synchronize the uncorrupted log groups to the most up-to-date log
	group; we also copy checkpoint info to groups */

	log_sys->next_checkpoint_lsn = checkpoint_lsn;
	log_sys->next_checkpoint_no = checkpoint_no + 1;

#ifdef UNIV_LOG_ARCHIVE
	log_sys->archived_lsn = archived_lsn;
#endif /* UNIV_LOG_ARCHIVE */

	recv_synchronize_groups(up_to_date_group);

	if (!recv_needed_recovery) {
		ut_a(checkpoint_lsn == recv_sys->recovered_lsn);
	} else {
		srv_start_lsn = recv_sys->recovered_lsn;
	}

	log_sys->lsn = recv_sys->recovered_lsn;

	ut_memcpy(log_sys->buf, recv_sys->last_block, OS_FILE_LOG_BLOCK_SIZE);

	log_sys->buf_free = (ulint) log_sys->lsn % OS_FILE_LOG_BLOCK_SIZE;
	log_sys->buf_next_to_write = log_sys->buf_free;
	log_sys->written_to_some_lsn = log_sys->lsn;
	log_sys->written_to_all_lsn = log_sys->lsn;

	log_sys->last_checkpoint_lsn = checkpoint_lsn;

	log_sys->next_checkpoint_no = checkpoint_no + 1;

#ifdef UNIV_LOG_ARCHIVE
	if (archived_lsn == IB_UINT64_T_MAX) {

		log_sys->archiving_state = LOG_ARCH_OFF;
	}
#endif /* UNIV_LOG_ARCHIVE */

	mutex_enter(&(recv_sys->mutex));

	recv_sys->apply_log_recs = TRUE;

	mutex_exit(&(recv_sys->mutex));

	mutex_exit(&(log_sys->mutex));

	recv_lsn_checks_on = TRUE;

	/* The database is now ready to start almost normal processing of user
	transactions: transaction rollbacks and the application of the log
	records in the hash table can be run in background. */

	return(DB_SUCCESS);

#undef TYPE_CHECKPOINT
#undef LIMIT_LSN
}

/********************************************************//**
Completes recovery from a checkpoint. */
UNIV_INTERN
void
recv_recovery_from_checkpoint_finish(
/*=================================*/
	ib_recovery_t	recovery)	/*!< in: recovery flag */
{
	/* Apply the hashed log records to the respective file pages */

	if (recovery < IB_RECOVERY_NO_LOG_REDO) {

		recv_apply_hashed_log_recs(TRUE);
	}

#ifdef UNIV_DEBUG
	if (log_debug_writes) {
		ib_logger(ib_stream,
			  "InnoDB: Log records applied to the database\n");
	}
#endif /* UNIV_DEBUG */


	if (recv_sys->found_corrupt_log) {

		ib_logger(ib_stream,
			  "InnoDB: WARNING: the log file may have been"
			  " corrupt and it\n"
			  "InnoDB: is possible that the log scan or parsing"
			  " did not proceed\n"
			  "InnoDB: far enough in recovery. Please run"
			  " CHECK TABLE\n"
			  "InnoDB: on your InnoDB tables to check that"
			  " they are ok!\n"
			  "InnoDB: It may be safest to recover your"
			  " InnoDB database from\n"
			  "InnoDB: a backup!\n");
	}

	/* Free the resources of the recovery system */

	recv_recovery_on = FALSE;

#ifndef UNIV_LOG_DEBUG
	recv_sys_debug_free();
#endif
	/* Roll back any recovered data dictionary transactions, so
	that the data dictionary tables will be free of any locks.
	The data dictionary latch should guarantee that there is at
	most one data dictionary transaction active at a time. */
	trx_rollback_or_clean_recovered(FALSE);
}

/********************************************************//**
Initiates the rollback of active transactions. */
UNIV_INTERN
void
recv_recovery_rollback_active(void)
/*===============================*/
{
	int		i;

	/* This is required to set the compare context before recovery, also
	it's a one-shot. We can safely set it to NULL after calling it. */
	if (recv_pre_rollback_hook != NULL) {
		recv_pre_rollback_hook();
		recv_pre_rollback_hook = NULL;
	}

#ifdef UNIV_SYNC_DEBUG
	/* Wait for a while so that created threads have time to suspend
	themselves before we switch the latching order checks on */
	os_thread_sleep(1000000);

	/* Switch latching order checks on in sync0sync.c */
	sync_order_checks_on = TRUE;
#endif
	ddl_drop_all_temp_indexes(srv_force_recovery);
	ddl_drop_all_temp_tables(srv_force_recovery);

	if (srv_force_recovery < IB_RECOVERY_NO_TRX_UNDO) {
		/* Rollback the uncommitted transactions which have no user
		session */

		os_thread_create(trx_rollback_or_clean_all_recovered,
				 (void *)&i, NULL);
	}
}

/******************************************************//**
Resets the logs. The contents of log files will be lost! */
UNIV_INTERN
void
recv_reset_logs(
/*============*/
	ib_uint64_t	lsn,		/*!< in: reset to this lsn
					rounded up to be divisible by
					OS_FILE_LOG_BLOCK_SIZE, after
					which we add
					LOG_BLOCK_HDR_SIZE */
#ifdef UNIV_LOG_ARCHIVE
	ulint		arch_log_no,	/*!< in: next archived log file number */
#endif /* UNIV_LOG_ARCHIVE */
	ibool		new_logs_created)/*!< in: TRUE if resetting logs
					is done at the log creation;
					FALSE if it is done after
					archive recovery */
{
	log_group_t*	group;

	ut_ad(mutex_own(&(log_sys->mutex)));

	log_sys->lsn = ut_uint64_align_up(lsn, OS_FILE_LOG_BLOCK_SIZE);

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group) {
		group->lsn = log_sys->lsn;
		group->lsn_offset = LOG_FILE_HDR_SIZE;
#ifdef UNIV_LOG_ARCHIVE
		group->archived_file_no = arch_log_no;
		group->archived_offset = 0;
#endif /* UNIV_LOG_ARCHIVE */

		if (!new_logs_created) {
			recv_truncate_group(group, group->lsn, group->lsn,
					    group->lsn, group->lsn);
		}

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	log_sys->buf_next_to_write = 0;
	log_sys->written_to_some_lsn = log_sys->lsn;
	log_sys->written_to_all_lsn = log_sys->lsn;

	log_sys->next_checkpoint_no = 0;
	log_sys->last_checkpoint_lsn = 0;

#ifdef UNIV_LOG_ARCHIVE
	log_sys->archived_lsn = log_sys->lsn;
#endif /* UNIV_LOG_ARCHIVE */

	log_block_init(log_sys->buf, log_sys->lsn);
	log_block_set_first_rec_group(log_sys->buf, LOG_BLOCK_HDR_SIZE);

	log_sys->buf_free = LOG_BLOCK_HDR_SIZE;
	log_sys->lsn += LOG_BLOCK_HDR_SIZE;

	mutex_exit(&(log_sys->mutex));

	/* Reset the checkpoint fields in logs */

	log_make_checkpoint_at(IB_UINT64_T_MAX, TRUE);
	log_make_checkpoint_at(IB_UINT64_T_MAX, TRUE);

	mutex_enter(&(log_sys->mutex));
}
#endif /* !UNIV_HOTBACKUP */

#ifdef UNIV_HOTBACKUP
/******************************************************//**
Creates new log files after a backup has been restored. */
UNIV_INTERN
void
recv_reset_log_files_for_backup(
/*============================*/
	const char*	log_dir,	/*!< in: log file directory path */
	ulint		n_log_files,	/*!< in: number of log files */
	ulint		log_file_size,	/*!< in: log file size */
	ib_uint64_t	lsn)		/*!< in: new start lsn, must be
					divisible by OS_FILE_LOG_BLOCK_SIZE */
{
	os_file_t	log_file;
	ibool		success;
	byte*		buf;
	ulint		i;
	ulint		log_dir_len;
	char		name[5000];
	static const char ib_logfile_basename[] = "ib_logfile";

	log_dir_len = strlen(log_dir);
	/* full path name of ib_logfile consists of log dir path + basename
	+ number. This must fit in the name buffer.
	*/
	ut_a(log_dir_len + strlen(ib_logfile_basename) + 11  < sizeof(name));

	buf = ut_malloc(LOG_FILE_HDR_SIZE + OS_FILE_LOG_BLOCK_SIZE);
	memset(buf, '\0', LOG_FILE_HDR_SIZE + OS_FILE_LOG_BLOCK_SIZE);

	for (i = 0; i < n_log_files; i++) {

		ut_snprintf(name, sizeof(name), "%s%s%lu", log_dir,
			    ib_logfile_basename, (ulong)i);

		log_file = os_file_create_simple(name, OS_FILE_CREATE,
						 OS_FILE_READ_WRITE, &success);
		if (!success) {
			ib_logger(ib_stream,
				"InnoDB: Cannot create %s. Check that"
				" the file does not exist yet.\n", name);

			exit(1);
		}

		ib_logger(ib_stream,
			"Setting log file size to %lu %lu\n",
			(ulong) ut_get_high32(log_file_size),
			(ulong) log_file_size & 0xFFFFFFFFUL);

		success = os_file_set_size(name, log_file,
					   log_file_size & 0xFFFFFFFFUL,
					   ut_get_high32(log_file_size));

		if (!success) {
			ib_logger(ib_stream,
				"InnoDB: Cannot set %s size to %lu %lu\n",
				name, (ulong) ut_get_high32(log_file_size),
				(ulong) (log_file_size & 0xFFFFFFFFUL));
			exit(1);
		}

		os_file_flush(log_file);
		os_file_close(log_file);
	}

	/* We pretend there is a checkpoint at lsn + LOG_BLOCK_HDR_SIZE */

	log_reset_first_header_and_checkpoint(buf, lsn);

	log_block_init_in_old_format(buf + LOG_FILE_HDR_SIZE, lsn);
	log_block_set_first_rec_group(buf + LOG_FILE_HDR_SIZE,
				      LOG_BLOCK_HDR_SIZE);

	ut_snprintf(name, sizeof(name)-1, "%s%s%lu",
		    log_dir, ib_logfile_basename, (ulong)0);

	log_file = os_file_create_simple(name, OS_FILE_OPEN,
					 OS_FILE_READ_WRITE, &success);
	if (!success) {
		ib_logger(ib_stream, "InnoDB: Cannot open %s.\n", name);

		exit(1);
	}

	os_file_write(name, log_file, buf, 0, 0,
		      LOG_FILE_HDR_SIZE + OS_FILE_LOG_BLOCK_SIZE);
	os_file_flush(log_file);
	os_file_close(log_file);

	ut_free(buf);
}
#endif /* UNIV_HOTBACKUP */

#ifdef UNIV_LOG_ARCHIVE
/******************************************************//**
Reads from the archive of a log group and performs recovery.
@return	TRUE if no more complete consistent archive files */
UNIV_STATIC
ibool
log_group_recover_from_archive_file(
/*================================*/
	ib_recovery_t	recovery,	/*!< in: recovery flag */
	log_group_t*	group)		/*!< in: log group */
{
	os_file_t	file_handle;
	ib_uint64_t	start_lsn;
	ib_uint64_t	file_end_lsn;
	ib_uint64_t	dummy_lsn;
	ib_uint64_t	scanned_lsn;
	ulint		len;
	ibool		ret;
	byte*		buf;
	ulint		read_offset;
	ulint		file_size;
	ulint		file_size_high;
	int		input_char;
	char		name[10000];

	ut_a(0);

try_open_again:
	buf = log_sys->buf;

	/* Add the file to the archive file space; open the file */

	log_archived_file_name_gen(name, group->id, group->archived_file_no);

	file_handle = os_file_create(name, OS_FILE_OPEN,
				     OS_FILE_LOG, OS_FILE_AIO, &ret);

	if (ret == FALSE) {
ask_again:
		ib_logger(ib_stream,
			  "InnoDB: Do you want to copy additional"
			  " archived log files\n"
			  "InnoDB: to the directory\n");
		ib_logger(ib_stream,
			  "InnoDB: or were these all the files needed"
			  " in recovery?\n");
		ib_logger(ib_stream,
			  "InnoDB: (Y == copy more files; N == this is all)?");

		input_char = getchar();

		if (input_char == (int) 'N') {

			return(TRUE);
		} else if (input_char == (int) 'Y') {

			goto try_open_again;
		} else {
			goto ask_again;
		}
	}

	ret = os_file_get_size(file_handle, &file_size, &file_size_high);
	ut_a(ret);

	ut_a(file_size_high == 0);

	ib_logger(ib_stream, "InnoDB: Opened archived log file %s\n", name);

	ret = os_file_close(file_handle);

	if (file_size < LOG_FILE_HDR_SIZE) {
		ib_logger(ib_stream,
			  "InnoDB: Archive file header incomplete %s\n", name);

		return(TRUE);
	}

	ut_a(ret);

	/* Add the archive file as a node to the space */

	fil_node_create(name, 1 + file_size / UNIV_PAGE_SIZE,
			group->archive_space_id, FALSE);
#if RECV_SCAN_SIZE < LOG_FILE_HDR_SIZE
# error "RECV_SCAN_SIZE < LOG_FILE_HDR_SIZE"
#endif

	/* Read the archive file header */
	fil_io(OS_FILE_READ | OS_FILE_LOG,
	       TRUE,
	       group->archive_space_id,
	       0, // FIXME: ARCHIVE: Zip size
	       0,
	       0,
	       LOG_FILE_HDR_SIZE,
	       buf,
	       NULL);

	/* Check if the archive file header is consistent */

	if (mach_read_from_4(buf + LOG_GROUP_ID) != group->id
	    || mach_read_from_4(buf + LOG_FILE_NO)
	    != group->archived_file_no) {
		ib_logger(ib_stream,
			  "InnoDB: Archive file header inconsistent %s\n",
			  name);

		return(TRUE);
	}

	if (!mach_read_from_4(buf + LOG_FILE_ARCH_COMPLETED)) {
		ib_logger(ib_stream,
			  "InnoDB: Archive file not completely written %s\n",
			  name);

		return(TRUE);
	}

	start_lsn = mach_read_ull(buf + LOG_FILE_START_LSN);
	file_end_lsn = mach_read_ull(buf + LOG_FILE_END_LSN);

	if (!recv_sys->scanned_lsn) {

		if (recv_sys->parse_start_lsn < start_lsn) {
			ib_logger(ib_stream,
				  "InnoDB: Archive log file %s"
				  " starts from too big a lsn\n",
				name);
			return(TRUE);
		}

		recv_sys->scanned_lsn = start_lsn;
	}

	if (recv_sys->scanned_lsn != start_lsn) {

		ib_logger(ib_stream,
			  "InnoDB: Archive log file %s starts from"
			  " a wrong lsn\n",
			  name);
		return(TRUE);
	}

	read_offset = LOG_FILE_HDR_SIZE;

	for (;;) {
		len = RECV_SCAN_SIZE;

		if (read_offset + len > file_size) {
			len = ut_calc_align_down(file_size - read_offset,
						 OS_FILE_LOG_BLOCK_SIZE);
		}

		if (len == 0) {

			break;
		}

#ifdef UNIV_DEBUG
		if (log_debug_writes) {
			ib_logger(ib_stream,
				  "InnoDB: Archive read starting at"
				  " lsn %llu, len %lu from file %s\n",
				  start_lsn,
				  (ulong) len, name);
		}
#endif /* UNIV_DEBUG */

		fil_io(OS_FILE_READ | OS_FILE_LOG,
		       TRUE,
		       group->archive_space_id,
		       0, // FIXME: ARCHIVE: Zip size
		       read_offset / UNIV_PAGE_SIZE,
		       read_offset % UNIV_PAGE_SIZE,
		       len,
		       buf,
		       NULL);

		ret = recv_scan_log_recs(
			recovery,
			// FIXME: ARCHIVE: buf_pool_t::n_frames
			(buf_pool->curr_size - recv_n_pool_free_frames)
			* UNIV_PAGE_SIZE, TRUE, buf, len, start_lsn,
			&dummy_lsn, &scanned_lsn);

		if (scanned_lsn == file_end_lsn) {

			return(FALSE);
		}

		if (ret) {
			ib_logger(ib_stream,
				  "InnoDB: Archive log file %s"
				  " does not scan right\n",
				  name);
			return(TRUE);
		}

		read_offset += len;
		start_lsn += len;

		ut_ad(start_lsn == scanned_lsn);
	}

	return(FALSE);
}

/********************************************************//**
Recovers from archived log files, and also from log files, if they exist.
@return	error code or DB_SUCCESS */
UNIV_INTERN
ulint
recv_recovery_from_archive_start(
/*=============================*/
	ib_uint64_t	min_flushed_lsn,/*!< in: min flushed lsn field from the
					data files */
	ib_uint64_t	limit_lsn,	/*!< in: recover up to this lsn if
					possible */
	ulint		first_log_no)	/*!< in: number of the first archived
					log file to use in the recovery; the
					file will be searched from
					INNOBASE_LOG_ARCH_DIR specified in
					server config file */
{
	log_group_t*	group;
	ulint		group_id;
	ulint		trunc_len;
	ibool		ret;
	ulint		err;

	ut_a(0);

	recv_sys_create();
	recv_sys_init(buf_pool_get_curr_size());

	recv_recovery_on = TRUE;
	recv_recovery_from_backup_on = TRUE;

	recv_sys->limit_lsn = limit_lsn;

	group_id = 0;

	group = UT_LIST_GET_FIRST(log_sys->log_groups);

	while (group) {
		if (group->id == group_id) {

			break;
		}

		group = UT_LIST_GET_NEXT(log_groups, group);
	}

	if (!group) {
		ib_logger(ib_stream,
			  "InnoDB: There is no log group defined with id %lu!\n",
			  (ulong) group_id);
		return(DB_ERROR);
	}

	group->archived_file_no = first_log_no;

	recv_sys->parse_start_lsn = min_flushed_lsn;

	recv_sys->scanned_lsn = 0;
	recv_sys->scanned_checkpoint_no = 0;
	recv_sys->recovered_lsn = recv_sys->parse_start_lsn;

	recv_sys->archive_group = group;

	ret = FALSE;

	mutex_enter(&(log_sys->mutex));

	while (!ret) {
		ret = log_group_recover_from_archive_file(group);

		/* Close and truncate a possible processed archive file
		from the file space */

		trunc_len = UNIV_PAGE_SIZE
			* fil_space_get_size(group->archive_space_id);
		if (trunc_len > 0) {
			fil_space_truncate_start(group->archive_space_id,
						 trunc_len);
		}

		group->archived_file_no++;
	}

	if (recv_sys->recovered_lsn < limit_lsn) {

		if (!recv_sys->scanned_lsn) {

			recv_sys->scanned_lsn = recv_sys->parse_start_lsn;
		}

		mutex_exit(&(log_sys->mutex));

		err = recv_recovery_from_checkpoint_start(LOG_ARCHIVE,
							  limit_lsn,
							  IB_UINT64_T_MAX,
							  IB_UINT64_T_MAX);
		if (err != DB_SUCCESS) {

			return(err);
		}

		mutex_enter(&(log_sys->mutex));
	}

	if (limit_lsn != IB_UINT64_T_MAX) {

		recv_apply_hashed_log_recs(FALSE);

		recv_reset_logs(recv_sys->recovered_lsn, 0, FALSE);
	}

	mutex_exit(&(log_sys->mutex));

	return(DB_SUCCESS);
}

/********************************************************//**
Completes recovery from archive. */
UNIV_INTERN
void
recv_recovery_from_archive_finish(void)
/*===================================*/
{
	recv_recovery_from_checkpoint_finish();

	recv_recovery_from_backup_on = FALSE;
}
#endif /* UNIV_LOG_ARCHIVE */
